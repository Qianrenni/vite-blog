## 7.3 内存管理

### 内存分配机制

```go
package main

import (
    "fmt"
    "runtime"
    "sync"
    "time"
    "unsafe"
)

// 内存分配基础示例
func demonstrateMemoryAllocation() {
    fmt.Println("=== 内存分配机制 ===")
    
    // 栈分配 vs 堆分配
    // 栈分配：小对象，生命周期短
    func stackAllocation() {
        var x int = 42
        var y float64 = 3.14
        fmt.Printf("Stack variables - x: %d, y: %f\n", x, y)
    }
    
    stackAllocation()
    
    // 堆分配：大对象，需要逃逸到堆
    func heapAllocation() *int {
        x := 42  // 这个变量会逃逸到堆
        return &x
    }
    
    ptr := heapAllocation()
    fmt.Printf("Heap allocated value: %d\n", *ptr)
    
    // 不同大小对象的分配
    fmt.Println("Different size allocations:")
    
    // 小对象 - 通常栈分配
    small := make([]int, 10)
    fmt.Printf("Small slice (10 ints): %p\n", &small[0])
    
    // 中等对象 - 可能堆分配
    medium := make([]int, 1000)
    fmt.Printf("Medium slice (1000 ints): %p\n", &medium[0])
    
    // 大对象 - 堆分配
    large := make([]int, 100000)
    fmt.Printf("Large slice (100000 ints): %p\n", &large[0])
}

// 内存分配器工作原理
func demonstrateAllocator() {
    fmt.Println("\n=== 内存分配器工作原理 ===")
    
    // TCMalloc风格的分配器
    // Go使用类似TCMalloc的分配器，分为不同的大小类别
    
    // 小对象分配 (0-32KB)
    smallObjects := make([][]byte, 1000)
    for i := range smallObjects {
        smallObjects[i] = make([]byte, 1024)  // 1KB对象
    }
    
    fmt.Printf("Allocated 1000 small objects (1KB each)\n")
    
    // 中等对象分配 (32KB-32MB)
    mediumObjects := make([][]byte, 100)
    for i := range mediumObjects {
        mediumObjects[i] = make([]byte, 64*1024)  // 64KB对象
    }
    
    fmt.Printf("Allocated 100 medium objects (64KB each)\n")
    
    // 大对象分配 (>32MB)
    largeObject := make([]byte, 64*1024*1024)  // 64MB对象
    fmt.Printf("Allocated large object (64MB): %p\n", &largeObject[0])
    
    // 显示内存统计
    var m runtime.MemStats
    runtime.ReadMemStats(&m)
    fmt.Printf("Alloc: %d KB\n", m.Alloc/1024)
    fmt.Printf("TotalAlloc: %d KB\n", m.TotalAlloc/1024)
    fmt.Printf("Sys: %d KB\n", m.Sys/1024)
    fmt.Printf("NumGC: %d\n", m.NumGC)
}

// 内存池使用
func demonstrateMemoryPool() {
    fmt.Println("\n=== 内存池使用 ===")
    
    // sync.Pool示例
    type LargeObject struct {
        Data [1024]byte
        ID   int
    }
    
    var objectPool = sync.Pool{
        New: func() interface{} {
            return &LargeObject{}
        },
    }
    
    // 不使用内存池
    start := time.Now()
    for i := 0; i < 100000; i++ {
        obj := &LargeObject{ID: i}
        _ = obj.ID
    }
    withoutPoolTime := time.Since(start)
    
    // 使用内存池
    start = time.Now()
    for i := 0; i < 100000; i++ {
        obj := objectPool.Get().(*LargeObject)
        obj.ID = i
        _ = obj.ID
        objectPool.Put(obj)
    }
    withPoolTime := time.Since(start)
    
    fmt.Printf("Without pool: %v\n", withoutPoolTime)
    fmt.Printf("With pool: %v\n", withPoolTime)
    fmt.Printf("Pool improvement: %.2fx\n", float64(withoutPoolTime)/float64(withPoolTime))
    
    // 内存池统计
    var m1, m2 runtime.MemStats
    runtime.GC()
    runtime.ReadMemStats(&m1)
    
    // 使用内存池进行大量分配
    for i := 0; i < 10000; i++ {
        obj := objectPool.Get().(*LargeObject)
        obj.ID = i
        objectPool.Put(obj)
    }
    
    runtime.GC()
    runtime.ReadMemStats(&m2)
    
    fmt.Printf("Memory allocated: %d KB\n", (m2.TotalAlloc-m1.TotalAlloc)/1024)
    fmt.Printf("Objects allocated: %d\n", m2.Mallocs-m1.Mallocs)
}

// 内存分配优化技巧
func demonstrateAllocationOptimization() {
    fmt.Println("\n=== 内存分配优化技巧 ===")
    
    // 1. 预分配切片容量
    fmt.Println("1. 预分配切片容量:")
    
    // 不好的做法
    start := time.Now()
    var badSlice []int
    for i := 0; i < 10000; i++ {
        badSlice = append(badSlice, i)
    }
    badTime := time.Since(start)
    
    // 好的做法
    start = time.Now()
    goodSlice := make([]int, 0, 10000)
    for i := 0; i < 10000; i++ {
        goodSlice = append(goodSlice, i)
    }
    goodTime := time.Since(start)
    
    fmt.Printf("  Without preallocation: %v\n", badTime)
    fmt.Printf("  With preallocation: %v\n", goodTime)
    fmt.Printf("  Improvement: %.2fx\n", float64(badTime)/float64(goodTime))
    
    // 2. 重用切片
    fmt.Println("\n2. 重用切片:")
    
    reusableSlice := make([]int, 0, 1000)
    
    start = time.Now()
    for i := 0; i < 1000; i++ {
        reusableSlice = reusableSlice[:0]  // 重置但保留容量
        for j := 0; j < 100; j++ {
            reusableSlice = append(reusableSlice, j)
        }
        _ = len(reusableSlice)
    }
    reuseTime := time.Since(start)
    
    start = time.Now()
    for i := 0; i < 1000; i++ {
        newSlice := make([]int, 0, 100)  // 每次都创建新切片
        for j := 0; j < 100; j++ {
            newSlice = append(newSlice, j)
        }
        _ = len(newSlice)
    }
    createTime := time.Since(start)
    
    fmt.Printf("  Reusing slice: %v\n", reuseTime)
    fmt.Printf("  Creating new slices: %v\n", createTime)
    fmt.Printf("  Reuse improvement: %.2fx\n", float64(createTime)/float64(reuseTime))
    
    // 3. 使用指针避免大对象复制
    fmt.Println("\n3. 使用指针避免大对象复制:")
    
    type LargeStruct struct {
        Data [10000]int
        Name string
    }
    
    // 不好的做法 - 值传递
    func processLargeStruct(ls LargeStruct) int {
        return len(ls.Data)
    }
    
    // 好的做法 - 指针传递
    func processLargeStructPtr(ls *LargeStruct) int {
        return len(ls.Data)
    }
    
    largeObj := LargeStruct{Name: "test"}
    
    start = time.Now()
    for i := 0; i < 100000; i++ {
        _ = processLargeStruct(largeObj)
    }
    valueTime := time.Since(start)
    
    start = time.Now()
    for i := 0; i < 100000; i++ {
        _ = processLargeStructPtr(&largeObj)
    }
    pointerTime := time.Since(start)
    
    fmt.Printf("  Value passing: %v\n", valueTime)
    fmt.Printf("  Pointer passing: %v\n", pointerTime)
    fmt.Printf("  Pointer improvement: %.2fx\n", float64(valueTime)/float64(pointerTime))
}

// 内存分配器内部结构
func demonstrateAllocatorInternals() {
    fmt.Println("\n=== 内存分配器内部结构 ===")
    
    // 显示分配器统计信息
    var m runtime.MemStats
    runtime.ReadMemStats(&m)
    
    fmt.Printf("Allocator Stats:\n")
    fmt.Printf("  Alloc: %d KB (当前分配的字节数)\n", m.Alloc/1024)
    fmt.Printf("  TotalAlloc: %d KB (累计分配的字节数)\n", m.TotalAlloc/1024)
    fmt.Printf("  Sys: %d KB (从系统获取的字节数)\n", m.Sys/1024)
    fmt.Printf("  Lookups: %d (指针查找次数)\n", m.Lookups)
    fmt.Printf("  Mallocs: %d (分配次数)\n", m.Mallocs)
    fmt.Printf("  Frees: %d (释放次数)\n", m.Frees)
    fmt.Printf("  HeapAlloc: %d KB (堆分配字节数)\n", m.HeapAlloc/1024)
    fmt.Printf("  HeapSys: %d KB (堆从系统获取字节数)\n", m.HeapSys/1024)
    fmt.Printf("  HeapIdle: %d KB (堆空闲字节数)\n", m.HeapIdle/1024)
    fmt.Printf("  HeapInuse: %d KB (堆使用字节数)\n", m.HeapInuse/1024)
    fmt.Printf("  HeapReleased: %d KB (堆释放回系统的字节数)\n", m.HeapReleased/1024)
    fmt.Printf("  HeapObjects: %d (堆对象数量)\n", m.HeapObjects)
    fmt.Printf("  StackInuse: %d KB (栈使用字节数)\n", m.StackInuse/1024)
    fmt.Printf("  StackSys: %d KB (栈从系统获取字节数)\n", m.StackSys/1024)
    fmt.Printf("  MSpanInuse: %d KB (MSpan结构使用字节数)\n", m.MSpanInuse/1024)
    fmt.Printf("  MCacheInuse: %d KB (MCache结构使用字节数)\n", m.MCacheInuse/1024)
    fmt.Printf("  BuckHashSys: %d KB (剖析桶哈希表字节数)\n", m.BuckHashSys/1024)
    fmt.Printf("  GCSys: %d KB (GC元数据字节数)\n", m.GCSys/1024)
    fmt.Printf("  OtherSys: %d KB (其他系统分配字节数)\n", m.OtherSys/1024)
    fmt.Printf("  NextGC: %d KB (下次GC目标)\n", m.NextGC/1024)
    fmt.Printf("  LastGC: %v (上次GC时间)\n", time.Unix(0, int64(m.LastGC)))
    fmt.Printf("  PauseTotalNs: %v (GC暂停总时间)\n", time.Duration(m.PauseTotalNs))
    fmt.Printf("  NumGC: %d (GC执行次数)\n", m.NumGC)
    fmt.Printf("  NumForcedGC: %d (强制GC次数)\n", m.NumForcedGC)
    fmt.Printf("  GCCPUFraction: %.2f (GC使用的CPU时间比例)\n", m.GCCPUFraction)
    fmt.Printf("  EnableGC: %t (GC是否启用)\n", m.EnableGC)
    fmt.Printf("  DebugGC: %t (GC调试是否启用)\n", m.DebugGC)
}

// 内存分配模式分析
func demonstrateAllocationPatterns() {
    fmt.Println("\n=== 内存分配模式分析 ===")
    
    // 1. 批量分配
    fmt.Println("1. 批量分配模式:")
    
    // 单个分配
    start := time.Now()
    var singleAlloc [][]int
    for i := 0; i < 1000; i++ {
        singleAlloc = append(singleAlloc, make([]int, 100))
    }
    singleTime := time.Since(start)
    
    // 批量分配
    start = time.Now()
    batchAlloc := make([][]int, 1000)
    for i := range batchAlloc {
        batchAlloc[i] = make([]int, 100)
    }
    batchTime := time.Since(start)
    
    fmt.Printf("  Single allocation: %v\n", singleTime)
    fmt.Printf("  Batch allocation: %v\n", batchTime)
    fmt.Printf("  Batch improvement: %.2fx\n", float64(singleTime)/float64(batchTime))
    
    // 2. 对象池模式
    fmt.Println("\n2. 对象池模式:")
    
    type Worker struct {
        ID   int
        Data []byte
    }
    
    workerPool := sync.Pool{
        New: func() interface{} {
            return &Worker{
                Data: make([]byte, 1024),
            }
        },
    }
    
    // 使用对象池
    start = time.Now()
    for i := 0; i < 10000; i++ {
        worker := workerPool.Get().(*Worker)
        worker.ID = i
        // 处理工作...
        workerPool.Put(worker)
    }
    poolTime := time.Since(start)
    
    // 不使用对象池
    start = time.Now()
    for i := 0; i < 10000; i++ {
        worker := &Worker{
            ID:   i,
            Data: make([]byte, 1024),
        }
        // 处理工作...
        _ = worker.ID
    }
    noPoolTime := time.Since(start)
    
    fmt.Printf("  With pool: %v\n", poolTime)
    fmt.Printf("  Without pool: %v\n", noPoolTime)
    fmt.Printf("  Pool improvement: %.2fx\n", float64(noPoolTime)/float64(poolTime))
    
    // 3. 预分配模式
    fmt.Println("\n3. 预分配模式:")
    
    // 动态增长
    start = time.Now()
    dynamicSlice := make([]int, 0)
    for i := 0; i < 10000; i++ {
        dynamicSlice = append(dynamicSlice, i)
    }
    dynamicTime := time.Since(start)
    
    // 预分配
    start = time.Now()
    preallocSlice := make([]int, 0, 10000)
    for i := 0; i < 10000; i++ {
        preallocSlice = append(preallocSlice, i)
    }
    preallocTime := time.Since(start)
    
    fmt.Printf("  Dynamic growth: %v\n", dynamicTime)
    fmt.Printf("  Preallocated: %v\n", preallocTime)
    fmt.Printf("  Prealloc improvement: %.2fx\n", float64(dynamicTime)/float64(preallocTime))
}

func main() {
    demonstrateMemoryAllocation()
    demonstrateAllocator()
    demonstrateMemoryPool()
    demonstrateAllocationOptimization()
    demonstrateAllocatorInternals()
    demonstrateAllocationPatterns()
}
```

### 垃圾回收机制

```go
package main

import (
    "fmt"
    "runtime"
    "runtime/debug"
    "sync"
    "time"
)

// 垃圾回收基础
func demonstrateGarbageCollection() {
    fmt.Println("=== 垃圾回收机制 ===")
    
    // 显示GC信息
    fmt.Println("Initial GC state:")
    var m runtime.MemStats
    runtime.ReadMemStats(&m)
    fmt.Printf("  Alloc: %d KB\n", m.Alloc/1024)
    fmt.Printf("  NumGC: %d\n", m.NumGC)
    
    // 创建大量对象触发GC
    fmt.Println("\nCreating objects to trigger GC...")
    objects := make([]*[]int, 100000)
    for i := range objects {
        slice := make([]int, 100)
        objects[i] = &slice
    }
    
    runtime.ReadMemStats(&m)
    fmt.Printf("After allocation - Alloc: %d KB\n", m.Alloc/1024)
    
    // 手动触发GC
    fmt.Println("Triggering GC...")
    start := time.Now()
    runtime.GC()
    gcDuration := time.Since(start)
    
    runtime.ReadMemStats(&m)
    fmt.Printf("After GC - Alloc: %d KB\n", m.Alloc/1024)
    fmt.Printf("GC duration: %v\n", gcDuration)
    fmt.Printf("GC cycles: %d\n", m.NumGC)
}

// GC调优参数
func demonstrateGCTuning() {
    fmt.Println("\n=== GC调优参数 ===")
    
    // 获取当前GC设置
    fmt.Println("Current GC settings:")
    fmt.Printf("  GOGC: %v\n", debug.SetGCPercent(-1))  // -1表示只读取不设置
    
    // 设置GC百分比
    oldGCPercent := debug.SetGCPercent(50)  // 50%的堆增长触发GC
    fmt.Printf("  Old GOGC: %d\n", oldGCPercent)
    fmt.Printf("  New GOGC: %d\n", debug.SetGCPercent(-1))
    
    // 设置GC目标
    debug.SetGCPercent(100)  // 恢复默认值
    
    // 显示GC统计
    var m runtime.MemStats
    runtime.ReadMemStats(&m)
    fmt.Printf("  NextGC target: %d KB\n", m.NextGC/1024)
    fmt.Printf("  GC CPU fraction: %.2f%%\n", m.GCCPUFraction*100)
    
    // GC模式设置
    fmt.Println("\nGC mode settings:")
    fmt.Println("  GODEBUG=gctrace=1  # 启用GC跟踪")
    fmt.Println("  GOGC=off          # 禁用自动GC")
    fmt.Println("  GOGC=20           # 20%堆增长触发GC")
    fmt.Println("  GOGC=200          # 200%堆增长触发GC")
}

// GC三色标记算法
func demonstrateThreeColorMarking() {
    fmt.Println("\n=== GC三色标记算法 ===")
    
    // 模拟三色标记过程
    type Node struct {
        value    int
        children []*Node
        marked   bool  // 简化版本的标记
    }
    
    // 创建对象图
    root := &Node{value: 1}
    node2 := &Node{value: 2}
    node3 := &Node{value: 3}
    node4 := &Node{value: 4}
    
    root.children = []*Node{node2, node3}
    node2.children = []*Node{node4}
    
    // 模拟GC标记过程
    fmt.Println("Simulating GC marking process:")
    
    // 白色集合（未标记对象）
    whiteSet := map[*Node]bool{root: true, node2: true, node3: true, node4: true}
    
    // 灰色集合（已发现但未完全扫描）
    graySet := []*Node{root}
    delete(whiteSet, root)
    
    fmt.Println("  Initial state:")
    fmt.Printf("    White: %d objects\n", len(whiteSet))
    fmt.Printf("    Gray: %d objects\n", len(graySet))
    
    // 标记过程
    for len(graySet) > 0 {
        // 从灰色集合取出一个对象
        current := graySet[0]
        graySet = graySet[1:]
        
        // 标记该对象的所有子对象
        for _, child := range current.children {
            if whiteSet[child] {
                delete(whiteSet, child)
                graySet = append(graySet, child)
            }
        }
        
        fmt.Printf("    Marked node %d, Gray: %d, White: %d\n", 
            current.value, len(graySet), len(whiteSet))
    }
    
    fmt.Println("  Final state:")
    fmt.Printf("    Reachable objects: %d\n", 4-len(whiteSet))
    fmt.Printf("    Unreachable objects: %d\n", len(whiteSet))
}

// 写屏障机制
func demonstrateWriteBarrier() {
    fmt.Println("\n=== 写屏障机制 ===")
    
    // 模拟写屏障的工作原理
    type Object struct {
        value    int
        pointers []*Object
        marked   bool
    }
    
    // 创建对象图
    obj1 := &Object{value: 1}
    obj2 := &Object{value: 2}
    obj3 := &Object{value: 3}
    
    obj1.pointers = []*Object{obj2}
    obj2.pointers = []*Object{obj3}
    
    fmt.Println("Write barrier simulation:")
    fmt.Printf("  Initial graph: obj1 -> obj2 -> obj3\n")
    
    // 模拟GC正在进行中，obj1已经被标记
    obj1.marked = true
    obj2.marked = false  // obj2未被标记
    obj3.marked = false  // obj3未被标记
    
    // 模拟写操作：obj1.pointers[0] = obj3
    // 写屏障会检测到这种情况并确保obj3被正确标记
    fmt.Println("  GC in progress, obj1 marked, obj2 and obj3 unmarked")
    
    // 写屏障逻辑
    oldValue := obj1.pointers[0]
    newValue := obj3
    
    fmt.Printf("  Writing obj3 to obj1.pointers[0] (was obj2)\n")
    
    // 写屏障检查
    if obj1.marked && !newValue.marked {
        fmt.Printf("  Write barrier: marking obj3\n")
        newValue.marked = true
    }
    
    fmt.Printf("  obj1 marked: %t\n", obj1.marked)
    fmt.Printf("  obj2 marked: %t\n", obj2.marked)
    fmt.Printf("  obj3 marked: %t\n", obj3.marked)
}

// GC性能分析
func demonstrateGCPerformance() {
    fmt.Println("\n=== GC性能分析 ===")
    
    // 测试不同GC设置的性能
    testCases := []struct {
        name     string
        gcPercent int
        objects  int
    }{
        {"Default GC (100%)", 100, 100000},
        {"Fast GC (50%)", 50, 100000},
        {"Slow GC (200%)", 200, 100000},
    }
    
    for _, tc := range testCases {
        fmt.Printf("\nTesting %s:\n", tc.name)
        
        // 设置GC百分比
        oldGC := debug.SetGCPercent(tc.gcPercent)
        fmt.Printf("  Set GOGC to %d (was %d)\n", tc.gcPercent, oldGC)
        
        // 创建对象并测量性能
        start := time.Now()
        objects := make([]*[]int, tc.objects)
        
        for i := range objects {
            objects[i] = &[]int{i}
        }
        
        allocTime := time.Since(start)
        fmt.Printf("  Allocation time: %v\n", allocTime)
        
        // 触发GC并测量
        start = time.Now()
        runtime.GC()
        gcTime := time.Since(start)
        
        var m runtime.MemStats
        runtime.ReadMemStats(&m)
        fmt.Printf("  GC time: %v\n", gcTime)
        fmt.Printf("  GC cycles: %d\n", m.NumGC)
        fmt.Printf("  Heap objects: %d\n", m.HeapObjects)
    }
    
    // 恢复默认GC设置
    debug.SetGCPercent(100)
}

// GC调优实践
func demonstrateGCTuningPractice() {
    fmt.Println("\n=== GC调优实践 ===")
    
    // 1. 减少分配
    fmt.Println("1. Reducing allocations:")
    
    // 使用对象池
    type DataProcessor struct {
        buffer []byte
        result []int
    }
    
    var processorPool = sync.Pool{
        New: func() interface{} {
            return &DataProcessor{
                buffer: make([]byte, 1024),
                result: make([]int, 0, 100),
            }
        },
    }
    
    // 处理大量数据
    start := time.Now()
    for i := 0; i < 10000; i++ {
        processor := processorPool.Get().(*DataProcessor)
        // 处理数据...
        processor.result = processor.result[:0]  // 重置结果切片
        processorPool.Put(processor)
    }
    poolTime := time.Since(start)
    
    fmt.Printf("  With object pool: %v\n", poolTime)
    
    // 2. 预分配内存
    fmt.Println("\n2. Preallocating memory:")
    
    // 动态分配
    start = time.Now()
    var dynamic [][]int
    for i := 0; i < 1000; i++ {
        dynamic = append(dynamic, make([]int, 100))
    }
    dynamicTime := time.Since(start)
    
    // 预分配
    start = time.Now()
    prealloc := make([][]int, 1000)
    for i := range prealloc {
        prealloc[i] = make([]int, 100)
    }
    preallocTime := time.Since(start)
    
    fmt.Printf("  Dynamic allocation: %v\n", dynamicTime)
    fmt.Printf("  Preallocated: %v\n", preallocTime)
    fmt.Printf("  Improvement: %.2fx\n", float64(dynamicTime)/float64(preallocTime))
    
    // 3. 减少指针使用
    fmt.Println("\n3. Reducing pointer usage:")
    
    type SmallStruct struct {
        a, b, c int
    }
    
    // 使用值类型
    start = time.Now()
    values := make([]SmallStruct, 100000)
    for i := range values {
        values[i] = SmallStruct{a: i, b: i * 2, c: i * 3}
    }
    valueTime := time.Since(start)
    
    // 使用指针类型
    start = time.Now()
    pointers := make([]*SmallStruct, 100000)
    for i := range pointers {
        pointers[i] = &SmallStruct{a: i, b: i * 2, c: i * 3}
    }
    pointerTime := time.Since(start)
    
    fmt.Printf("  Value types: %v\n", valueTime)
    fmt.Printf("  Pointer types: %v\n", pointerTime)
    fmt.Printf("  Value improvement: %.2fx\n", float64(pointerTime)/float64(valueTime))
}

// GC监控和调试
func demonstrateGCMonitoring() {
    fmt.Println("\n=== GC监控和调试 ===")
    
    // 启用GC跟踪
    fmt.Println("GC tracing can be enabled with:")
    fmt.Println("  GODEBUG=gctrace=1 go run main.go")
    
    // 实时监控GC状态
    fmt.Println("\nReal-time GC monitoring:")
    
    // 启动监控goroutine
    go func() {
        ticker := time.NewTicker(1 * time.Second)
        defer ticker.Stop()
        
        for range ticker.C {
            var m runtime.MemStats
            runtime.ReadMemStats(&m)
            
            fmt.Printf("GC Stats - Alloc: %dKB, Sys: %dKB, NumGC: %d, Pause: %v\n",
                m.Alloc/1024, m.Sys/1024, m.NumGC, time.Duration(m.PauseTotalNs))
        }
    }()
    
    // 模拟工作负载
    fmt.Println("Simulating workload...")
    for i := 0; i < 5; i++ {
        // 创建大量对象
        objects := make([]*[]int, 50000)
        for j := range objects {
            objects[j] = &[]int{j}
        }
        
        time.Sleep(500 * time.Millisecond)
    }
    
    time.Sleep(2 * time.Second)
}

// GC最佳实践
func demonstrateGCBestPractices() {
    fmt.Println("\n=== GC最佳实践 ===")
    
    fmt.Println("1. 减少内存分配:")
    fmt.Println("   - 预分配切片和映射容量")
    fmt.Println("   - 使用对象池重用对象")
    fmt.Println("   - 避免不必要的字符串拼接")
    fmt.Println("   - 使用值类型而非指针类型（当对象较小时）")
    
    fmt.Println("\n2. 优化数据结构:")
    fmt.Println("   - 选择合适的数据结构")
    fmt.Println("   - 避免深层嵌套的指针结构")
    fmt.Println("   - 使用紧凑的数据布局")
    fmt.Println("   - 考虑内存对齐")
    
    fmt.Println("\n3. GC参数调优:")
    fmt.Println("   - GOGC=50  # 频繁GC，低延迟")
    fmt.Println("   - GOGC=200 # 少GC，高吞吐")
    fmt.Println("   - 根据应用特性调整")
    
    fmt.Println("\n4. 监控和分析:")
    fmt.Println("   - 使用runtime.ReadMemStats监控")
    fmt.Println("   - 启用GODEBUG=gctrace=1")
    fmt.Println("   - 使用pprof分析内存使用")
    fmt.Println("   - 定期进行性能测试")
    
    fmt.Println("\n5. 避免常见陷阱:")
    fmt.Println("   - 避免在热点路径中分配内存")
    fmt.Println("   - 注意goroutine泄漏导致的对象无法回收")
    fmt.Println("   - 避免循环引用")
    fmt.Println("   - 及时关闭资源（文件、网络连接等）")
    
    fmt.Println("\n6. 性能测试:")
    fmt.Println("   - 基准测试前后对比")
    fmt.Println("   - 监控GC暂停时间")
    fmt.Println("   - 分析内存分配模式")
    fmt.Println("   - 使用工具进行深入分析")
}

func main() {
    demonstrateGarbageCollection()
    demonstrateGCTuning()
    demonstrateThreeColorMarking()
    demonstrateWriteBarrier()
    demonstrateGCPerformance()
    demonstrateGCTuningPractice()
    demonstrateGCMonitoring()
    demonstrateGCBestPractices()
}
```

### 内存逃逸分析

```go
package main

import (
    "fmt"
    "sync"
)

// 内存逃逸基础示例
func demonstrateEscapeAnalysis() {
    fmt.Println("=== 内存逃逸分析 ===")
    
    // 1. 栈分配 - 不会逃逸
    func stackAllocation() {
        x := 42  // 栈分配
        fmt.Printf("Stack variable x: %d\n", x)
    }
    
    stackAllocation()
    
    // 2. 堆分配 - 会逃逸
    func heapAllocation() *int {
        x := 42  // 逃逸到堆
        return &x
    }
    
    ptr := heapAllocation()
    fmt.Printf("Heap allocated value: %d\n", *ptr)
    
    // 3. 切片逃逸
    func sliceEscape() []int {
        slice := make([]int, 10)  // 可能逃逸到堆
        return slice
    }
    
    slice := sliceEscape()
    fmt.Printf("Escaped slice length: %d\n", len(slice))
    
    // 4. 接口逃逸
    func interfaceEscape() interface{} {
        x := 42  // 逃逸到堆（接口需要）
        return x
    }
    
    value := interfaceEscape()
    fmt.Printf("Interface escaped value: %v\n", value)
}

// 逃逸分析详细示例
func demonstrateDetailedEscapeAnalysis() {
    fmt.Println("\n=== 详细逃逸分析 ===")
    
    // 1. 返回局部变量的指针 - 逃逸
    func returnPointer() *int {
        x := 100
        return &x  // x逃逸到堆
    }
    
    ptr1 := returnPointer()
    fmt.Printf("Returned pointer value: %d\n", *ptr1)
    
    // 2. 传递指针给其他函数 - 逃逸
    func passPointerToFunction() {
        x := 200
        func(p *int) {
            fmt.Printf("Passed pointer value: %d\n", *p)
        }(&x)  // x逃逸到堆
    }
    
    passPointerToFunction()
    
    // 3. 存储到全局变量 - 逃逸
    var globalPtr *int
    
    func storeToGlobal() {
        x := 300
        globalPtr = &x  // x逃逸到堆
    }
    
    storeToGlobal()
    fmt.Printf("Global pointer value: %d\n", *globalPtr)
    
    // 4. 大对象 - 逃逸
    func largeObject() *[10000]int {
        var arr [10000]int  // 大对象通常逃逸到堆
        return &arr
    }
    
    largeArr := largeObject()
    fmt.Printf("Large array length: %d\n", len(largeArr))
    
    // 5. 切片扩容 - 可能逃逸
    func sliceGrowth() []int {
        slice := make([]int, 0, 5)
        for i := 0; i < 10; i++ {
            slice = append(slice, i)  // 可能触发扩容，逃逸到堆
        }
        return slice
    }
    
    grownSlice := sliceGrowth()
    fmt.Printf("Grown slice: %v\n", grownSlice)
}

// 避免逃逸的技巧
func demonstrateEscapeAvoidance() {
    fmt.Println("\n=== 避免逃逸的技巧 ===")
    
    // 1. 使用值返回而非指针返回
    fmt.Println("1. 使用值返回:")
    
    // 逃逸的版本
    func escapeVersion() *int {
        x := 42
        return &x  // 逃逸
    }
    
    // 不逃逸的版本
    func noEscapeVersion() int {
        x := 42
        return x  // 不逃逸
    }
    
    escapedValue := escapeVersion()
    noEscapedValue := noEscapeVersion()
    fmt.Printf("  Escaped: %d, No escape: %d\n", *escapedValue, noEscapedValue)
    
    // 2. 预分配足够的容量
    fmt.Println("\n2. 预分配容量:")
    
    // 可能逃逸的版本
    func mayEscapeVersion() []int {
        var slice []int
        for i := 0; i < 10; i++ {
            slice = append(slice, i)  // 可能触发扩容
        }
        return slice
    }
    
    // 不逃逸的版本
    func noEscapeVersionSlice() []int {
        slice := make([]int, 0, 10)  // 预分配足够容量
        for i := 0; i < 10; i++ {
            slice = append(slice, i)
        }
        return slice
    }
    
    mayEscapeSlice := mayEscapeVersion()
    noEscapeSlice := noEscapeVersionSlice()
    fmt.Printf("  May escape length: %d, No escape length: %d\n", 
        len(mayEscapeSlice), len(noEscapeSlice))
    
    // 3. 使用sync.Pool避免逃逸
    fmt.Println("\n3. 使用sync.Pool:")
    
    type ReusableObject struct {
        Data [100]byte
        ID   int
    }
    
    var objectPool = sync.Pool{
        New: func() interface{} {
            return &ReusableObject{}
        },
    }
    
    // 使用对象池避免频繁分配
    func usePool() *ReusableObject {
        obj := objectPool.Get().(*ReusableObject)
        obj.ID = 42
        return obj  // 不会逃逸，因为对象来自池
    }
    
    pooledObj := usePool()
    fmt.Printf("  Pooled object ID: %d\n", pooledObj.ID)
    objectPool.Put(pooledObj)  // 归还到池中
}

// 逃逸分析工具使用
func demonstrateEscapeAnalysisTools() {
    fmt.Println("\n=== 逃逸分析工具使用 ===")
    
    fmt.Println("使用go build -gcflags进行逃逸分析:")
    fmt.Println("  go build -gcflags=\"-m\" main.go")
    fmt.Println("  go build -gcflags=\"-m -m\" main.go  # 更详细")
    
    // 示例函数用于分析
    func exampleForAnalysis() *int {
        x := 100
        return &x
    }
    
    result := exampleForAnalysis()
    fmt.Printf("Example result: %d\n", *result)
    
    fmt.Println("\n逃逸分析输出示例:")
    fmt.Println("  ./main.go:10:2: moved to heap: x")
    fmt.Println("  ./main.go:11:9: &x escapes to heap")
    
    fmt.Println("\n常见的逃逸模式:")
    fmt.Println("  1. 返回局部变量的指针")
    fmt.Println("  2. 传递指针给可能存储的函数")
    fmt.Println("  3. 存储到全局变量或堆对象")
    fmt.Println("  4. 大对象分配")
    fmt.Println("  5. 接口转换")
    fmt.Println("  6. 切片扩容")
    fmt.Println("  7. 闭包捕获变量")
}

// 闭包逃逸分析
func demonstrateClosureEscape() {
    fmt.Println("\n=== 闭包逃逸分析 ===")
    
    // 1. 简单闭包 - 可能逃逸
    func simpleClosure() func() int {
        x := 42  // 可能逃逸到堆
        return func() int {
            return x  // 捕获x
        }
    }
    
    closure := simpleClosure()
    fmt.Printf("Simple closure result: %d\n", closure())
    
    // 2. 复杂闭包 - 更可能逃逸
    func complexClosure() func(int) int {
        multiplier := 2  // 逃逸到堆
        offset := 10     // 逃逸到堆
        
        return func(x int) int {
            return x*multiplier + offset  // 捕获多个变量
        }
    }
    
    complex := complexClosure()
    fmt.Printf("Complex closure result: %d\n", complex(5))
    
    // 3. 避免闭包逃逸
    fmt.Println("\n3. 避免闭包逃逸:")
    
    // 使用函数参数而非闭包捕获
    func avoidClosure(x, multiplier, offset int) int {
        return x*multiplier + offset  // 不需要逃逸
    }
    
    result := avoidClosure(5, 2, 10)
    fmt.Printf("  Avoided closure result: %d\n", result)
}

// 接口逃逸分析
func demonstrateInterfaceEscape() {
    fmt.Println("\n=== 接口逃逸分析 ===")
    
    // 1. 基本类型转接口 - 逃逸
    func basicToInterface() interface{} {
        x := 42  // 逃逸到堆（接口存储需要）
        return x
    }
    
    interfaceValue := basicToInterface()
    fmt.Printf("Basic to interface: %v\n", interfaceValue)
    
    // 2. 结构体转接口 - 逃逸
    type MyStruct struct {
        Value int
    }
    
    func structToInterface() interface{} {
        s := MyStruct{Value: 100}  // 逃逸到堆
        return s
    }
    
    structInterface := structToInterface()
    fmt.Printf("Struct to interface: %+v\n", structInterface)
    
    // 3. 避免接口逃逸
    fmt.Println("\n3. 避免接口逃逸:")
    
    // 使用具体类型而非接口
    func useConcreteType(s MyStruct) int {
        return s.Value  // 不需要逃逸
    }
    
    concrete := MyStruct{Value: 200}
    concreteResult := useConcreteType(concrete)
    fmt.Printf("  Concrete type result: %d\n", concreteResult)
}

// 切片和映射逃逸分析
func demonstrateSliceMapEscape() {
    fmt.Println("\n=== 切片和映射逃逸分析 ===")
    
    // 1. 切片逃逸情况
    func sliceEscapeCases() {
        // 返回切片 - 逃逸
        func returnSlice() []int {
            slice := make([]int, 10)  // 逃逸
            return slice
        }
        
        returnedSlice := returnSlice()
        fmt.Printf("Returned slice length: %d\n", len(returnedSlice))
        
        // 存储到全局变量 - 逃逸
        var globalSlice []int
        
        func storeToGlobalSlice() {
            localSlice := make([]int, 5)  // 逃逸
            globalSlice = localSlice
        }
        
        storeToGlobalSlice()
        fmt.Printf("Global slice length: %d\n", len(globalSlice))
    }
    
    sliceEscapeCases()
    
    // 2. 映射逃逸情况
    func mapEscapeCases() {
        // 返回映射 - 逃逸
        func returnMap() map[string]int {
            m := make(map[string]int)  // 逃逸
            return m
        }
        
        returnedMap := returnMap()
        fmt.Printf("Returned map length: %d\n", len(returnedMap))
        
        // 传递给函数 - 可能逃逸
        func processMap(m map[string]int) {
            m["key"] = 42
        }
        
        localMap := make(map[string]int)  // 可能逃逸
        processMap(localMap)
        fmt.Printf("Processed map value: %d\n", localMap["key"])
    }
    
    mapEscapeCases()
    
    // 3. 避免切片和映射逃逸
    fmt.Println("\n3. 避免切片和映射逃逸:")
    
    // 预分配足够容量
    func avoidSliceEscape() []int {
        slice := make([]int, 0, 100)  // 预分配容量
        for i := 0; i < 50; i++ {
            slice = append(slice, i)  // 不会触发扩容
        }
        return slice  // 可能仍然逃逸，但减少了分配
    }
    
    avoidedSlice := avoidSliceEscape()
    fmt.Printf("  Avoided slice length: %d\n", len(avoidedSlice))
}

// 逃逸分析优化示例
func demonstrateEscapeOptimization() {
    fmt.Println("\n=== 逃逸分析优化示例 ===")
    
    // 1. 优化前的代码
    fmt.Println("1. 优化前:")
    
    type Data struct {
        Values []int
        Count  int
    }
    
    // 逃逸的版本
    func escapeVersion() *Data {
        data := &Data{  // data逃逸到堆
            Values: make([]int, 10),
            Count:  42,
        }
        return data
    }
    
    escapedData := escapeVersion()
    fmt.Printf("  Escaped data count: %d\n", escapedData.Count)
    
    // 2. 优化后的代码
    fmt.Println("\n2. 优化后:")
    
    // 使用值返回
    func optimizedVersion() Data {
        data := Data{  // data在栈上分配
            Values: make([]int, 10),
            Count:  42,
        }
        return data
    }
    
    optimizedData := optimizedVersion()
    fmt.Printf("  Optimized data count: %d\n", optimizedData.Count)
    
    // 3. 使用对象池进一步优化
    fmt.Println("\n3. 使用对象池:")
    
    var dataPool = sync.Pool{
        New: func() interface{} {
            return &Data{
                Values: make([]int, 10),
            }
        },
    }
    
    func poolVersion() *Data {
        data := dataPool.Get().(*Data)  // 从池中获取，不逃逸
        data.Count = 42
        return data
    }
    
    pooledData := poolVersion()
    fmt.Printf("  Pooled data count: %d\n", pooledData.Count)
    dataPool.Put(pooledData)  // 归还到池中
}

// 逃逸分析最佳实践
func escapeAnalysisBestPractices() {
    fmt.Println("\n=== 逃逸分析最佳实践 ===")
    
    fmt.Println("1. 识别逃逸场景:")
    fmt.Println("   - 返回局部变量的指针")
    fmt.Println("   - 传递指针给可能存储的函数")
    fmt.Println("   - 存储到全局变量或堆对象")
    fmt.Println("   - 大对象分配")
    fmt.Println("   - 接口转换")
    fmt.Println("   - 切片扩容")
    fmt.Println("   - 闭包捕获变量")
    
    fmt.Println("\n2. 避免逃逸的策略:")
    fmt.Println("   - 使用值返回而非指针返回")
    fmt.Println("   - 预分配足够的切片和映射容量")
    fmt.Println("   - 使用对象池重用对象")
    fmt.Println("   - 避免不必要的接口转换")
    fmt.Println("   - 减少闭包的使用")
    fmt.Println("   - 选择合适的数据结构")
    
    fmt.Println("\n3. 工具使用:")
    fmt.Println("   - go build -gcflags=\"-m\" 查看逃逸分析")
    fmt.Println("   - go build -gcflags=\"-m -m\" 更详细分析")
    fmt.Println("   - go tool compile -S 查看汇编代码")
    fmt.Println("   - 使用pprof分析内存分配")
    
    fmt.Println("\n4. 性能考虑:")
    fmt.Println("   - 栈分配比堆分配快")
    fmt.Println("   - 减少逃逸可以降低GC压力")
    fmt.Println("   - 逃逸分析有助于编译器优化")
    fmt.Println("   - 平衡性能和代码可读性")
    
    fmt.Println("\n5. 调试技巧:")
    fmt.Println("   - 定期检查逃逸分析输出")
    fmt.Println("   - 监控内存分配模式")
    fmt.Println("   - 使用基准测试验证优化效果")
    fmt.Println("   - 分析GC统计信息")
}

func main() {
    demonstrateEscapeAnalysis()
    demonstrateDetailedEscapeAnalysis()
    demonstrateEscapeAvoidance()
    demonstrateEscapeAnalysisTools()
    demonstrateClosureEscape()
    demonstrateInterfaceEscape()
    demonstrateSliceMapEscape()
    demonstrateEscapeOptimization()
    escapeAnalysisBestPractices()
}
```

### 性能优化技巧

```go
package main

import (
    "fmt"
    "runtime"
    "sync"
    "time"
)

// 性能优化基础
func demonstrateBasicOptimization() {
    fmt.Println("=== 性能优化基础 ===")
    
    // 1. 避免不必要的内存分配
    fmt.Println("1. 避免不必要的内存分配:")
    
    // 不好的做法
    func badStringConcat() string {
        var result string
        for i := 0; i < 1000; i++ {
            result += fmt.Sprintf("%d ", i)  // 每次都创建新字符串
        }
        return result
    }
    
    // 好的做法
    func goodStringConcat() string {
        var builder strings.Builder
        builder.Grow(5000)  // 预分配容量
        for i := 0; i < 1000; i++ {
            builder.WriteString(fmt.Sprintf("%d ", i))
        }
        return builder.String()
    }
    
    start := time.Now()
    badResult := badStringConcat()
    badTime := time.Since(start)
    
    start = time.Now()
    goodResult := goodStringConcat()
    goodTime := time.Since(start)
    
    fmt.Printf("  Bad string concat: %v (length: %d)\n", badTime, len(badResult))
    fmt.Printf("  Good string concat: %v (length: %d)\n", goodTime, len(goodResult))
    fmt.Printf("  Improvement: %.2fx\n", float64(badTime)/float64(goodTime))
    
    // 2. 预分配切片容量
    fmt.Println("\n2. 预分配切片容量:")
    
    // 不好的做法
    func badSliceAllocation() []int {
        var slice []int
        for i := 0; i < 10000; i++ {
            slice = append(slice, i)  // 可能多次重新分配
        }
        return slice
    }
    
    // 好的做法
    func goodSliceAllocation() []int {
        slice := make([]int, 0, 10000)  // 预分配容量
        for i := 0; i < 10000; i++ {
            slice = append(slice, i)
        }
        return slice
    }
    
    start = time.Now()
    badSlice := badSliceAllocation()
    badSliceTime := time.Since(start)
    
    start = time.Now()
    goodSlice := goodSliceAllocation()
    goodSliceTime := time.Since(start)
    
    fmt.Printf("  Bad slice allocation: %v (length: %d)\n", badSliceTime, len(badSlice))
    fmt.Printf("  Good slice allocation: %v (length: %d)\n", goodSliceTime, len(goodSlice))
    fmt.Printf("  Improvement: %.2fx\n", float64(badSliceTime)/float64(goodSliceTime))
}

// 内存优化技巧
func demonstrateMemoryOptimization() {
    fmt.Println("\n=== 内存优化技巧 ===")
    
    // 1. 使用对象池
    fmt.Println("1. 使用对象池:")
    
    type Worker struct {
        ID   int
        Data []byte
    }
    
    var workerPool = sync.Pool{
        New: func() interface{} {
            return &Worker{
                Data: make([]byte, 1024),
            }
        },
    }
    
    // 不使用对象池
    start := time.Now()
    for i := 0; i < 100000; i++ {
        worker := &Worker{
            ID:   i,
            Data: make([]byte, 1024),
        }
        _ = worker.ID
    }
    noPoolTime := time.Since(start)
    
    // 使用对象池
    start = time.Now()
    for i := 0; i < 100000; i++ {
        worker := workerPool.Get().(*Worker)
        worker.ID = i
        _ = worker.ID
        workerPool.Put(worker)
    }
    poolTime := time.Since(start)
    
    fmt.Printf("  Without pool: %v\n", noPoolTime)
    fmt.Printf("  With pool: %v\n", poolTime)
    fmt.Printf("  Pool improvement: %.2fx\n", float64(noPoolTime)/float64(poolTime))
    
    // 2. 重用数据结构
    fmt.Println("\n2. 重用数据结构:")
    
    reusableSlice := make([]int, 0, 1000)
    
    // 不重用
    start = time.Now()
    for i := 0; i < 10000; i++ {
        slice := make([]int, 0, 100)
        for j := 0; j < 100; j++ {
            slice = append(slice, j)
        }
        _ = len(slice)
    }
    noReuseTime := time.Since(start)
    
    // 重用
    start = time.Now()
    for i := 0; i < 10000; i++ {
        reusableSlice = reusableSlice[:0]  // 重置但保留容量
        for j := 0; j < 100; j++ {
            reusableSlice = append(reusableSlice, j)
        }
        _ = len(reusableSlice)
    }
    reuseTime := time.Since(start)
    
    fmt.Printf("  Without reuse: %v\n", noReuseTime)
    fmt.Printf("  With reuse: %v\n", reuseTime)
    fmt.Printf("  Reuse improvement: %.2fx\n", float64(noReuseTime)/float64(reuseTime))
}

// 算法优化技巧
func demonstrateAlgorithmOptimization() {
    fmt.Println("\n=== 算法优化技巧 ===")
    
    // 1. 选择合适的数据结构
    fmt.Println("1. 选择合适的数据结构:")
    
    // 使用切片进行查找 - O(n)
    func sliceContains(slice []int, target int) bool {
        for _, v := range slice {
            if v == target {
                return true
            }
        }
        return false
    }
    
    // 使用映射进行查找 - O(1)
    func mapContains(m map[int]bool, target int) bool {
        return m[target]
    }
    
    // 准备测试数据
    slice := make([]int, 10000)
    for i := range slice {
        slice[i] = i
    }
    
    m := make(map[int]bool)
    for i := 0; i < 10000; i++ {
        m[i] = true
    }
    
    target := 9999
    
    // 测试切片查找
    start := time.Now()
    for i := 0; i < 1000; i++ {
        _ = sliceContains(slice, target)
    }
    sliceTime := time.Since(start)
    
    // 测试映射查找
    start = time.Now()
    for i := 0; i < 1000; i++ {
        _ = mapContains(m, target)
    }
    mapTime := time.Since(start)
    
    fmt.Printf("  Slice lookup: %v\n", sliceTime)
    fmt.Printf("  Map lookup: %v\n", mapTime)
    fmt.Printf("  Map improvement: %.2fx\n", float64(sliceTime)/float64(mapTime))
    
    // 2. 算法复杂度优化
    fmt.Println("\n2. 算法复杂度优化:")
    
    // 冒泡排序 - O(n²)
    func bubbleSort(slice []int) {
        n := len(slice)
        for i := 0; i < n-1; i++ {
            for j := 0; j < n-i-1; j++ {
                if slice[j] > slice[j+1] {
                    slice[j], slice[j+1] = slice[j+1], slice[j]
                }
            }
        }
    }
    
    // 快速排序 - O(n log n)
    func quickSort(slice []int, low, high int) {
        if low < high {
            pi := partition(slice, low, high)
            quickSort(slice, low, pi-1)
            quickSort(slice, pi+1, high)
        }
    }
    
    func partition(slice []int, low, high int) int {
        pivot := slice[high]
        i := low - 1
        for j := low; j < high; j++ {
            if slice[j] < pivot {
                i++
                slice[i], slice[j] = slice[j], slice[i]
            }
        }
        slice[i+1], slice[high] = slice[high], slice[i+1]
        return i + 1
    }
    
    // 准备测试数据
    bubbleData := make([]int, 1000)
    quickData := make([]int, 1000)
    for i := range bubbleData {
        bubbleData[i] = 1000 - i  // 逆序数据
        quickData[i] = 1000 - i
    }
    
    // 测试冒泡排序
    start = time.Now()
    bubbleSort(bubbleData)
    bubbleTime := time.Since(start)
    
    // 测试快速排序
    start = time.Now()
    quickSort(quickData, 0, len(quickData)-1)
    quickTime := time.Since(start)
    
    fmt.Printf("  Bubble sort: %v\n", bubbleTime)
    fmt.Printf("  Quick sort: %v\n", quickTime)
    fmt.Printf("  Quick sort improvement: %.2fx\n", float64(bubbleTime)/float64(quickTime))
}

// 并发优化技巧
func demonstrateConcurrencyOptimization() {
    fmt.Println("\n=== 并发优化技巧 ===")
    
    // 1. 减少锁竞争
    fmt.Println("1. 减少锁竞争:")
    
    // 高锁竞争版本
    type Counter struct {
        mu    sync.Mutex
        count int64
    }
    
    func (c *Counter) Increment() {
        c.mu.Lock()
        c.count++
        c.mu.Unlock()
    }
    
    func (c *Counter) Get() int64 {
        c.mu.Lock()
        defer c.mu.Unlock()
        return c.count
    }
    
    // 低锁竞争版本（使用原子操作）
    type AtomicCounter struct {
        count int64
    }
    
    func (ac *AtomicCounter) Increment() int64 {
        return atomic.AddInt64(&ac.count, 1)
    }
    
    func (ac *AtomicCounter) Get() int64 {
        return atomic.LoadInt64(&ac.count)
    }
    
    // 测试高锁竞争
    counter := &Counter{}
    start := time.Now()
    
    var wg sync.WaitGroup
    for i := 0; i < 1000; i++ {
        wg.Add(1)
        go func() {
            defer wg.Done()
            for j := 0; j < 1000; j++ {
                counter.Increment()
            }
        }()
    }
    wg.Wait()
    
    mutexTime := time.Since(start)
    fmt.Printf("  Mutex counter time: %v\n", mutexTime)
    fmt.Printf("  Mutex counter final: %d\n", counter.Get())
    
    // 测试低锁竞争
    atomicCounter := &AtomicCounter{}
    start = time.Now()
    
    var wg2 sync.WaitGroup
    for i := 0; i < 1000; i++ {
        wg2.Add(1)
        go func() {
            defer wg2.Done()
            for j := 0; j < 1000; j++ {
                atomicCounter.Increment()
            }
        }()
    }
    wg2.Wait()
    
    atomicTime := time.Since(start)
    fmt.Printf("  Atomic counter time: %v\n", atomicTime)
    fmt.Printf("  Atomic counter final: %d\n", atomicCounter.Get())
    fmt.Printf("  Atomic improvement: %.2fx\n", float64(mutexTime)/float64(atomicTime))
    
    // 2. 工作池模式
    fmt.Println("\n2. 工作池模式:")
    
    type Job struct {
        ID   int
        Data int
    }
    
    type Result struct {
        JobID int
        Value int
    }
    
    // 不使用工作池
    start = time.Now()
    var results []Result
    for i := 0; i < 10000; i++ {
        result := Result{
            JobID: i,
            Value: i * 2,
        }
        results = append(results, result)
    }
    noPoolTime := time.Since(start)
    
    // 使用工作池
    jobQueue := make(chan Job, 100)
    resultQueue := make(chan Result, 100)
    
    // 启动工作goroutine
    var workerWg sync.WaitGroup
    for i := 0; i < 10; i++ {
        workerWg.Add(1)
        go func() {
            defer workerWg.Done()
            for job := range jobQueue {
                result := Result{
                    JobID: job.ID,
                    Value: job.Data * 2,
                }
                resultQueue <- result
            }
        }()
    }
    
    // 启动结果收集goroutine
    var collectorWg sync.WaitGroup
    collectorWg.Add(1)
    go func() {
        defer collectorWg.Done()
        count := 0
        for result := range resultQueue {
            _ = result.Value
            count++
            if count >= 10000 {
                break
            }
        }
    }()
    
    start = time.Now()
    // 发送工作
    for i := 0; i < 10000; i++ {
        jobQueue <- Job{ID: i, Data: i}
    }
    close(jobQueue)
    
    workerWg.Wait()
    close(resultQueue)
    collectorWg.Wait()
    
    poolTime := time.Since(start)
    fmt.Printf("  Without work pool: %v\n", noPoolTime)
    fmt.Printf("  With work pool: %v\n", poolTime)
    fmt.Printf("  Work pool improvement: %.2fx\n", float64(noPoolTime)/float64(poolTime))
}

// 编译器优化技巧
func demonstrateCompilerOptimization() {
    fmt.Println("\n=== 编译器优化技巧 ===")
    
    // 1. 内联优化
    fmt.Println("1. 内联优化:")
    
    // 可以内联的小函数
    func add(a, b int) int {
        return a + b
    }
    
    // 不容易内联的大函数
    func complexFunction(a, b int) int {
        sum := 0
        for i := 0; i < 1000; i++ {
            sum += a + b + i
        }
        return sum
    }
    
    // 测试内联效果
    start := time.Now()
    for i := 0; i < 10000000; i++ {
        _ = add(i, i+1)
    }
    inlineTime := time.Since(start)
    
    start = time.Now()
    for i := 0; i < 10000000; i++ {
        _ = complexFunction(i, i+1)
    }
    noInlineTime := time.Since(start)
    
    fmt.Printf("  Inline function time: %v\n", inlineTime)
    fmt.Printf("  No inline function time: %v\n", noInlineTime)
    
    // 2. 逃逸分析优化
    fmt.Println("\n2. 逃逸分析优化:")
    
    // 会逃逸的函数
    func escapeFunction() *int {
        x := 42
        return &x
    }
    
    // 不会逃逸的函数
    func noEscapeFunction() int {
        x := 42
        return x
    }
    
    // 测试逃逸影响
    start = time.Now()
    for i := 0; i < 1000000; i++ {
        _ = *escapeFunction()
    }
    escapeTime := time.Since(start)
    
    start = time.Now()
    for i := 0; i < 1000000; i++ {
        _ = noEscapeFunction()
    }
    noEscapeTime := time.Since(start)
    
    fmt.Printf("  Escape function time: %v\n", escapeTime)
    fmt.Printf("  No escape function time: %v\n", noEscapeTime)
    fmt.Printf("  Escape overhead: %.2fx\n", float64(escapeTime)/float64(noEscapeTime))
}

// 性能监控和分析
func demonstratePerformanceMonitoring() {
    fmt.Println("\n=== 性能监控和分析 ===")
    
    // 1. 内存使用监控
    fmt.Println("1. 内存使用监控:")
    
    var m1, m2 runtime.MemStats
    runtime.ReadMemStats(&m1)
    
    // 执行一些操作
    data := make([][]int, 1000)
    for i := range data {
        data[i] = make([]int, 1000)
    }
    
    runtime.ReadMemStats(&m2)
    
    fmt.Printf("  Memory allocated: %d KB\n", (m2.TotalAlloc-m1.TotalAlloc)/1024)
    fmt.Printf("  Objects allocated: %d\n", m2.Mallocs-m1.Mallocs)
    fmt.Printf("  Current heap usage: %d KB\n", m2.HeapAlloc/1024)
    
    // 2. GC影响分析
    fmt.Println("\n2. GC影响分析:")
    
    fmt.Printf("  GC cycles: %d\n", m2.NumGC-m1.NumGC)
    fmt.Printf("  GC pause time: %v\n", time.Duration(m2.PauseTotalNs-m1.PauseTotalNs))
    fmt.Printf("  GC CPU fraction: %.2f%%\n", (m2.GCCPUFraction-m1.GCCPUFraction)*100)
    
    // 3. 性能基准测试
    fmt.Println("\n3. 性能基准测试:")
    
    // 使用testing包进行基准测试
    fmt.Println("  Use 'go test -bench=.' for benchmarking")
    fmt.Println("  Use 'go test -bench=. -benchmem' for memory analysis")
    fmt.Println("  Use 'go test -bench=. -cpuprofile=cpu.prof' for CPU profiling")
    fmt.Println("  Use 'go test -bench=. -memprofile=mem.prof' for memory profiling")
}

// 性能优化最佳实践
func performanceOptimizationBestPractices() {
    fmt.Println("\n=== 性能优化最佳实践 ===")
    
    fmt.Println("1. 性能分析:")
    fmt.Println("   - 使用pprof进行性能分析")
    fmt.Println("   - 监控内存分配和GC")
    fmt.Println("   - 分析CPU使用模式")
    fmt.Println("   - 识别性能瓶颈")
    
    fmt.Println("\n2. 内存优化:")
    fmt.Println("   - 预分配切片和映射容量")
    fmt.Println("   - 使用对象池重用对象")
    fmt.Println("   - 避免不必要的内存分配")
    fmt.Println("   - 选择合适的数据结构")
    
    fmt.Println("\n3. 算法优化:")
    fmt.Println("   - 选择合适的时间复杂度")
    fmt.Println("   - 优化数据访问模式")
    fmt.Println("   - 减少不必要的计算")
    fmt.Println("   - 使用缓存和预计算")
    
    fmt.Println("\n4. 并发优化:")
    fmt.Println("   - 减少锁竞争")
    fmt.Println("   - 使用无锁数据结构")
    fmt.Println("   - 合理使用goroutine")
    fmt.Println("   - 使用工作池模式")
    
    fmt.Println("\n5. 编译器优化:")
    fmt.Println("   - 编写可内联的函数")
    fmt.Println("   - 避免不必要的逃逸")
    fmt.Println("   - 使用编译器优化标志")
    fmt.Println("   - 理解编译器行为")
    
    fmt.Println("\n6. 测试和验证:")
    fmt.Println("   - 编写基准测试")
    fmt.Println("   - 进行A/B测试")
    fmt.Println("   - 监控生产环境性能")
    fmt.Println("   - 定期性能回归测试")
    
    fmt.Println("\n7. 工具使用:")
    fmt.Println("   - go tool pprof")
    fmt.Println("   - go tool trace")
    fmt.Println("   - runtime/pprof包")
    fmt.Println("   - net/http/pprof包")
    
    fmt.Println("\n8. 常见陷阱:")
    fmt.Println("   - 过早优化")
    fmt.Println("   - 忽视内存分配")
    fmt.Println("   - 不合理的并发使用")
    fmt.Println("   - 忽视GC影响")
}

func main() {
    demonstrateBasicOptimization()
    demonstrateMemoryOptimization()
    demonstrateAlgorithmOptimization()
    demonstrateConcurrencyOptimization()
    demonstrateCompilerOptimization()
    demonstratePerformanceMonitoring()
    performanceOptimizationBestPractices()
}
```

### 内存泄漏检测

```go
package main

import (
    "fmt"
    "net/http"
    "_net/http/pprof"
    "runtime"
    "sync"
    "time"
)

// 内存泄漏检测基础
func demonstrateMemoryLeakDetection() {
    fmt.Println("=== 内存泄漏检测 ===")
    
    // 1. 使用runtime包监控内存
    fmt.Println("1. 使用runtime包监控内存:")
    
    var m1, m2 runtime.MemStats
    runtime.ReadMemStats(&m1)
    
    // 模拟内存泄漏
    leakyData := make(map[string][]byte)
    for i := 0; i < 10000; i++ {
        key := fmt.Sprintf("key_%d", i)
        leakyData[key] = make([]byte, 1024)  // 分配内存但不释放
    }
    
    runtime.ReadMemStats(&m2)
    
    fmt.Printf("  Memory allocated: %d KB\n", (m2.TotalAlloc-m1.TotalAlloc)/1024)
    fmt.Printf("  Heap objects: %d\n", m2.HeapObjects-m1.HeapObjects)
    fmt.Printf("  Heap allocated: %d KB\n", (m2.HeapAlloc-m1.HeapAlloc)/1024)
    
    // 2. 监控goroutine泄漏
    fmt.Println("\n2. 监控goroutine泄漏:")
    
    initialGoroutines := runtime.NumGoroutine()
    fmt.Printf("  Initial goroutines: %d\n", initialGoroutines)
    
    // 启动一些goroutine但不正确关闭
    for i := 0; i < 100; i++ {
        go func(id int) {
            for {
                time.Sleep(time.Second)  // 永远不退出的goroutine
                _ = id
            }
        }(i)
    }
    
    time.Sleep(100 * time.Millisecond)  // 给goroutine时间启动
    currentGoroutines := runtime.NumGoroutine()
    fmt.Printf("  Current goroutines: %d\n", currentGoroutines)
    fmt.Printf("  Leaked goroutines: %d\n", currentGoroutines-initialGoroutines)
}

// 使用pprof检测内存泄漏
func demonstratePprofDetection() {
    fmt.Println("\n=== 使用pprof检测内存泄漏 ===")
    
    // 启动pprof服务器
    go func() {
        http.ListenAndServe(":6060", nil)
    }()
    
    fmt.Println("  pprof server started on :6060")
    fmt.Println("  Use 'go tool pprof http://localhost:6060/debug/pprof/heap' to analyze")
    fmt.Println("  Use 'go tool pprof http://localhost:6060/debug/pprof/goroutine' to analyze goroutines")
    
    // 模拟内存泄漏以供分析
    leakyMap := make(map[string]*LeakyObject)
    
    for i := 0; i < 10000; i++ {
        key := fmt.Sprintf("object_%d", i)
        leakyMap[key] = &LeakyObject{
            Data: make([]byte, 1024),
            ID:   i,
        }
    }
    
    fmt.Printf("  Created %d leaky objects\n", len(leakyMap))
}

type LeakyObject struct {
    Data []byte
    ID   int
}

// 常见内存泄漏模式
func demonstrateCommonLeakPatterns() {
    fmt.Println("\n=== 常见内存泄漏模式 ===")
    
    // 1. 循环引用
    fmt.Println("1. 循环引用:")
    
    type Node struct {
        Value    int
        Children []*Node
        Parent   *Node  // 可能导致循环引用
    }
    
    // 创建循环引用
    parent := &Node{Value: 1}
    child := &Node{Value: 2, Parent: parent}
    parent.Children = append(parent.Children, child)
    
    // 如果不正确处理，可能导致内存泄漏
    fmt.Printf("  Created circular reference: parent(%d) -> child(%d) -> parent(%d)\n", 
        parent.Value, child.Value, child.Parent.Value)
    
    // 2. 未关闭的资源
    fmt.Println("\n2. 未关闭的资源:")
    
    // 模拟未关闭的HTTP客户端
    for i := 0; i < 100; i++ {
        client := &http.Client{
            Timeout: 30 * time.Second,
        }
        // 忘记关闭或正确管理client
        _ = client  // 模拟泄漏
    }
    
    fmt.Println("  Simulated HTTP client leak")
    
    // 3. 定时器泄漏
    fmt.Println("\n3. 定时器泄漏:")
    
    // 泄漏的定时器
    for i := 0; i < 100; i++ {
        timer := time.AfterFunc(time.Hour, func() {
            fmt.Println("Timer fired")
        })
        // 忘记调用timer.Stop()
        _ = timer  // 模拟泄漏
    }
    
    fmt.Println("  Simulated timer leak")
    
    // 4. channel泄漏
    fmt.Println("\n4. Channel泄漏:")
    
    // 未消费的channel
    for i := 0; i < 100; i++ {
        ch := make(chan int, 10)
        ch <- 42  // 发送但不消费
        _ = ch    // 模拟泄漏
    }
    
    fmt.Println("  Simulated channel leak")
}

// 内存泄漏检测工具
func demonstrateLeakDetectionTools() {
    fmt.Println("\n=== 内存泄漏检测工具 ===")
    
    fmt.Println("1. 内置工具:")
    fmt.Println("   - runtime.ReadMemStats() - 读取内存统计")
    fmt.Println("   - runtime.NumGoroutine() - goroutine数量")
    fmt.Println("   - runtime.GC() - 手动触发GC")
    fmt.Println("   - debug.FreeOSMemory() - 释放系统内存")
    
    fmt.Println("\n2. pprof工具:")
    fmt.Println("   - go tool pprof - 分析CPU和内存")
    fmt.Println("   - go tool trace - 分析执行跟踪")
    fmt.Println("   - web界面: http://localhost:6060/debug/pprof/")
    
    fmt.Println("\n3. 第三方工具:")
    fmt.Println("   - goleak - 检测goroutine泄漏")
    fmt.Println("   - memviz - 内存可视化")
    fmt.Println("   - fgprof - 细粒度性能分析")
    
    // 示例：使用runtime监控
    var before, after runtime.MemStats
    runtime.ReadMemStats(&before)
    
    // 执行一些操作
    data := make([][]int, 1000)
    for i := range data {
        data[i] = make([]int, 100)
    }
    
    runtime.ReadMemStats(&after)
    
    fmt.Printf("\nMemory usage analysis:\n")
    fmt.Printf("  Allocated: %d KB\n", (after.TotalAlloc-before.TotalAlloc)/1024)
    fmt.Printf("  Heap objects: %d\n", after.HeapObjects-before.HeapObjects)
    fmt.Printf("  GC cycles: %d\n", after.NumGC-before.NumGC)
}

// goroutine泄漏检测
func demonstrateGoroutineLeakDetection() {
    fmt.Println("\n=== goroutine泄漏检测 ===")
    
    // 1. 手动检测
    fmt.Println("1. 手动检测:")
    
    initialCount := runtime.NumGoroutine()
    fmt.Printf("  Initial goroutines: %d\n", initialCount)
    
    // 启动泄漏的goroutine
    var wg sync.WaitGroup
    for i := 0; i < 10; i++ {
        wg.Add(1)
        go func(id int) {
            defer wg.Done()
            // 模拟长时间运行的goroutine
            time.Sleep(10 * time.Second)
            fmt.Printf("Goroutine %d finished\n", id)
        }(i)
    }
    
    time.Sleep(100 * time.Millisecond)  // 等待goroutine启动
    currentCount := runtime.NumGoroutine()
    fmt.Printf("  Current goroutines: %d\n", currentCount)
    fmt.Printf("  New goroutines: %d\n", currentCount-initialCount)
    
    // 2. 使用第三方库检测 (goleak示例)
    fmt.Println("\n2. 使用第三方库检测:")
    fmt.Println("   // 使用uber-go/goleak检测goroutine泄漏")
    fmt.Println("   // import go.uber.org/goleak")
    fmt.Println("   // defer goleak.VerifyNone(t) // 在测试中使用")
    
    // 3. 自定义泄漏检测
    fmt.Println("\n3. 自定义泄漏检测:")
    
    type LeakDetector struct {
        initialCount int
        timeout      time.Duration
    }
    
    func NewLeakDetector() *LeakDetector {
        return &LeakDetector{
            initialCount: runtime.NumGoroutine(),
            timeout:      5 * time.Second,
        }
    }
    
    func (ld *LeakDetector) Check() error {
        time.Sleep(ld.timeout)
        currentCount := runtime.NumGoroutine()
        if currentCount > ld.initialCount {
            return fmt.Errorf("potential goroutine leak: %d -> %d", 
                ld.initialCount, currentCount)
        }
        return nil
    }
    
    detector := NewLeakDetector()
    go func() {
        time.Sleep(2 * time.Second)
    }()
    
    if err := detector.Check(); err != nil {
        fmt.Printf("  %v\n", err)
    } else {
        fmt.Println("  No goroutine leak detected")
    }
    
    wg.Wait()  // 等待所有goroutine完成
}

// 内存泄漏预防
func demonstrateLeakPrevention() {
    fmt.Println("\n=== 内存泄漏预防 ===")
    
    // 1. 使用defer确保资源释放
    fmt.Println("1. 使用defer确保资源释放:")
    
    func processFile(filename string) error {
        file, err := os.Open(filename)
        if err != nil {
            return err
        }
        defer file.Close()  // 确保文件关闭
        
        // 处理文件...
        return nil
    }
    
    // 2. 正确管理channel
    fmt.Println("\n2. 正确管理channel:")
    
    func properChannelUsage() {
        ch := make(chan int, 10)
        
        // 发送者
        go func() {
            defer close(ch)  // 确保channel关闭
            for i := 0; i < 5; i++ {
                ch <- i
            }
        }()
        
        // 接收者
        for value := range ch {
            fmt.Printf("Received: %d\n", value)
        }
    }
    
    properChannelUsage()
    
    // 3. 正确管理定时器
    fmt.Println("\n3. 正确管理定时器:")
    
    func properTimerUsage() {
        timer := time.NewTimer(5 * time.Second)
        defer timer.Stop()  // 确保定时器停止
        
        select {
        case <-timer.C:
            fmt.Println("Timer fired")
        case <-time.After(3 * time.Second):
            fmt.Println("Cancelled")
            return
        }
    }
    
    properTimerUsage()
    
    // 4. 使用context管理生命周期
    fmt.Println("\n4. 使用context管理生命周期:")
    
    func contextManagedFunction(ctx context.Context) {
        ticker := time.NewTicker(time.Second)
        defer ticker.Stop()
        
        for {
            select {
            case <-ctx.Done():
                fmt.Println("Function cancelled")
                return
            case <-ticker.C:
                fmt.Println("Tick")
            }
        }
    }
    
    ctx, cancel := context.WithTimeout(context.Background(), 3*time.Second)
    defer cancel()
    
    go contextManagedFunction(ctx)
    time.Sleep(4 * time.Second)
}

// 内存泄漏测试
func demonstrateLeakTesting() {
    fmt.Println("\n=== 内存泄漏测试 ===")
    
    // 1. 基准测试中的泄漏检测
    fmt.Println("1. 基准测试中的泄漏检测:")
    
    fmt.Println("   func BenchmarkNoLeak(b *testing.B) {")
    fmt.Println("       b.ReportAllocs()")
    fmt.Println("       for i := 0; i < b.N; i++ {")
    fmt.Println("           // 测试代码，应该不产生内存泄漏")
    fmt.Println("       }")
    fmt.Println("   }")
    
    // 2. 集成测试中的泄漏检测
    fmt.Println("\n2. 集成测试中的泄漏检测:")
    
    fmt.Println("   func TestNoGoroutineLeak(t *testing.T) {")
    fmt.Println("       defer goleak.VerifyNone(t)")
    fmt.Println("       // 测试代码")
    fmt.Println("   }")
    
    // 3. 生产环境监控
    fmt.Println("\n3. 生产环境监控:")
    
    // 启动内存监控goroutine
    go func() {
        ticker := time.NewTicker(30 * time.Second)
        defer ticker.Stop()
        
        for range ticker.C {
            var m runtime.MemStats
            runtime.ReadMemStats(&m)
            
            // 检查内存使用是否异常
            if m.Alloc > 100*1024*1024 {  // 超过100MB
                fmt.Printf("WARNING: High memory usage: %d MB\n", m.Alloc/1024/1024)
            }
            
            // 检查goroutine数量是否异常
            if runtime.NumGoroutine() > 10000 {
                fmt.Printf("WARNING: High goroutine count: %d\n", runtime.NumGoroutine())
            }
        }
    }()
    
    fmt.Println("  Started production memory monitoring")
}

// 内存泄漏最佳实践
func memoryLeakBestPractices() {
    fmt.Println("\n=== 内存泄漏最佳实践 ===")
    
    fmt.Println("1. 资源管理:")
    fmt.Println("   - 始终使用defer关闭资源")
    fmt.Println("   - 正确管理文件、网络连接、数据库连接")
    fmt.Println("   - 使用context管理请求生命周期")
    fmt.Println("   - 及时关闭HTTP客户端和服务器")
    
    fmt.Println("\n2. goroutine管理:")
    fmt.Println("   - 避免启动无法控制的goroutine")
    fmt.Println("   - 使用context取消长时间运行的goroutine")
    fmt.Println("   - 正确关闭channel")
    fmt.Println("   - 及时停止定时器")
    
    fmt.Println("\n3. 数据结构管理:")
    fmt.Println("   - 避免循环引用")
    fmt.Println("   - 及时清理缓存")
    fmt.Println("   - 使用对象池重用对象")
    fmt.Println("   - 正确管理映射和切片的生命周期")
    
    fmt.Println("\n4. 监控和测试:")
    fmt.Println("   - 定期监控内存使用")
    fmt.Println("   - 使用pprof分析内存")
    fmt.Println("   - 编写泄漏检测测试")
    fmt.Println("   - 在生产环境启用监控")
    
    fmt.Println("\n5. 工具使用:")
    fmt.Println("   - runtime包监控内存和goroutine")
    fmt.Println("   - pprof进行深入分析")
    fmt.Println("   - 第三方工具如goleak")
    fmt.Println("   - 自定义监控和告警")
    
    fmt.Println("\n6. 常见陷阱:")
    fmt.Println("   - 忘记关闭资源")
    fmt.Println("   - goroutine无法退出")
    fmt.Println("   - channel未正确关闭")
    fmt.Println("   - 定时器未停止")
    fmt.Println("   - 循环引用导致GC无法回收")
}

func main() {
    demonstrateMemoryLeakDetection()
    demonstratePprofDetection()
    demonstrateCommonLeakPatterns()
    demonstrateLeakDetectionTools()
    demonstrateGoroutineLeakDetection()
    demonstrateLeakPrevention()
    demonstrateLeakTesting()
    memoryLeakBestPractices()
}
```

### 内存对齐

```go
package main

import (
    "fmt"
    "unsafe"
)

// 内存对齐基础
func demonstrateMemoryAlignment() {
    fmt.Println("=== 内存对齐 ===")
    
    // 1. 基本数据类型对齐
    fmt.Println("1. 基本数据类型对齐:")
    
    fmt.Printf("  bool size: %d, alignment: %d\n", 
        unsafe.Sizeof(bool(false)), unsafe.Alignof(bool(false)))
    fmt.Printf("  int8 size: %d, alignment: %d\n", 
        unsafe.Sizeof(int8(0)), unsafe.Alignof(int8(0)))
    fmt.Printf("  int16 size: %d, alignment: %d\n", 
        unsafe.Sizeof(int16(0)), unsafe.Alignof(int16(0)))
    fmt.Printf("  int32 size: %d, alignment: %d\n", 
        unsafe.Sizeof(int32(0)), unsafe.Alignof(int32(0)))
    fmt.Printf("  int64 size: %d, alignment: %d\n", 
        unsafe.Sizeof(int64(0)), unsafe.Alignof(int64(0)))
    fmt.Printf("  float32 size: %d, alignment: %d\n", 
        unsafe.Sizeof(float32(0)), unsafe.Alignof(float32(0)))
    fmt.Printf("  float64 size: %d, alignment: %d\n", 
        unsafe.Sizeof(float64(0)), unsafe.Alignof(float64(0)))
    fmt.Printf("  pointer size: %d, alignment: %d\n", 
        unsafe.Sizeof((*int)(nil)), unsafe.Alignof((*int)(nil)))
    
    // 2. 结构体对齐
    fmt.Println("\n2. 结构体对齐:")
    
    type BadStruct struct {
        b bool    // 1 byte
        i int64   // 8 bytes
        s int16   // 2 bytes
    }
    
    type GoodStruct struct {
        i int64   // 8 bytes
        s int16   // 2 bytes
        b bool    // 1 byte
    }
    
    fmt.Printf("  BadStruct size: %d bytes\n", unsafe.Sizeof(BadStruct{}))
    fmt.Printf("  GoodStruct size: %d bytes\n", unsafe.Sizeof(GoodStruct{}))
    
    // 显示结构体字段偏移
    fmt.Println("\n  BadStruct field offsets:")
    fmt.Printf("    b: offset %d\n", unsafe.Offsetof(BadStruct{}.b))
    fmt.Printf("    i: offset %d\n", unsafe.Offsetof(BadStruct{}.i))
    fmt.Printf("    s: offset %d\n", unsafe.Offsetof(BadStruct{}.s))
    
    fmt.Println("\n  GoodStruct field offsets:")
    fmt.Printf("    i: offset %d\n", unsafe.Offsetof(GoodStruct{}.i))
    fmt.Printf("    s: offset %d\n", unsafe.Offsetof(GoodStruct{}.s))
    fmt.Printf("    b: offset %d\n", unsafe.Offsetof(GoodStruct{}.b))
    
    // 3. 数组对齐
    fmt.Println("\n3. 数组对齐:")
    
    var arr1 [3]int8
    var arr2 [3]int16
    var arr3 [3]int32
    var arr4 [3]int64
    
    fmt.Printf("  [3]int8 size: %d, alignment: %d\n", 
        unsafe.Sizeof(arr1), unsafe.Alignof(arr1))
    fmt.Printf("  [3]int16 size: %d, alignment: %d\n", 
        unsafe.Sizeof(arr2), unsafe.Alignof(arr2))
    fmt.Printf("  [3]int32 size: %d, alignment: %d\n", 
        unsafe.Sizeof(arr3), unsafe.Alignof(arr3))
    fmt.Printf("  [3]int64 size: %d, alignment: %d\n", 
        unsafe.Sizeof(arr4), unsafe.Alignof(arr4))
}

// 结构体优化示例
func demonstrateStructOptimization() {
    fmt.Println("\n=== 结构体优化示例 ===")
    
    // 未优化的结构体
    type Unoptimized struct {
        a bool    // 1 byte
        b int32   // 4 bytes
        c bool    // 1 byte
        d int64   // 8 bytes
        e int8    // 1 byte
    }
    
    // 优化后的结构体
    type Optimized struct {
        d int64   // 8 bytes
        b int32   // 4 bytes
        a bool    // 1 byte
        c bool    // 1 byte
        e int8    // 1 byte
    }
    
    fmt.Printf("Unoptimized struct size: %d bytes\n", unsafe.Sizeof(Unoptimized{}))
    fmt.Printf("Optimized struct size: %d bytes\n", unsafe.Sizeof(Optimized{}))
    
    // 显示字段布局
    fmt.Println("\nUnoptimized struct layout:")
    u := Unoptimized{}
    fmt.Printf("  a (bool): offset %d\n", unsafe.Offsetof(u.a))
    fmt.Printf("  b (int32): offset %d\n", unsafe.Offsetof(u.b))
    fmt.Printf("  c (bool): offset %d\n", unsafe.Offsetof(u.c))
    fmt.Printf("  d (int64): offset %d\n", unsafe.Offsetof(u.d))
    fmt.Printf("  e (int8): offset %d\n", unsafe.Offsetof(u.e))
    
    fmt.Println("\nOptimized struct layout:")
    o := Optimized{}
    fmt.Printf("  d (int64): offset %d\n", unsafe.Offsetof(o.d))
    fmt.Printf("  b (int32): offset %d\n", unsafe.Offsetof(o.b))
    fmt.Printf("  a (bool): offset %d\n", unsafe.Offsetof(o.a))
    fmt.Printf("  c (bool): offset %d\n", unsafe.Offsetof(o.c))
    fmt.Printf("  e (int8): offset %d\n", unsafe.Offsetof(o.e))
    
    // 计算节省的内存
    sizeDiff := unsafe.Sizeof(Unoptimized{}) - unsafe.Sizeof(Optimized{})
    fmt.Printf("\nMemory saved per struct: %d bytes\n", sizeDiff)
    
    // 如果创建100万个实例
    instances := 1000000
    totalSaved := int64(sizeDiff) * int64(instances)
    fmt.Printf("Memory saved for %d instances: %d KB\n", instances, totalSaved/1024)
}

// 内存对齐优化技巧
func demonstrateAlignmentOptimization() {
    fmt.Println("\n=== 内存对齐优化技巧 ===")
    
    // 1. 字段排序优化
    fmt.Println("1. 字段排序优化:")
    
    // 按大小降序排列字段
    type SortedStruct struct {
        large  [16]byte  // 16 bytes
        medium int64     // 8 bytes
        small  int32     // 4 bytes
        tiny   bool      // 1 byte
    }
    
    type UnsortedStruct struct {
        tiny   bool      // 1 byte
        medium int64     // 8 bytes (需要填充7字节)
        small  int32     // 4 bytes
        large  [16]byte  // 16 bytes
    }
    
    fmt.Printf("  Sorted struct size: %d bytes\n", unsafe.Sizeof(SortedStruct{}))
    fmt.Printf("  Unsorted struct size: %d bytes\n", unsafe.Sizeof(UnsortedStruct{}))
    
    // 2. 使用padding显式控制对齐
    fmt.Println("\n2. 使用padding显式控制对齐:")
    
    type ExplicitPadding struct {
        a bool      // 1 byte
        _ [7]byte   // 显式填充到8字节边界
        b int64     // 8 bytes
        c int32     // 4 bytes
        _ [4]byte   // 显式填充到8字节边界
        d int64     // 8 bytes
    }
    
    type AutomaticPadding struct {
        a bool      // 1 byte
        b int64     // 8 bytes (自动填充7字节)
        c int32     // 4 bytes
        d int64     // 8 bytes (自动填充4字节)
    }
    
    fmt.Printf("  Explicit padding size: %d bytes\n", unsafe.Sizeof(ExplicitPadding{}))
    fmt.Printf("  Automatic padding size: %d bytes\n", unsafe.Sizeof(AutomaticPadding{}))
    
    // 3. 嵌套结构体对齐
    fmt.Println("\n3. 嵌套结构体对齐:")
    
    type Inner struct {
        x int8
        y int32
    }
    
    type Outer struct {
        inner Inner
        z     int64
    }
    
    type OptimizedOuter struct {
        z     int64
        inner Inner
    }
    
    fmt.Printf("  Inner struct size: %d bytes\n", unsafe.Sizeof(Inner{}))
    fmt.Printf("  Outer struct size: %d bytes\n", unsafe.Sizeof(Outer{}))
    fmt.Printf("  Optimized outer size: %d bytes\n", unsafe.Sizeof(OptimizedOuter{}))
}

// 对齐和性能影响
func demonstrateAlignmentPerformance() {
    fmt.Println("\n=== 对齐和性能影响 ===")
    
    // 1. 对齐对访问性能的影响
    fmt.Println("1. 对齐对访问性能的影响:")
    
    const size = 1000000
    
    // 对齐的数组
    aligned := make([]int64, size)
    
    // 非对齐的访问（通过指针运算模拟）
    start := time.Now()
    for i := 0; i < size; i++ {
        aligned[i] = int64(i)
    }
    alignedTime := time.Since(start)
    
    fmt.Printf("  Aligned access time: %v\n", alignedTime)
    
    // 2. 结构体对齐对缓存的影响
    fmt.Println("\n2. 结构体对齐对缓存的影响:")
    
    type CacheUnfriendly struct {
        a bool
        b int64
        c bool
        d int64
    }
    
    type CacheFriendly struct {
        b int64
        d int64
        a bool
        c bool
    }
    
    // 创建数组进行测试
    unfriendly := make([]CacheUnfriendly, 100000)
    friendly := make([]CacheFriendly, 100000)
    
    // 测试访问性能
    start = time.Now()
    for i := range unfriendly {
        unfriendly[i].b = int64(i)
        unfriendly[i].d = int64(i * 2)
    }
    unfriendlyTime := time.Since(start)
    
    start = time.Now()
    for i := range friendly {
        friendly[i].b = int64(i)
        friendly[i].d = int64(i * 2)
    }
    friendlyTime := time.Since(start)
    
    fmt.Printf("  Cache unfriendly time: %v\n", unfriendlyTime)
    fmt.Printf("  Cache friendly time: %v\n", friendlyTime)
    fmt.Printf("  Performance improvement: %.2fx\n", 
        float64(unfriendlyTime)/float64(friendlyTime))
}

// 对齐工具和分析
func demonstrateAlignmentTools() {
    fmt.Println("\n=== 对齐工具和分析 ===")
    
    // 1. 使用unsafe包分析对齐
    fmt.Println("1. 使用unsafe包分析对齐:")
    
    type AnalysisStruct struct {
        a bool
        b int32
        c int64
        d float32
        e string
    }
    
    s := AnalysisStruct{}
    fmt.Printf("Struct analysis:\n")
    fmt.Printf("  Total size: %d bytes\n", unsafe.Sizeof(s))
    fmt.Printf("  Alignment: %d bytes\n", unsafe.Alignof(s))
    fmt.Printf("  Field 'a' (bool): offset %d, size %d\n", 
        unsafe.Offsetof(s.a), unsafe.Sizeof(s.a))
    fmt.Printf("  Field 'b' (int32): offset %d, size %d\n", 
        unsafe.Offsetof(s.b), unsafe.Sizeof(s.b))
    fmt.Printf("  Field 'c' (int64): offset %d, size %d\n", 
        unsafe.Offsetof(s.c), unsafe.Sizeof(s.c))
    fmt.Printf("  Field 'd' (float32): offset %d, size %d\n", 
        unsafe.Offsetof(s.d), unsafe.Sizeof(s.d))
    fmt.Printf("  Field 'e' (string): offset %d, size %d\n", 
        unsafe.Offsetof(s.e), unsafe.Sizeof(s.e))
    
    // 2. 计算填充字节
    fmt.Println("\n2. 计算填充字节:")
    
    type PaddedStruct struct {
        a bool    // 1 byte
        b int32   // 4 bytes (需要3字节填充)
        c int64   // 8 bytes
    }
    
    p := PaddedStruct{}
    totalSize := unsafe.Sizeof(p)
    fieldSizes := unsafe.Sizeof(p.a) + unsafe.Sizeof(p.b) + unsafe.Sizeof(p.c)
    padding := totalSize - fieldSizes
    
    fmt.Printf("  Total size: %d bytes\n", totalSize)
    fmt.Printf("  Field sizes: %d bytes\n", fieldSizes)
    fmt.Printf("  Padding bytes: %d bytes\n", padding)
    
    // 3. 对齐建议
    fmt.Println("\n3. 对齐建议:")
    
    type RecommendedStruct struct {
        // 按大小降序排列
        largeField  [16]byte  // 16 bytes
        int64Field  int64     // 8 bytes
        int32Field  int32     // 4 bytes
        int16Field  int16     // 2 bytes
        byteField   byte      // 1 byte
    }
    
    r := RecommendedStruct{}
    fmt.Printf("  Recommended struct size: %d bytes\n", unsafe.Sizeof(r))
    fmt.Printf("  Field offsets: a(%d), b(%d), c(%d), d(%d), e(%d)\n",
        unsafe.Offsetof(r.largeField),
        unsafe.Offsetof(r.int64Field),
        unsafe.Offsetof(r.int32Field),
        unsafe.Offsetof(r.int16Field),
        unsafe.Offsetof(r.byteField))
}

// 对齐最佳实践
func alignmentBestPractices() {
    fmt.Println("\n=== 对齐最佳实践 ===")
    
    fmt.Println("1. 字段排序:")
    fmt.Println("   - 按字段大小降序排列")
    fmt.Println("   - 64位字段优先")
    fmt.Println("   - 32位字段次之")
    fmt.Println("   - 16位和8位字段最后")
    
    fmt.Println("\n2. 结构体设计:")
    fmt.Println("   - 考虑缓存行大小（通常64字节）")
    fmt.Println("   - 避免跨缓存行访问")
    fmt.Println("   - 合理分组相关字段")
    fmt.Println("   - 考虑数组元素的对齐")
    
    fmt.Println("\n3. 性能考虑:")
    fmt.Println("   - 对齐可以提高访问速度")
    fmt.Println("   - 减少内存使用")
    fmt.Println("   - 改善缓存局部性")
    fmt.Println("   - 但不要过度优化")
    
    fmt.Println("\n4. 工具使用:")
    fmt.Println("   - unsafe.Sizeof() 检查大小")
    fmt.Println("   - unsafe.Alignof() 检查对齐")
    fmt.Println("   - unsafe.Offsetof() 检查偏移")
    fmt.Println("   - go vet 检查潜在问题")
    
    fmt.Println("\n5. 权衡考虑:")
    fmt.Println("   - 代码可读性 vs 内存效率")
    fmt.Println("   - 维护性 vs 性能")
    fmt.Println("   - 不同架构的对齐要求")
    fmt.Println("   - 编译器优化的影响")
    
    fmt.Println("\n6. 常见模式:")
    fmt.Println("   - 布尔字段分组放置")
    fmt.Println("   - 相关字段分组")
    fmt.Println("   - 大字段优先")
    fmt.Println("   - 避免不必要的填充")
}

func main() {
    demonstrateMemoryAlignment()
    demonstrateStructOptimization()
    demonstrateAlignmentOptimization()
    demonstrateAlignmentPerformance()
    demonstrateAlignmentTools()
    alignmentBestPractices()
}
```

### 栈和堆分配

```go
package main

import (
    "fmt"
    "runtime"
    "sync"
    "time"
    "unsafe"
)

// 栈和堆分配基础
func demonstrateStackHeapAllocation() {
    fmt.Println("=== 栈和堆分配 ===")
    
    // 1. 栈分配示例
    fmt.Println("1. 栈分配示例:")
    
    func stackAllocation() {
        x := 42        // 栈分配
        y := 3.14      // 栈分配
        arr := [10]int{1, 2, 3, 4, 5, 6, 7, 8, 9, 10}  // 栈分配
        
        fmt.Printf("  Stack variables - x: %d, y: %f, arr[0]: %d\n", x, y, arr[0])
        fmt.Printf("  Stack addresses - x: %p, y: %p, arr: %p\n", &x, &y, &arr)
    }
    
    stackAllocation()
    
    // 2. 堆分配示例
    fmt.Println("\n2. 堆分配示例:")
    
    func heapAllocation() *int {
        x := 42  // 逃逸到堆
        return &x
    }
    
    ptr := heapAllocation()
    fmt.Printf("  Heap allocated value: %d, address: %p\n", *ptr, ptr)
    
    // 3. 切片分配
    fmt.Println("\n3. 切片分配:")
    
    // 小切片 - 可能在栈上
    smallSlice := make([]int, 5)
    fmt.Printf("  Small slice address: %p, len: %d, cap: %d\n", 
        &smallSlice[0], len(smallSlice), cap(smallSlice))
    
    // 大切片 - 在堆上
    largeSlice := make([]int, 10000)
    fmt.Printf("  Large slice address: %p, len: %d, cap: %d\n", 
        &largeSlice[0], len(largeSlice), cap(largeSlice))
}

// 栈分配优化
func demonstrateStackOptimization() {
    fmt.Println("\n=== 栈分配优化 ===")
    
    // 1. 避免逃逸到堆
    fmt.Println("1. 避免逃逸到堆:")
    
    // 逃逸的版本
    func escapeVersion() *int {
        x := 100  // 逃逸到堆
        return &x
    }
    
    // 不逃逸的版本
    func noEscapeVersion() int {
        x := 100  // 栈分配
        return x
    }
    
    start := time.Now()
    for i := 0; i < 1000000; i++ {
        _ = *escapeVersion()
    }
    escapeTime := time.Since(start)
    
    start = time.Now()
    for i := 0; i < 1000000; i++ {
        _ = noEscapeVersion()
    }
    noEscapeTime := time.Since(start)
    
    fmt.Printf("  Escape version time: %v\n", escapeTime)
    fmt.Printf("  No escape version time: %v\n", noEscapeTime)
    fmt.Printf("  Stack allocation improvement: %.2fx\n", 
        float64(escapeTime)/float64(noEscapeTime))
    
    // 2. 栈大小限制
    fmt.Println("\n2. 栈大小限制:")
    
    // 默认栈大小
    fmt.Printf("  Default goroutine stack size: %d KB\n", 
        runtime.MinStack/1024)
    
    // 最大栈大小
    fmt.Printf("  Maximum goroutine stack size: %d MB\n", 
        runtime.MaxStack/(1024*1024))
    
    // 3. 栈增长
    fmt.Println("\n3. 栈增长:")
    
    // 递归函数可能导致栈增长
    func recursiveFunction(n int) int {
        if n <= 0 {
            return 1
        }
        return n * recursiveFunction(n-1)
    }
    
    result := recursiveFunction(10)
    fmt.Printf("  Recursive function result: %d\n", result)
    
    // 深度递归可能导致栈溢出
    fmt.Println("  Note: Very deep recursion can cause stack overflow")
}

// 堆分配管理
func demonstrateHeapManagement() {
    fmt.Println("\n=== 堆分配管理 ===")
    
    // 1. 堆分配监控
    fmt.Println("1. 堆分配监控:")
    
    var m1, m2 runtime.MemStats
    runtime.ReadMemStats(&m1)
    
    // 创建大量堆对象
    heapObjects := make([]*[]int, 10000)
    for i := range heapObjects {
        slice := make([]int, 100)
        heapObjects[i] = &slice
    }
    
    runtime.ReadMemStats(&m2)
    
    fmt.Printf("  Heap allocated: %d KB\n", (m2.HeapAlloc-m1.HeapAlloc)/1024)
    fmt.Printf("  Heap objects: %d\n", m2.HeapObjects-m1.HeapObjects)
    fmt.Printf("  Total allocations: %d KB\n", (m2.TotalAlloc-m1.TotalAlloc)/1024)
    
    // 2. 堆分配优化
    fmt.Println("\n2. 堆分配优化:")
    
    // 使用对象池减少堆分配
    type ReusableObject struct {
        Data [1024]byte
        ID   int
    }
    
    var objectPool = sync.Pool{
        New: func() interface{} {
            return &ReusableObject{}
        },
    }
    
    // 不使用对象池
    start := time.Now()
    for i := 0; i < 100000; i++ {
        obj := &ReusableObject{
            ID: i,
        }
        _ = obj.ID
    }
    noPoolTime := time.Since(start)
    
    // 使用对象池
    start = time.Now()
    for i := 0; i < 100000; i++ {
        obj := objectPool.Get().(*ReusableObject)
        obj.ID = i
        _ = obj.ID
        objectPool.Put(obj)
    }
    poolTime := time.Since(start)
    
    fmt.Printf("  Without pool: %v\n", noPoolTime)
    fmt.Printf("  With pool: %v\n", poolTime)
    fmt.Printf("  Pool improvement: %.2fx\n", float64(noPoolTime)/float64(poolTime))
    
    // 3. 大对象分配
    fmt.Println("\n3. 大对象分配:")
    
    // 小对象 - 可能栈分配
    start = time.Now()
    smallObjects := make([][100]byte, 10000)
    for i := range smallObjects {
        smallObjects[i][0] = byte(i)
    }
    smallTime := time.Since(start)
    
    // 大对象 - 堆分配
    start = time.Now()
    largeObjects := make([][10000]byte, 1000)
    for i := range largeObjects {
        largeObjects[i][0] = byte(i)
    }
    largeTime := time.Since(start)
    
    fmt.Printf("  Small objects allocation: %v\n", smallTime)
    fmt.Printf("  Large objects allocation: %v\n", largeTime)
}

// 栈和堆性能对比
func demonstrateStackHeapPerformance() {
    fmt.Println("\n=== 栈和堆性能对比 ===")
    
    // 1. 分配速度对比
    fmt.Println("1. 分配速度对比:")
    
    // 栈分配
    start := time.Now()
    for i := 0; i < 1000000; i++ {
        x := i  // 栈分配
        _ = x
    }
    stackTime := time.Since(start)
    
    // 堆分配
    start = time.Now()
    for i := 0; i < 1000000; i++ {
        x := new(int)  // 堆分配
        *x = i
    }
    heapTime := time.Since(start)
    
    fmt.Printf("  Stack allocation time: %v\n", stackTime)
    fmt.Printf("  Heap allocation time: %v\n", heapTime)
    fmt.Printf("  Stack is %.2fx faster\n", float64(heapTime)/float64(stackTime))
    
    // 2. 访问速度对比
    fmt.Println("\n2. 访问速度对比:")
    
    // 栈变量访问
    func stackAccess() int {
        x := 42
        sum := 0
        for i := 0; i < 1000000; i++ {
            sum += x
        }
        return sum
    }
    
    // 堆变量访问
    func heapAccess() int {
        x := new(int)
        *x = 42
        sum := 0
        for i := 0; i < 1000000; i++ {
            sum += *x
        }
        return sum
    }
    
    start = time.Now()
    stackResult := stackAccess()
    stackAccessTime := time.Since(start)
    
    start = time.Now()
    heapResult := heapAccess()
    heapAccessTime := time.Since(start)
    
    fmt.Printf("  Stack access time: %v, result: %d\n", stackAccessTime, stackResult)
    fmt.Printf("  Heap access time: %v, result: %d\n", heapAccessTime, heapResult)
    fmt.Printf("  Stack access is %.2fx faster\n", float64(heapAccessTime)/float64(stackAccessTime))
}

// 栈溢出处理
func demonstrateStackOverflow() {
    fmt.Println("\n=== 栈溢出处理 ===")
    
    // 1. 检测栈大小
    fmt.Println("1. 检测栈大小:")
    
    var stackVar int
    fmt.Printf("  Current stack variable address: %p\n", &stackVar)
    
    // 2. 安全的递归
    fmt.Println("\n2. 安全的递归:")
    
    func safeRecursive(n int) int {
        if n <= 0 {
            return 1
        }
        // 限制递归深度
        if n > 10000 {
            panic("recursion too deep")
        }
        return n * safeRecursive(n-1)
    }
    
    // 3. 使用堆避免栈溢出
    fmt.Println("\n3. 使用堆避免栈溢出:")
    
    // 深度递归使用栈
    func deepStackRecursion(n int) int {
        if n <= 0 {
            return 1
        }
        return n + deepStackRecursion(n-1)
    }
    
    // 使用堆的迭代版本
    func heapBasedCalculation(n int) int {
        // 使用堆分配的大数组
        stack := make([]int, n+1)
        stack[0] = 1
        for i := 1; i <= n; i++ {
            stack[i] = i + stack[i-1]
        }
        return stack[n]
    }
    
    n := 1000
    start := time.Now()
    stackResult := deepStackRecursion(n)
    stackTime := time.Since(start)
    
    start = time.Now()
    heapResult := heapBasedCalculation(n)
    heapTime := time.Since(start)
    
    fmt.Printf("  Stack recursion result: %d, time: %v\n", stackResult, stackTime)
    fmt.Printf("  Heap calculation result: %d, time: %v\n", heapResult, heapTime)
}

// 栈和堆分配策略
func demonstrateAllocationStrategy() {
    fmt.Println("\n=== 栈和堆分配策略 ===")
    
    // 1. 选择合适的分配方式
    fmt.Println("1. 选择合适的分配方式:")
    
    // 短生命周期对象 - 使用栈
    func shortLivedObjects() {
        for i := 0; i < 1000; i++ {
            x := i * 2  // 栈分配，生命周期短
            fmt.Printf("  Value: %d\n", x)  // 简化输出
        }
    }
    
    // 长生命周期对象 - 使用堆
    func longLivedObjects() []*int {
        var results []*int
        for i := 0; i < 1000; i++ {
            x := i * 2  // 逃逸到堆
            results = append(results, &x)
        }
        return results
    }
    
    start := time.Now()
    shortLivedObjects()
    shortTime := time.Since(start)
    
    start = time.Now()
    results := longLivedObjects()
    longTime := time.Since(start)
    
    fmt.Printf("  Short-lived objects time: %v\n", shortTime)
    fmt.Printf("  Long-lived objects time: %v\n", longTime)
    fmt.Printf("  Objects returned: %d\n", len(results))
    
    // 2. 批量分配优化
    fmt.Println("\n2. 批量分配优化:")
    
    // 逐个分配
    start = time.Now()
    var individual []*int
    for i := 0; i < 10000; i++ {
        x := i
        individual = append(individual, &x)  // 每次都逃逸
    }
    individualTime := time.Since(start)
    
    // 批量分配
    start = time.Now()
    batch := make([]*int, 10000)
    data := make([]int, 10000)  // 一次性分配
    for i := range batch {
        data[i] = i
        batch[i] = &data[i]  // 指向批量分配的数据
    }
    batchTime := time.Since(start)
    
    fmt.Printf("  Individual allocation time: %v\n", individualTime)
    fmt.Printf("  Batch allocation time: %v\n", batchTime)
    fmt.Printf("  Batch improvement: %.2fx\n", float64(individualTime)/float64(batchTime))
}

// 栈和堆监控
func demonstrateStackHeapMonitoring() {
    fmt.Println("\n=== 栈和堆监控 ===")
    
    // 1. 实时监控
    fmt.Println("1. 实时监控:")
    
    // 启动监控goroutine
    go func() {
        ticker := time.NewTicker(1 * time.Second)
        defer ticker.Stop()
        
        for range ticker.C {
            var m runtime.MemStats
            runtime.ReadMemStats(&m)
            
            fmt.Printf("  MemStats - Alloc: %dKB, Sys: %dKB, StackInuse: %dKB\n",
                m.Alloc/1024, m.Sys/1024, m.StackInuse/1024)
        }
    }()
    
    // 2. 栈使用监控
    fmt.Println("\n2. 栈使用监控:")
    
    // 显示当前goroutine信息
    fmt.Printf("  NumGoroutine: %d\n", runtime.NumGoroutine())
    fmt.Printf("  NumCPU: %d\n", runtime.NumCPU())
    
    // 3. 堆使用监控
    fmt.Println("\n3. 堆使用监控:")
    
    var before, after runtime.MemStats
    runtime.ReadMemStats(&before)
    
    // 创建一些堆对象
    data := make([][]int, 1000)
    for i := range data {
        data[i] = make([]int, 1000)
    }
    
    runtime.ReadMemStats(&after)
    
    fmt.Printf("  Heap allocated: %d KB\n", (after.HeapAlloc-before.HeapAlloc)/1024)
    fmt.Printf("  Heap objects: %d\n", after.HeapObjects-before.HeapObjects)
    fmt.Printf("  GC cycles: %d\n", after.NumGC-before.NumGC)
    
    // 4. 性能分析
    fmt.Println("\n4. 性能分析:")
    fmt.Println("  Use 'go tool pprof' for detailed analysis")
    fmt.Println("  Use 'GODEBUG=schedtrace=1000' for scheduler tracing")
    fmt.Println("  Use 'GOTRACEBACK=all' for detailed stack traces")
}

// 栈和堆最佳实践
func stackHeapBestPractices() {
    fmt.Println("\n=== 栈和堆最佳实践 ===")
    
    fmt.Println("1. 分配策略:")
    fmt.Println("   - 短生命周期对象使用栈分配")
    fmt.Println("   - 长生命周期对象使用堆分配")
    fmt.Println("   - 避免不必要的指针传递")
    fmt.Println("   - 合理使用值类型和指针类型")
    
    fmt.Println("\n2. 性能优化:")
    fmt.Println("   - 栈分配比堆分配快")
    fmt.Println("   - 减少逃逸分析的开销")
    fmt.Println("   - 批量分配减少系统调用")
    fmt.Println("   - 使用对象池重用对象")
    
    fmt.Println("\n3. 内存管理:")
    fmt.Println("   - 监控内存使用情况")
    fmt.Println("   - 避免栈溢出")
    fmt.Println("   - 合理设置栈大小")
    fmt.Println("   - 使用内存池减少GC压力")
    
    fmt.Println("\n4. 调试技巧:")
    fmt.Println("   - 使用go build -gcflags=\"-m\"分析逃逸")
    fmt.Println("   - 使用runtime.ReadMemStats监控内存")
    fmt.Println("   - 使用pprof分析性能")
    fmt.Println("   - 启用调试标志追踪问题")
    
    fmt.Println("\n5. 常见陷阱:")
    fmt.Println("   - 过度使用指针导致逃逸")
    fmt.Println("   - 深度递归导致栈溢出")
    fmt.Println("   - 不合理的对象生命周期管理")
    fmt.Println("   - 忽视内存分配模式")
    
    fmt.Println("\n6. 工具使用:")
    fmt.Println("   - runtime包监控内存和goroutine")
    fmt.Println("   - unsafe包分析内存布局")
    fmt.Println("   - pprof进行性能分析")
    fmt.Println("   - 编译器标志优化代码")
}

func main() {
    demonstrateStackHeapAllocation()
    demonstrateStackOptimization()
    demonstrateHeapManagement()
    demonstrateStackHeapPerformance()
    demonstrateStackOverflow()
    demonstrateAllocationStrategy()
    demonstrateStackHeapMonitoring()
    stackHeapBestPractices()
}
```