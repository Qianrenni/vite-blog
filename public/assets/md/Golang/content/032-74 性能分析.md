## 7.4 性能分析

### pprof性能分析工具

```go
package main

import (
    "fmt"
    "log"
    "net/http"
    "_net/http/pprof"
    "runtime"
    "runtime/pprof"
    "sync"
    "time"
)

// pprof基础使用
func demonstratePprofBasics() {
    fmt.Println("=== pprof性能分析工具 ===")
    
    // 1. 启用pprof HTTP服务
    fmt.Println("1. 启用pprof HTTP服务:")
    
    // 启动pprof服务器
    go func() {
        // 注册pprof处理器
        http.HandleFunc("/debug/pprof/", pprof.Index)
        http.HandleFunc("/debug/pprof/cmdline", pprof.Cmdline)
        http.HandleFunc("/debug/pprof/profile", pprof.Profile)
        http.HandleFunc("/debug/pprof/symbol", pprof.Symbol)
        http.HandleFunc("/debug/pprof/trace", pprof.Trace)
        
        log.Println("pprof server starting on :6060")
        log.Fatal(http.ListenAndServe(":6060", nil))
    }()
    
    fmt.Println("  pprof server available at http://localhost:6060/debug/pprof/")
    fmt.Println("  Use 'go tool pprof http://localhost:6060/debug/pprof/profile' for CPU profiling")
    fmt.Println("  Use 'go tool pprof http://localhost:6060/debug/pprof/heap' for memory profiling")
    
    // 2. 手动创建profile文件
    fmt.Println("\n2. 手动创建profile文件:")
    
    // CPU profile
    func createCPUProfile() {
        f, err := os.Create("cpu.prof")
        if err != nil {
            log.Fatal("could not create CPU profile: ", err)
        }
        defer f.Close()
        
        if err := pprof.StartCPUProfile(f); err != nil {
            log.Fatal("could not start CPU profile: ", err)
        }
        defer pprof.StopCPUProfile()
        
        // 执行需要分析的代码
        cpuIntensiveWork()
    }
    
    // 内存profile
    func createMemoryProfile() {
        f, err := os.Create("mem.prof")
        if err != nil {
            log.Fatal("could not create memory profile: ", err)
        }
        defer f.Close()
        
        // 执行需要分析的代码
        memoryIntensiveWork()
        
        runtime.GC() // 获取最新的内存统计
        if err := pprof.WriteHeapProfile(f); err != nil {
            log.Fatal("could not write memory profile: ", err)
        }
    }
    
    fmt.Println("  Created cpu.prof and mem.prof files")
}

// CPU密集型工作示例
func cpuIntensiveWork() {
    // 模拟CPU密集型工作
    result := 0
    for i := 0; i < 1000000; i++ {
        result += i * i
    }
    _ = result
}

// 内存密集型工作示例
func memoryIntensiveWork() {
    // 模拟内存密集型工作
    data := make([][]int, 1000)
    for i := range data {
        data[i] = make([]int, 1000)
        for j := range data[i] {
            data[i][j] = i * j
        }
    }
    _ = len(data)
}

// pprof分析示例
func demonstratePprofAnalysis() {
    fmt.Println("\n=== pprof分析示例 ===")
    
    // 1. CPU分析
    fmt.Println("1. CPU分析:")
    
    // 启动CPU profile
    f, err := os.Create("cpu_analysis.prof")
    if err != nil {
        log.Fatal(err)
    }
    defer f.Close()
    
    if err := pprof.StartCPUProfile(f); err != nil {
        log.Fatal(err)
    }
    
    // 执行各种操作
    var wg sync.WaitGroup
    
    // CPU密集型任务
    wg.Add(1)
    go func() {
        defer wg.Done()
        for i := 0; i < 100; i++ {
            cpuIntensiveWork()
        }
    }()
    
    // 内存密集型任务
    wg.Add(1)
    go func() {
        defer wg.Done()
        for i := 0; i < 100; i++ {
            memoryIntensiveWork()
        }
    }()
    
    // I/O密集型任务
    wg.Add(1)
    go func() {
        defer wg.Done()
        for i := 0; i < 1000; i++ {
            time.Sleep(time.Millisecond)
        }
    }()
    
    wg.Wait()
    pprof.StopCPUProfile()
    
    fmt.Println("  CPU profile saved to cpu_analysis.prof")
    fmt.Println("  Use 'go tool pprof cpu_analysis.prof' to analyze")
    
    // 2. 内存分析
    fmt.Println("\n2. 内存分析:")
    
    f, err = os.Create("mem_analysis.prof")
    if err != nil {
        log.Fatal(err)
    }
    defer f.Close()
    
    // 创建大量对象
    objects := make([]*[]int, 100000)
    for i := range objects {
        slice := make([]int, 100)
        objects[i] = &slice
    }
    
    runtime.GC()
    if err := pprof.WriteHeapProfile(f); err != nil {
        log.Fatal(err)
    }
    
    fmt.Println("  Memory profile saved to mem_analysis.prof")
    fmt.Println("  Use 'go tool pprof mem_analysis.prof' to analyze")
}

// pprof web界面使用
func demonstratePprofWebInterface() {
    fmt.Println("\n=== pprof web界面使用 ===")
    
    fmt.Println("pprof web界面功能:")
    fmt.Println("  1. http://localhost:6060/debug/pprof/ - 主页")
    fmt.Println("  2. http://localhost:6060/debug/pprof/profile - CPU profile")
    fmt.Println("  3. http://localhost:6060/debug/pprof/heap - Heap profile")
    fmt.Println("  4. http://localhost:6060/debug/pprof/goroutine - Goroutine profile")
    fmt.Println("  5. http://localhost:6060/debug/pprof/threadcreate - Thread creation profile")
    fmt.Println("  6. http://localhost:6060/debug/pprof/block - Blocking profile")
    fmt.Println("  7. http://localhost:6060/debug/pprof/mutex - Mutex profile")
    fmt.Println("  8. http://localhost:6060/debug/pprof/cmdline - 命令行")
    fmt.Println("  9. http://localhost:6060/debug/pprof/symbol - 符号")
    fmt.Println("  10. http://localhost:6060/debug/pprof/trace - 执行跟踪")
    
    // 启动一些goroutine供分析
    for i := 0; i < 100; i++ {
        go func(id int) {
            for {
                time.Sleep(time.Second)
                _ = id
            }
        }(i)
    }
    
    fmt.Println("  Started 100 goroutines for analysis")
    fmt.Println("  Visit http://localhost:6060/debug/pprof/goroutine?debug=1 to see goroutine info")
}

// pprof命令行工具使用
func demonstratePprofCommandLine() {
    fmt.Println("\n=== pprof命令行工具使用 ===")
    
    fmt.Println("pprof命令行基本用法:")
    fmt.Println("  go tool pprof [binary] [profile]")
    fmt.Println("  go tool pprof http://localhost:6060/debug/pprof/profile")
    fmt.Println("  go tool pprof cpu.prof")
    fmt.Println("  go tool pprof mem.prof")
    
    fmt.Println("\n常用交互命令:")
    fmt.Println("  top - 显示最耗时的函数")
    fmt.Println("  list <function> - 显示函数源码")
    fmt.Println("  web - 生成并打开Web图形")
    fmt.Println("  png - 生成PNG图片")
    fmt.Println("  pdf - 生成PDF文档")
    fmt.Println("  peek <function> - 查看函数调用")
    fmt.Println("  quit - 退出")
    
    fmt.Println("\n过滤和排序:")
    fmt.Println("  top10 - 显示前10个")
    fmt.Println("  top -cum - 按累积时间排序")
    fmt.Println("  focus=<regex> - 过滤函数")
    fmt.Println("  ignore=<regex> - 忽略函数")
    fmt.Println("  hide=<regex> - 隐藏函数")
    
    // 生成示例profile文件
    generateSampleProfiles()
}

func generateSampleProfiles() {
    // CPU profile
    f, err := os.Create("sample_cpu.prof")
    if err != nil {
        log.Fatal(err)
    }
    defer f.Close()
    
    if err := pprof.StartCPUProfile(f); err != nil {
        log.Fatal(err)
    }
    
    // 执行一些工作
    simulateWorkload()
    
    pprof.StopCPUProfile()
    
    // Memory profile
    f, err = os.Create("sample_mem.prof")
    if err != nil {
        log.Fatal(err)
    }
    defer f.Close()
    
    runtime.GC()
    if err := pprof.WriteHeapProfile(f); err != nil {
        log.Fatal(err)
    }
    
    fmt.Println("  Generated sample_cpu.prof and sample_mem.prof")
    fmt.Println("  Use 'go tool pprof sample_cpu.prof' to analyze")
}

func simulateWorkload() {
    var wg sync.WaitGroup
    
    // 模拟不同类型的工作负载
    for i := 0; i < 10; i++ {
        wg.Add(1)
        go func() {
            defer wg.Done()
            for j := 0; j < 100000; j++ {
                _ = j * j
            }
        }()
    }
    
    wg.Wait()
}

// pprof高级功能
func demonstratePprofAdvanced() {
    fmt.Println("\n=== pprof高级功能 ===")
    
    // 1. 自定义profile
    fmt.Println("1. 自定义profile:")
    
    // 创建自定义profile
    customProfile := pprof.NewProfile("custom")
    
    func customProfileExample() {
        // 开始profile
        customProfile.Add("custom_work", 1)
        
        // 执行自定义工作
        time.Sleep(100 * time.Millisecond)
        
        // 结束profile
        customProfile.Remove("custom_work")
    }
    
    customProfileExample()
    fmt.Println("  Created custom profile")
    
    // 2. 阻塞profile
    fmt.Println("\n2. 阻塞profile:")
    
    // 启用阻塞profile
    runtime.SetBlockProfileRate(1)
    
    // 创建阻塞情况
    var mutex sync.Mutex
    var wg sync.WaitGroup
    
    for i := 0; i < 100; i++ {
        wg.Add(1)
        go func() {
            defer wg.Done()
            mutex.Lock()
            time.Sleep(time.Millisecond)
            mutex.Unlock()
        }()
    }
    
    wg.Wait()
    
    fmt.Println("  Block profile enabled and collected")
    fmt.Println("  Use 'go tool pprof http://localhost:6060/debug/pprof/block' to analyze")
    
    // 3. 互斥锁profile
    fmt.Println("\n3. 互斥锁profile:")
    
    // 启用互斥锁profile
    runtime.SetMutexProfileFraction(1)
    
    // 创建锁竞争
    var mu sync.RWMutex
    for i := 0; i < 100; i++ {
        go func() {
            mu.Lock()
            time.Sleep(time.Millisecond)
            mu.Unlock()
        }()
        
        go func() {
            mu.RLock()
            time.Sleep(time.Millisecond)
            mu.RUnlock()
        }()
    }
    
    time.Sleep(100 * time.Millisecond)
    fmt.Println("  Mutex profile enabled and collected")
    fmt.Println("  Use 'go tool pprof http://localhost:6060/debug/pprof/mutex' to analyze")
}

// pprof实战案例
func demonstratePprofRealWorld() {
    fmt.Println("\n=== pprof实战案例 ===")
    
    // 1. Web服务器性能分析
    fmt.Println("1. Web服务器性能分析:")
    
    // 模拟Web服务器
    http.HandleFunc("/api/users", func(w http.ResponseWriter, r *http.Request) {
        // 模拟数据库查询
        time.Sleep(10 * time.Millisecond)
        fmt.Fprintf(w, `{"users": [%s]}`, generateUserJSON())
    })
    
    http.HandleFunc("/api/orders", func(w http.ResponseWriter, r *http.Request) {
        // 模拟复杂计算
        result := complexCalculation()
        fmt.Fprintf(w, `{"result": %d}`, result)
    })
    
    // 启动服务器（在goroutine中）
    go func() {
        log.Println("Web server starting on :8080")
        log.Fatal(http.ListenAndServe(":8080", nil))
    }()
    
    fmt.Println("  Web server available at http://localhost:8080")
    fmt.Println("  API endpoints: /api/users, /api/orders")
    
    // 2. 数据库查询分析
    fmt.Println("\n2. 数据库查询分析:")
    
    // 模拟数据库操作
    func databaseQuery() {
        // 模拟网络延迟
        time.Sleep(5 * time.Millisecond)
        
        // 模拟数据处理
        data := make([]int, 1000)
        for i := range data {
            data[i] = i
        }
        
        // 模拟复杂查询
        result := 0
        for _, v := range data {
            result += v * v
        }
        _ = result
    }
    
    // 执行数据库查询
    for i := 0; i < 1000; i++ {
        databaseQuery()
    }
    
    fmt.Println("  Simulated 1000 database queries")
}

func generateUserJSON() string {
    return `{"id": 1, "name": "John", "email": "john@example.com"}`
}

func complexCalculation() int {
    result := 0
    for i := 0; i < 10000; i++ {
        result += i * i
    }
    return result
}

// pprof最佳实践
func pprofBestPractices() {
    fmt.Println("\n=== pprof最佳实践 ===")
    
    fmt.Println("1. 生产环境使用:")
    fmt.Println("   - 在独立端口运行pprof")
    fmt.Println("   - 添加认证和授权")
    fmt.Println("   - 限制访问频率")
    fmt.Println("   - 监控profile文件大小")
    
    fmt.Println("\n2. 性能分析策略:")
    fmt.Println("   - 定期进行性能分析")
    fmt.Println("   - 对比分析不同版本")
    fmt.Println("   - 关注关键路径性能")
    fmt.Println("   - 建立性能基线")
    
    fmt.Println("\n3. 工具使用技巧:")
    fmt.Println("   - 熟悉pprof交互命令")
    fmt.Println("   - 使用标签过滤数据")
    fmt.Println("   - 生成可视化图表")
    fmt.Println("   - 结合其他监控工具")
    
    fmt.Println("\n4. 常见分析场景:")
    fmt.Println("   - CPU使用率过高")
    fmt.Println("   - 内存使用持续增长")
    fmt.Println("   - goroutine泄漏")
    fmt.Println("   - 锁竞争严重")
    fmt.Println("   - I/O等待时间长")
    
    fmt.Println("\n5. 分析流程:")
    fmt.Println("   - 识别性能问题")
    fmt.Println("   - 收集profile数据")
    fmt.Println("   - 分析瓶颈点")
    fmt.Println("   - 制定优化方案")
    fmt.Println("   - 验证优化效果")
    
    fmt.Println("\n6. 注意事项:")
    fmt.Println("   - profile会影响性能")
    fmt.Println("   - 不要在生产环境长时间开启")
    fmt.Println("   - 保护profile数据安全")
    fmt.Println("   - 定期清理旧的profile文件")
}

func main() {
    demonstratePprofBasics()
    demonstratePprofAnalysis()
    demonstratePprofWebInterface()
    demonstratePprofCommandLine()
    demonstratePprofAdvanced()
    demonstratePprofRealWorld()
    pprofBestPractices()
    
    // 保持程序运行以便访问pprof
    fmt.Println("\nServer running... Press Ctrl+C to exit")
    select {}
}
```

### CPU性能分析

```go
package main

import (
    "fmt"
    "log"
    "os"
    "runtime"
    "runtime/pprof"
    "sync"
    "time"
)

// CPU性能分析基础
func demonstrateCPUBasicAnalysis() {
    fmt.Println("=== CPU性能分析 ===")
    
    // 1. 启动CPU profile
    fmt.Println("1. 启动CPU profile:")
    
    f, err := os.Create("cpu_basic.prof")
    if err != nil {
        log.Fatal("could not create CPU profile: ", err)
    }
    defer f.Close()
    
    if err := pprof.StartCPUProfile(f); err != nil {
        log.Fatal("could not start CPU profile: ", err)
    }
    
    // 执行需要分析的代码
    performBasicOperations()
    
    pprof.StopCPUProfile()
    fmt.Println("  CPU profile saved to cpu_basic.prof")
    
    // 2. 分析CPU使用模式
    fmt.Println("\n2. 分析CPU使用模式:")
    
    // 启动多个goroutine执行不同任务
    var wg sync.WaitGroup
    
    // CPU密集型任务
    wg.Add(1)
    go func() {
        defer wg.Done()
        cpuIntensiveTask()
    }()
    
    // I/O密集型任务
    wg.Add(1)
    go func() {
        defer wg.Done()
        ioIntensiveTask()
    }()
    
    // 内存密集型任务
    wg.Add(1)
    go func() {
        defer wg.Done()
        memoryIntensiveTask()
    }()
    
    wg.Wait()
    fmt.Println("  Completed multi-type workload analysis")
}

func performBasicOperations() {
    // 数学计算
    sum := 0
    for i := 0; i < 1000000; i++ {
        sum += i
    }
    _ = sum
    
    // 字符串操作
    var str string
    for i := 0; i < 100000; i++ {
        str += fmt.Sprintf("%d", i)
    }
    _ = len(str)
    
    // 切片操作
    slice := make([]int, 0, 100000)
    for i := 0; i < 100000; i++ {
        slice = append(slice, i)
    }
    _ = len(slice)
}

func cpuIntensiveTask() {
    result := 0
    for i := 0; i < 10000000; i++ {
        result += i * i
    }
    _ = result
}

func ioIntensiveTask() {
    for i := 0; i < 1000; i++ {
        time.Sleep(time.Millisecond)
    }
}

func memoryIntensiveTask() {
    data := make([][]int, 10000)
    for i := range data {
        data[i] = make([]int, 1000)
    }
    _ = len(data)
}

// CPU热点分析
func demonstrateCPUHotspotAnalysis() {
    fmt.Println("\n=== CPU热点分析 ===")
    
    // 1. 识别CPU热点
    fmt.Println("1. 识别CPU热点:")
    
    f, err := os.Create("cpu_hotspot.prof")
    if err != nil {
        log.Fatal(err)
    }
    defer f.Close()
    
    if err := pprof.StartCPUProfile(f); err != nil {
        log.Fatal(err)
    }
    
    // 执行包含热点的代码
    executeHotspotCode()
    
    pprof.StopCPUProfile()
    fmt.Println("  Hotspot profile saved to cpu_hotspot.prof")
    
    // 2. 热点函数优化
    fmt.Println("\n2. 热点函数优化:")
    
    // 优化前的热点函数
    func unoptimizedHotspot() int {
        result := 0
        for i := 0; i < 1000000; i++ {
            result += slowFunction(i)
        }
        return result
    }
    
    // 优化后的热点函数
    func optimizedHotspot() int {
        result := 0
        for i := 0; i < 1000000; i++ {
            result += fastFunction(i)
        }
        return result
    }
    
    // 性能对比
    start := time.Now()
    unoptimizedResult := unoptimizedHotspot()
    unoptimizedTime := time.Since(start)
    
    start = time.Now()
    optimizedResult := optimizedHotspot()
    optimizedTime := time.Since(start)
    
    fmt.Printf("  Unoptimized result: %d, time: %v\n", unoptimizedResult, unoptimizedTime)
    fmt.Printf("  Optimized result: %d, time: %v\n", optimizedResult, optimizedTime)
    fmt.Printf("  Performance improvement: %.2fx\n", 
        float64(unoptimizedTime)/float64(optimizedTime))
}

func executeHotspotCode() {
    // 模拟热点代码
    for i := 0; i < 100; i++ {
        hotspotFunction1()
        hotspotFunction2()
        hotspotFunction3()
    }
}

func hotspotFunction1() {
    sum := 0
    for i := 0; i < 100000; i++ {
        sum += i
    }
    _ = sum
}

func hotspotFunction2() {
    result := make([]int, 10000)
    for i := range result {
        result[i] = i * i
    }
    _ = len(result)
}

func hotspotFunction3() {
    var str string
    for i := 0; i < 10000; i++ {
        str += fmt.Sprintf("%d", i)
    }
    _ = len(str)
}

func slowFunction(x int) int {
    // 模拟慢速计算
    time.Sleep(time.Nanosecond)
    return x * x
}

func fastFunction(x int) int {
    // 快速计算
    return x * x
}

// 并发CPU分析
func demonstrateConcurrentCPUAnalysis() {
    fmt.Println("\n=== 并发CPU分析 ===")
    
    // 1. goroutine CPU使用分析
    fmt.Println("1. goroutine CPU使用分析:")
    
    f, err := os.Create("cpu_concurrent.prof")
    if err != nil {
        log.Fatal(err)
    }
    defer f.Close()
    
    if err := pprof.StartCPUProfile(f); err != nil {
        log.Fatal(err)
    }
    
    // 启动多个goroutine
    var wg sync.WaitGroup
    numGoroutines := runtime.NumCPU() * 2
    
    for i := 0; i < numGoroutines; i++ {
        wg.Add(1)
        go func(id int) {
            defer wg.Done()
            concurrentWorker(id)
        }(i)
    }
    
    wg.Wait()
    pprof.StopCPUProfile()
    
    fmt.Printf("  Started %d goroutines for CPU analysis\n", numGoroutines)
    fmt.Println("  Concurrent profile saved to cpu_concurrent.prof")
    
    // 2. 锁竞争分析
    fmt.Println("\n2. 锁竞争分析:")
    
    var mutex sync.Mutex
    var rwMutex sync.RWMutex
    var wg2 sync.WaitGroup
    
    // 启用阻塞profile
    runtime.SetBlockProfileRate(1)
    
    // 竞争写锁
    for i := 0; i < 50; i++ {
        wg2.Add(1)
        go func() {
            defer wg2.Done()
            mutex.Lock()
            time.Sleep(time.Millisecond)
            mutex.Unlock()
        }()
    }
    
    // 竞争读写锁
    for i := 0; i < 50; i++ {
        wg2.Add(1)
        go func() {
            defer wg2.Done()
            rwMutex.Lock()
            time.Sleep(time.Millisecond)
            rwMutex.Unlock()
        }()
        
        wg2.Add(1)
        go func() {
            defer wg2.Done()
            rwMutex.RLock()
            time.Sleep(time.Millisecond)
            rwMutex.RUnlock()
        }()
    }
    
    wg2.Wait()
    fmt.Println("  Lock contention analysis completed")
    fmt.Println("  Use 'go tool pprof http://localhost:6060/debug/pprof/block' to analyze")
}

func concurrentWorker(id int) {
    // 模拟并发工作
    for i := 0; i < 10000; i++ {
        _ = id * i
    }
    
    // 模拟I/O等待
    time.Sleep(time.Microsecond * 100)
}

// CPU性能优化技巧
func demonstrateCPUPerformanceOptimization() {
    fmt.Println("\n=== CPU性能优化技巧 ===")
    
    // 1. 算法优化
    fmt.Println("1. 算法优化:")
    
    // 低效算法
    func bubbleSort(slice []int) {
        n := len(slice)
        for i := 0; i < n-1; i++ {
            for j := 0; j < n-i-1; j++ {
                if slice[j] > slice[j+1] {
                    slice[j], slice[j+1] = slice[j+1], slice[j]
                }
            }
        }
    }
    
    // 高效算法
    func quickSort(slice []int, low, high int) {
        if low < high {
            pi := partition(slice, low, high)
            quickSort(slice, low, pi-1)
            quickSort(slice, pi+1, high)
        }
    }
    
    func partition(slice []int, low, high int) int {
        pivot := slice[high]
        i := low - 1
        for j := low; j < high; j++ {
            if slice[j] < pivot {
                i++
                slice[i], slice[j] = slice[j], slice[i]
            }
        }
        slice[i+1], slice[high] = slice[high], slice[i+1]
        return i + 1
    }
    
    // 性能测试
    data1 := make([]int, 10000)
    data2 := make([]int, 10000)
    for i := range data1 {
        data1[i] = 10000 - i
        data2[i] = data1[i]
    }
    
    start := time.Now()
    bubbleSort(data1)
    bubbleTime := time.Since(start)
    
    start = time.Now()
    quickSort(data2, 0, len(data2)-1)
    quickTime := time.Since(start)
    
    fmt.Printf("  Bubble sort time: %v\n", bubbleTime)
    fmt.Printf("  Quick sort time: %v\n", quickTime)
    fmt.Printf("  Algorithm improvement: %.2fx\n", float64(bubbleTime)/float64(quickTime))
    
    // 2. 数据结构优化
    fmt.Println("\n2. 数据结构优化:")
    
    // 使用切片查找
    func sliceSearch(slice []int, target int) bool {
        for _, v := range slice {
            if v == target {
                return true
            }
        }
        return false
    }
    
    // 使用映射查找
    func mapSearch(m map[int]bool, target int) bool {
        return m[target]
    }
    
    // 准备测试数据
    sliceData := make([]int, 10000)
    mapData := make(map[int]bool)
    for i := 0; i < 10000; i++ {
        sliceData[i] = i
        mapData[i] = true
    }
    
    target := 9999
    
    start = time.Now()
    for i := 0; i < 1000; i++ {
        _ = sliceSearch(sliceData, target)
    }
    sliceTime := time.Since(start)
    
    start = time.Now()
    for i := 0; i < 1000; i++ {
        _ = mapSearch(mapData, target)
    }
    mapTime := time.Since(start)
    
    fmt.Printf("  Slice search time: %v\n", sliceTime)
    fmt.Printf("  Map search time: %v\n", mapTime)
    fmt.Printf("  Data structure improvement: %.2fx\n", float64(sliceTime)/float64(mapTime))
}

// CPU分析工具使用
func demonstrateCPUAnalysisTools() {
    fmt.Println("\n=== CPU分析工具使用 ===")
    
    // 1. go tool pprof使用
    fmt.Println("1. go tool pprof使用:")
    
    // 生成CPU profile
    f, err := os.Create("cpu_tools.prof")
    if err != nil {
        log.Fatal(err)
    }
    defer f.Close()
    
    if err := pprof.StartCPUProfile(f); err != nil {
        log.Fatal(err)
    }
    
    // 执行复杂操作
    complexOperations()
    
    pprof.StopCPUProfile()
    
    fmt.Println("  Generated cpu_tools.prof")
    fmt.Println("  Use 'go tool pprof cpu_tools.prof' for analysis")
    fmt.Println("  Common commands:")
    fmt.Println("    top - Show top functions")
    fmt.Println("    list <function> - Show function source")
    fmt.Println("    web - Generate web graph")
    fmt.Println("    png - Generate PNG image")
    
    // 2. 火焰图生成
    fmt.Println("\n2. 火焰图生成:")
    fmt.Println("  go tool pprof -http=:8081 cpu_tools.prof")
    fmt.Println("  Visit http://localhost:8081/ui/flamegraph for flame graph")
    
    // 3. 命令行分析示例
    fmt.Println("\n3. 命令行分析示例:")
    fmt.Println("  (pprof) top10")
    fmt.Println("  (pprof) top -cum")
    fmt.Println("  (pprof) list main.complexOperations")
    fmt.Println("  (pprof) web")
    fmt.Println("  (pprof) quit")
}

func complexOperations() {
    var wg sync.WaitGroup
    
    // 并发执行不同类型的操作
    for i := 0; i < 10; i++ {
        wg.Add(1)
        go func(id int) {
            defer wg.Done()
            for j := 0; j < 100000; j++ {
                _ = id * j * j
            }
        }(i)
    }
    
    wg.Wait()
}

// CPU性能监控
func demonstrateCPUMonitoring() {
    fmt.Println("\n=== CPU性能监控 ===")
    
    // 1. 实时CPU监控
    fmt.Println("1. 实时CPU监控:")
    
    // 启动监控goroutine
    go func() {
        ticker := time.NewTicker(5 * time.Second)
        defer ticker.Stop()
        
        for range ticker.C {
            var m runtime.MemStats
            runtime.ReadMemStats(&m)
            
            // 模拟CPU使用率计算
            fmt.Printf("  CPU Stats - Goroutines: %d, Alloc: %dKB, NumGC: %d\n",
                runtime.NumGoroutine(), m.Alloc/1024, m.NumGC)
        }
    }()
    
    // 2. 自定义性能指标
    fmt.Println("\n2. 自定义性能指标:")
    
    type PerformanceMetrics struct {
        TotalOperations int64
        TotalTime       time.Duration
        PeakMemory      uint64
        mutex           sync.RWMutex
    }
    
    metrics := &PerformanceMetrics{}
    
    // 监控函数执行时间
    func monitorFunction(name string, fn func()) {
        start := time.Now()
        fn()
        duration := time.Since(start)
        
        metrics.mutex.Lock()
        metrics.TotalOperations++
        metrics.TotalTime += duration
        metrics.mutex.Unlock()
        
        fmt.Printf("  %s executed in %v\n", name, duration)
    }
    
    // 使用监控
    monitorFunction("CPU Intensive Task", func() {
        cpuIntensiveTask()
    })
    
    monitorFunction("Memory Intensive Task", func() {
        memoryIntensiveTask()
    })
    
    // 显示汇总统计
    metrics.mutex.RLock()
    avgTime := time.Duration(0)
    if metrics.TotalOperations > 0 {
        avgTime = metrics.TotalTime / time.Duration(metrics.TotalOperations)
    }
    metrics.mutex.RUnlock()
    
    fmt.Printf("  Total operations: %d\n", metrics.TotalOperations)
    fmt.Printf("  Average time per operation: %v\n", avgTime)
}

// CPU性能最佳实践
func cpuPerformanceBestPractices() {
    fmt.Println("\n=== CPU性能最佳实践 ===")
    
    fmt.Println("1. 性能分析流程:")
    fmt.Println("   - 识别性能瓶颈")
    fmt.Println("   - 收集profile数据")
    fmt.Println("   - 分析热点函数")
    fmt.Println("   - 制定优化方案")
    fmt.Println("   - 验证优化效果")
    
    fmt.Println("\n2. 优化策略:")
    fmt.Println("   - 算法优化优先")
    fmt.Println("   - 数据结构选择")
    fmt.Println("   - 减少不必要的计算")
    fmt.Println("   - 合理使用并发")
    fmt.Println("   - 缓存和预计算")
    
    fmt.Println("\n3. 并发优化:")
    fmt.Println("   - 合理的goroutine数量")
    fmt.Println("   - 减少锁竞争")
    fmt.Println("   - 使用无锁数据结构")
    fmt.Println("   - 工作池模式")
    fmt.Println("   - 批量处理")
    
    fmt.Println("\n4. 工具使用:")
    fmt.Println("   - go tool pprof")
    fmt.Println("   - runtime/pprof包")
    fmt.Println("   - net/http/pprof包")
    fmt.Println("   - 火焰图分析")
    fmt.Println("   - 基准测试")
    
    fmt.Println("\n5. 监控和告警:")
    fmt.Println("   - 实时性能监控")
    fmt.Println("   - 性能基线建立")
    fmt.Println("   - 异常检测")
    fmt.Println("   - 自动化分析")
    fmt.Println("   - 性能回归测试")
    
    fmt.Println("\n6. 常见陷阱:")
    fmt.Println("   - 过早优化")
    fmt.Println("   - 忽视算法复杂度")
    fmt.Println("   - 不合理的并发使用")
    fmt.Println("   - 忽视内存分配影响")
    fmt.Println("   - 缺乏性能测试")
    
    fmt.Println("\n7. 生产环境考虑:")
    fmt.Println("   - profile对性能的影响")
    fmt.Println("   - 安全访问控制")
    fmt.Println("   - 资源限制")
    fmt.Println("   - 监控告警")
    fmt.Println("   - 故障恢复")
}

func main() {
    demonstrateCPUBasicAnalysis()
    demonstrateCPUHotspotAnalysis()
    demonstrateConcurrentCPUAnalysis()
    demonstrateCPUPerformanceOptimization()
    demonstrateCPUAnalysisTools()
    demonstrateCPUMonitoring()
    cpuPerformanceBestPractices()
}
```

### 内存性能分析

```go
package main

import (
    "fmt"
    "log"
    "os"
    "runtime"
    "runtime/pprof"
    "sync"
    "time"
)

// 内存性能分析基础
func demonstrateMemoryBasicAnalysis() {
    fmt.Println("=== 内存性能分析 ===")
    
    // 1. 启动内存profile
    fmt.Println("1. 启动内存profile:")
    
    f, err := os.Create("mem_basic.prof")
    if err != nil {
        log.Fatal("could not create memory profile: ", err)
    }
    defer f.Close()
    
    // 执行需要分析的代码
    performMemoryOperations()
    
    runtime.GC() // 强制GC获取最新内存状态
    if err := pprof.WriteHeapProfile(f); err != nil {
        log.Fatal("could not write memory profile: ", err)
    }
    
    fmt.Println("  Memory profile saved to mem_basic.prof")
    
    // 2. 内存分配模式分析
    fmt.Println("\n2. 内存分配模式分析:")
    
    // 分析不同类型的内存分配
    analyzeMemoryAllocationPatterns()
}

func performMemoryOperations() {
    // 大量小对象分配
    smallObjects := make([]*int, 100000)
    for i := range smallObjects {
        x := i
        smallObjects[i] = &x
    }
    
    // 大对象分配
    largeObjects := make([][]int, 1000)
    for i := range largeObjects {
        largeObjects[i] = make([]int, 10000)
    }
    
    // 字符串分配
    var strings []string
    for i := 0; i < 10000; i++ {
        strings = append(strings, fmt.Sprintf("string_%d", i))
    }
    
    // 映射分配
    maps := make([]map[string]int, 1000)
    for i := range maps {
        maps[i] = make(map[string]int)
        for j := 0; j < 100; j++ {
            maps[i][fmt.Sprintf("key_%d", j)] = j
        }
    }
    
    // 保持引用防止被GC
    _ = smallObjects
    _ = largeObjects
    _ = strings
    _ = maps
}

func analyzeMemoryAllocationPatterns() {
    // 1. 频繁分配模式
    fmt.Println("  Frequent allocation pattern:")
    start := time.Now()
    for i := 0; i < 100000; i++ {
        _ = &[]int{i}
    }
    frequentTime := time.Since(start)
    
    // 2. 批量分配模式
    fmt.Println("  Batch allocation pattern:")
    start = time.Now()
    batch := make([][]int, 100000)
    for i := range batch {
        batch[i] = []int{i}
    }
    batchTime := time.Since(start)
    
    fmt.Printf("    Frequent allocation: %v\n", frequentTime)
    fmt.Printf("    Batch allocation: %v\n", batchTime)
    fmt.Printf("    Improvement: %.2fx\n", float64(frequentTime)/float64(batchTime))
}

// 内存泄漏分析
func demonstrateMemoryLeakAnalysis() {
    fmt.Println("\n=== 内存泄漏分析 ===")
    
    // 1. 模拟内存泄漏
    fmt.Println("1. 模拟内存泄漏:")
    
    f, err := os.Create("mem_leak.prof")
    if err != nil {
        log.Fatal(err)
    }
    defer f.Close()
    
    // 创建泄漏
    createMemoryLeaks()
    
    runtime.GC()
    if err := pprof.WriteHeapProfile(f); err != nil {
        log.Fatal(err)
    }
    
    fmt.Println("  Memory leak profile saved to mem_leak.prof")
    
    // 2. 泄漏检测和预防
    fmt.Println("\n2. 泄漏检测和预防:")
    
    // 使用对象池减少分配
    type ReusableObject struct {
        Data [1024]byte
        ID   int
    }
    
    var objectPool = sync.Pool{
        New: func() interface{} {
            return &ReusableObject{}
        },
    }
    
    // 不使用对象池
    start := time.Now()
    for i := 0; i < 100000; i++ {
        obj := &ReusableObject{ID: i}
        _ = obj.ID
    }
    noPoolTime := time.Since(start)
    
    // 使用对象池
    start = time.Now()
    for i := 0; i < 100000; i++ {
        obj := objectPool.Get().(*ReusableObject)
        obj.ID = i
        _ = obj.ID
        objectPool.Put(obj)
    }
    poolTime := time.Since(start)
    
    fmt.Printf("    Without pool: %v\n", noPoolTime)
    fmt.Printf("    With pool: %v\n", poolTime)
    fmt.Printf("    Pool improvement: %.2fx\n", float64(noPoolTime)/float64(poolTime))
}

func createMemoryLeaks() {
    // 1. 未释放的切片引用
    leakySlice := make([][]int, 10000)
    for i := range leakySlice {
        leakySlice[i] = make([]int, 1000)
    }
    
    // 2. 未关闭的channel
    for i := 0; i < 1000; i++ {
        ch := make(chan int, 10)
        ch <- 42
        _ = ch // 不消费也不关闭
    }
    
    // 3. 未停止的定时器
    for i := 0; i < 1000; i++ {
        timer := time.AfterFunc(time.Hour, func() {
            fmt.Println("Timer fired")
        })
        _ = timer // 不停止
    }
    
    // 4. 循环引用
    type Node struct {
        Value    int
        Children []*Node
        Parent   *Node
    }
    
    // 创建循环引用
    parent := &Node{Value: 1}
    child := &Node{Value: 2, Parent: parent}
    parent.Children = append(parent.Children, child)
    
    // 保持引用
    _ = leakySlice
    _ = parent
    _ = child
}

// 内存分配优化
func demonstrateMemoryAllocationOptimization() {
    fmt.Println("\n=== 内存分配优化 ===")
    
    // 1. 预分配优化
    fmt.Println("1. 预分配优化:")
    
    // 不预分配
    start := time.Now()
    var noPrealloc []int
    for i := 0; i < 100000; i++ {
        noPrealloc = append(noPrealloc, i)
    }
    noPreallocTime := time.Since(start)
    
    // 预分配
    start = time.Now()
    prealloc := make([]int, 0, 100000)
    for i := 0; i < 100000; i++ {
        prealloc = append(prealloc, i)
    }
    preallocTime := time.Since(start)
    
    fmt.Printf("    No preallocation: %v\n", noPreallocTime)
    fmt.Printf("    With preallocation: %v\n", preallocTime)
    fmt.Printf("    Preallocation improvement: %.2fx\n", 
        float64(noPreallocTime)/float64(preallocTime))
    
    // 2. 切片扩容优化
    fmt.Println("\n2. 切片扩容优化:")
    
    // 指数增长
    start = time.Now()
    exponential := make([]int, 0, 1)
    for i := 0; i < 10000; i++ {
        exponential = append(exponential, i)
    }
    exponentialTime := time.Since(start)
    
    // 线性增长
    start = time.Now()
    linear := make([]int, 0, 10000)
    for i := 0; i < 10000; i++ {
        linear = append(linear, i)
    }
    linearTime := time.Since(start)
    
    fmt.Printf("    Exponential growth: %v\n", exponentialTime)
    fmt.Printf("    Linear growth: %v\n", linearTime)
    fmt.Printf("    Growth optimization: %.2fx\n", 
        float64(exponentialTime)/float64(linearTime))
}

// 内存使用模式分析
func demonstrateMemoryUsagePatterns() {
    fmt.Println("\n=== 内存使用模式分析 ===")
    
    // 1. 栈 vs 堆分配
    fmt.Println("1. 栈 vs 堆分配:")
    
    // 栈分配
    func stackAllocation() {
        x := 42
        y := 3.14
        arr := [100]int{}
        _ = x + y + float64(arr[0])
    }
    
    // 堆分配
    func heapAllocation() {
        x := new(int)
        *x = 42
        y := new(float64)
        *y = 3.14
        arr := make([]int, 100)
        _ = *x + *y + float64(arr[0])
    }
    
    start := time.Now()
    for i := 0; i < 1000000; i++ {
        stackAllocation()
    }
    stackTime := time.Since(start)
    
    start = time.Now()
    for i := 0; i < 1000000; i++ {
        heapAllocation()
    }
    heapTime := time.Since(start)
    
    fmt.Printf("    Stack allocation: %v\n", stackTime)
    fmt.Printf("    Heap allocation: %v\n", heapTime)
    fmt.Printf("    Stack vs heap: %.2fx\n", float64(heapTime)/float64(stackTime))
    
    // 2. 对象大小对分配的影响
    fmt.Println("\n2. 对象大小对分配的影响:")
    
    // 小对象
    start = time.Now()
    smallObjects := make([]*int, 1000000)
    for i := range smallObjects {
        x := i
        smallObjects[i] = &x
    }
    smallTime := time.Since(start)
    
    // 大对象
    start = time.Now()
    largeObjects := make([]*[]int, 10000)
    for i := range largeObjects {
        largeObjects[i] = &[]int{i}
    }
    largeTime := time.Since(start)
    
    fmt.Printf("    Small objects (1M): %v\n", smallTime)
    fmt.Printf("    Large objects (10K): %v\n", largeTime)
}

// 内存分析工具使用
func demonstrateMemoryAnalysisTools() {
    fmt.Println("\n=== 内存分析工具使用 ===")
    
    // 1. pprof内存分析
    fmt.Println("1. pprof内存分析:")
    
    f, err := os.Create("mem_tools.prof")
    if err != nil {
        log.Fatal(err)
    }
    defer f.Close()
    
    // 执行内存密集型操作
    memoryIntensiveOperations()
    
    runtime.GC()
    if err := pprof.WriteHeapProfile(f); err != nil {
        log.Fatal(err)
    }
    
    fmt.Println("  Generated mem_tools.prof")
    fmt.Println("  Use 'go tool pprof mem_tools.prof' for analysis")
    fmt.Println("  Common commands:")
    fmt.Println("    top - Show top memory consumers")
    fmt.Println("    list <function> - Show function allocations")
    fmt.Println("    web - Generate web graph")
    fmt.Println("    png - Generate PNG image")
    
    // 2. 内存分配跟踪
    fmt.Println("\n2. 内存分配跟踪:")
    
    // 启用分配跟踪
    runtime.MemProfileRate = 1
    
    // 执行操作
    for i := 0; i < 10000; i++ {
        _ = &[]int{i}
    }
    
    fmt.Println("  Memory allocation tracing enabled")
    fmt.Println("  Use 'GODEBUG=allocfreetrace=1' for detailed tracing")
}

func memoryIntensiveOperations() {
    // 创建大量不同类型的对象
    data := make(map[string]interface{})
    
    // 字符串
    for i := 0; i < 10000; i++ {
        data[fmt.Sprintf("string_%d", i)] = fmt.Sprintf("value_%d", i)
    }
    
    // 切片
    for i := 0; i < 1000; i++ {
        data[fmt.Sprintf("slice_%d", i)] = make([]int, 1000)
    }
    
    // 结构体
    type DataStruct struct {
        Field1 string
        Field2 int
        Field3 []byte
    }
    
    for i := 0; i < 10000; i++ {
        data[fmt.Sprintf("struct_%d", i)] = &DataStruct{
            Field1: fmt.Sprintf("field_%d", i),
            Field2: i,
            Field3: make([]byte, 100),
        }
    }
    
    _ = data
}

// 内存监控和告警
func demonstrateMemoryMonitoring() {
    fmt.Println("\n=== 内存监控和告警 ===")
    
    // 1. 实时内存监控
    fmt.Println("1. 实时内存监控:")
    
    // 启动监控goroutine
    go func() {
        ticker := time.NewTicker(10 * time.Second)
        defer ticker.Stop()
        
        for range ticker.C {
            var m runtime.MemStats
            runtime.ReadMemStats(&m)
            
            fmt.Printf("  Memory Stats - Alloc: %dMB, Sys: %dMB, NumGC: %d, GCCPUFraction: %.2f%%\n",
                m.Alloc/1024/1024, m.Sys/1024/1024, m.NumGC, m.GCCPUFraction*100)
            
            // 内存使用告警
            if m.Alloc > 500*1024*1024 { // 超过500MB
                fmt.Printf("  WARNING: High memory usage: %dMB\n", m.Alloc/1024/1024)
            }
        }
    }()
    
    // 2. 自定义内存指标
    fmt.Println("\n2. 自定义内存指标:")
    
    type MemoryMetrics struct {
        TotalAllocations int64
        PeakMemory       uint64
        GCCount          uint32
        mutex            sync.RWMutex
    }
    
    metrics := &MemoryMetrics{}
    
    // 监控内存分配
    func monitorMemoryAllocation(size int) {
        metrics.mutex.Lock()
        metrics.TotalAllocations += int64(size)
        
        var m runtime.MemStats
        runtime.ReadMemStats(&m)
        if m.Alloc > metrics.PeakMemory {
            metrics.PeakMemory = m.Alloc
        }
        metrics.GCCount = m.NumGC
        metrics.mutex.Unlock()
    }
    
    // 使用监控
    for i := 0; i < 10000; i++ {
        data := make([]int, 1000)
        monitorMemoryAllocation(len(data) * 8) // 8 bytes per int
        _ = data
    }
    
    metrics.mutex.RLock()
    fmt.Printf("  Total allocations: %d bytes\n", metrics.TotalAllocations)
    fmt.Printf("  Peak memory: %d MB\n", metrics.PeakMemory/1024/1024)
    fmt.Printf("  GC count: %d\n", metrics.GCCount)
    metrics.mutex.RUnlock()
}

// 内存性能最佳实践
func memoryPerformanceBestPractices() {
    fmt.Println("\n=== 内存性能最佳实践 ===")
    
    fmt.Println("1. 分配优化:")
    fmt.Println("   - 预分配切片和映射容量")
    fmt.Println("   - 使用对象池重用对象")
    fmt.Println("   - 避免不必要的内存分配")
    fmt.Println("   - 合理使用栈和堆分配")
    
    fmt.Println("\n2. 数据结构选择:")
    fmt.Println("   - 根据访问模式选择数据结构")
    fmt.Println("   - 考虑内存布局和对齐")
    fmt.Println("   - 使用紧凑的数据结构")
    fmt.Println("   - 避免深层嵌套的指针")
    
    fmt.Println("\n3. 泄漏预防:")
    fmt.Println("   - 及时关闭资源")
    fmt.Println("   - 正确管理goroutine生命周期")
    fmt.Println("   - 避免循环引用")
    fmt.Println("   - 使用defer确保清理")
    
    fmt.Println("\n4. 监控和分析:")
    fmt.Println("   - 定期进行内存分析")
    fmt.Println("   - 监控内存使用趋势")
    fmt.Println("   - 设置内存使用告警")
    fmt.Println("   - 建立性能基线")
    
    fmt.Println("\n5. 工具使用:")
    fmt.Println("   - go tool pprof进行深入分析")
    fmt.Println("   - runtime包监控内存状态")
    fmt.Println("   - 第三方工具如goleak")
    fmt.Println("   - 内存可视化工具")
    
    fmt.Println("\n6. 生产环境考虑:")
    fmt.Println("   - 内存限制和OOM处理")
    fmt.Println("   - GC调优")
    fmt.Println("   - 容器内存管理")
    fmt.Println("   - 自动化监控和告警")
    
    fmt.Println("\n7. 常见陷阱:")
    fmt.Println("   - 忽视内存分配模式")
    fmt.Println("   - 不合理的数据结构选择")
    fmt.Println("   - goroutine泄漏")
    fmt.Println("   - 忘记关闭资源")
    
    fmt.Println("\n8. 性能测试:")
    fmt.Println("   - 使用基准测试验证优化")
    fmt.Println("   - 对比不同方案的内存使用")
    fmt.Println("   - 监控GC影响")
    fmt.Println("   - 长期性能回归测试")
}

func main() {
    demonstrateMemoryBasicAnalysis()
    demonstrateMemoryLeakAnalysis()
    demonstrateMemoryAllocationOptimization()
    demonstrateMemoryUsagePatterns()
    demonstrateMemoryAnalysisTools()
    demonstrateMemoryMonitoring()
    memoryPerformanceBestPractices()
}
```

### 协程分析

```go
package main

import (
    "fmt"
    "log"
    "net/http"
    "_net/http/pprof"
    "runtime"
    "sync"
    "time"
)

// 协程分析基础
func demonstrateGoroutineBasicAnalysis() {
    fmt.Println("=== 协程分析 ===")
    
    // 1. 启用goroutine profile
    fmt.Println("1. 启用goroutine profile:")
    
    // 启动pprof服务器
    go func() {
        http.HandleFunc("/debug/pprof/", pprof.Index)
        http.HandleFunc("/debug/pprof/goroutine", pprof.Index)
        log.Println("pprof server starting on :6060")
        log.Fatal(http.ListenAndServe(":6060", nil))
    }()
    
    fmt.Println("  pprof server available at http://localhost:6060/debug/pprof/goroutine")
    fmt.Println("  Use 'go tool pprof http://localhost:6060/debug/pprof/goroutine' for analysis")
    
    // 2. 基本goroutine监控
    fmt.Println("\n2. 基本goroutine监控:")
    
    initialGoroutines := runtime.NumGoroutine()
    fmt.Printf("  Initial goroutines: %d\n", initialGoroutines)
    
    // 启动一些goroutine
    var wg sync.WaitGroup
    for i := 0; i < 100; i++ {
        wg.Add(1)
        go func(id int) {
            defer wg.Done()
            time.Sleep(time.Second)
            _ = id
        }(i)
    }
    
    time.Sleep(100 * time.Millisecond) // 给goroutine时间启动
    currentGoroutines := runtime.NumGoroutine()
    fmt.Printf("  Current goroutines: %d\n", currentGoroutines)
    fmt.Printf("  New goroutines: %d\n", currentGoroutines-initialGoroutines)
    
    wg.Wait()
    finalGoroutines := runtime.NumGoroutine()
    fmt.Printf("  Final goroutines: %d\n", finalGoroutines)
}

// 协程泄漏分析
func demonstrateGoroutineLeakAnalysis() {
    fmt.Println("\n=== 协程泄漏分析 ===")
    
    // 1. 模拟协程泄漏
    fmt.Println("1. 模拟协程泄漏:")
    
    initialCount := runtime.NumGoroutine()
    fmt.Printf("  Initial goroutines: %d\n", initialCount)
    
    // 泄漏的goroutine
    for i := 0; i < 100; i++ {
        go func(id int) {
            for {
                time.Sleep(time.Second) // 永远不退出
                _ = id
            }
        }(i)
    }
    
    time.Sleep(100 * time.Millisecond)
    currentCount := runtime.NumGoroutine()
    fmt.Printf("  After leak creation: %d\n", currentCount)
    fmt.Printf("  Leaked goroutines: %d\n", currentCount-initialCount)
    
    // 2. 泄漏检测工具
    fmt.Println("\n2. 泄漏检测工具:")
    
    // 使用第三方库检测泄漏
    fmt.Println("  Use 'go.uber.org/goleak' for goroutine leak detection:")
    fmt.Println("  import go.uber.org/goleak")
    fmt.Println("  defer goleak.VerifyNone(t) // in tests")
    
    // 手动泄漏检测
    type LeakDetector struct {
        initialCount int
        timeout      time.Duration
    }
    
    func NewLeakDetector() *LeakDetector {
        return &LeakDetector{
            initialCount: runtime.NumGoroutine(),
            timeout:      5 * time.Second,
        }
    }
    
    func (ld *LeakDetector) Check() error {
        time.Sleep(ld.timeout)
        currentCount := runtime.NumGoroutine()
        if currentCount > ld.initialCount {
            return fmt.Errorf("potential goroutine leak: %d -> %d", 
                ld.initialCount, currentCount)
        }
        return nil
    }
    
    detector := NewLeakDetector()
    go func() {
        time.Sleep(2 * time.Second)
    }()
    
    if err := detector.Check(); err != nil {
        fmt.Printf("  %v\n", err)
    } else {
        fmt.Println("  No goroutine leak detected")
    }
}

// 协程性能分析
func demonstrateGoroutinePerformanceAnalysis() {
    fmt.Println("\n=== 协程性能分析 ===")
    
    // 1. 协程创建开销
    fmt.Println("1. 协程创建开销:")
    
    // 测量goroutine创建时间
    start := time.Now()
    var wg sync.WaitGroup
    for i := 0; i < 10000; i++ {
        wg.Add(1)
        go func() {
            defer wg.Done()
        }()
    }
    wg.Wait()
    creationTime := time.Since(start)
    
    fmt.Printf("  Created 10000 goroutines in: %v\n", creationTime)
    fmt.Printf("  Average creation time: %v\n", creationTime/10000)
    
    // 2. 协程调度分析
    fmt.Println("\n2. 协程调度分析:")
    
    // 启用调度器跟踪
    fmt.Println("  Use 'GODEBUG=schedtrace=1000' for scheduler tracing")
    fmt.Println("  Use 'GODEBUG=scheddetail=1' for detailed scheduler info")
    
    // 模拟调度场景
    var mutex sync.Mutex
    var counter int
    
    start = time.Now()
    var schedWg sync.WaitGroup
    for i := 0; i < 1000; i++ {
        schedWg.Add(1)
        go func() {
            defer schedWg.Done()
            for j := 0; j < 100; j++ {
                mutex.Lock()
                counter++
                mutex.Unlock()
                time.Sleep(time.Microsecond) // 模拟I/O等待
            }
        }()
    }
    schedWg.Wait()
    schedTime := time.Since(start)
    
    fmt.Printf("  Counter final value: %d\n", counter)
    fmt.Printf("  Scheduling time: %v\n", schedTime)
}

// 协程使用模式分析
func demonstrateGoroutineUsagePatterns() {
    fmt.Println("\n=== 协程使用模式分析 ===")
    
    // 1. 工作池模式
    fmt.Println("1. 工作池模式:")
    
    type Job struct {
        ID   int
        Data int
    }
    
    type Result struct {
        JobID int
        Value int
    }
    
    // 不使用工作池
    start := time.Now()
    var results []Result
    for i := 0; i < 10000; i++ {
        result := Result{
            JobID: i,
            Value: i * 2,
        }
        results = append(results, result)
    }
    noPoolTime := time.Since(start)
    
    // 使用工作池
    jobQueue := make(chan Job, 100)
    resultQueue := make(chan Result, 100)
    
    // 启动工作goroutine
    var workerWg sync.WaitGroup
    for i := 0; i < 10; i++ {
        workerWg.Add(1)
        go func() {
            defer workerWg.Done()
            for job := range jobQueue {
                result := Result{
                    JobID: job.ID,
                    Value: job.Data * 2,
                }
                resultQueue <- result
            }
        }()
    }
    
    // 启动结果收集goroutine
    var collectorWg sync.WaitGroup
    collectorWg.Add(1)
    go func() {
        defer collectorWg.Done()
        count := 0
        for result := range resultQueue {
            _ = result.Value
            count++
            if count >= 10000 {
                break
            }
        }
    }()
    
    start = time.Now()
    // 发送工作
    for i := 0; i < 10000; i++ {
        jobQueue <- Job{ID: i, Data: i}
    }
    close(jobQueue)
    
    workerWg.Wait()
    close(resultQueue)
    collectorWg.Wait()
    
    poolTime := time.Since(start)
    
    fmt.Printf("  Without work pool: %v\n", noPoolTime)
    fmt.Printf("  With work pool: %v\n", poolTime)
    fmt.Printf("  Work pool improvement: %.2fx\n", float64(noPoolTime)/float64(poolTime))
    
    // 2. 扇出扇入模式
    fmt.Println("\n2. 扇出扇入模式:")
    
    // 扇出处理
    func fanOut(input <-chan int, numWorkers int) []<-chan string {
        outputs := make([]<-chan string, numWorkers)
        
        for i := 0; i < numWorkers; i++ {
            output := make(chan string, 10)
            outputs[i] = output
            
            workerID := i
            go func(out chan<- string) {
                defer close(out)
                for num := range input {
                    result := fmt.Sprintf("Worker-%d processed %d", workerID, num*num)
                    out <- result
                }
            }(output)
        }
        
        return outputs
    }
    
    // 扇入合并
    func fanIn(inputs ...<-chan string) <-chan string {
        output := make(chan string, 100)
        
        var fanInWg sync.WaitGroup
        fanInWg.Add(len(inputs))
        
        for _, input := range inputs {
            go func(in <-chan string) {
                defer fanInWg.Done()
                for msg := range in {
                    output <- msg
                }
            }(input)
        }
        
        go func() {
            fanInWg.Wait()
            close(output)
        }()
        
        return output
    }
    
    // 使用扇出扇入
    input := make(chan int, 100)
    go func() {
        for i := 1; i <= 1000; i++ {
            input <- i
        }
        close(input)
    }()
    
    outputs := fanOut(input, 5)
    merged := fanIn(outputs...)
    
    start = time.Now()
    count := 0
    for result := range merged {
        _ = result
        count++
    }
    fanTime := time.Since(start)
    
    fmt.Printf("  Fan-in/fan-out processed %d items in: %v\n", count, fanTime)
}

// 协程状态分析
func demonstrateGoroutineStateAnalysis() {
    fmt.Println("\n=== 协程状态分析 ===")
    
    // 1. 协程状态监控
    fmt.Println("1. 协程状态监控:")
    
    // 启动不同状态的goroutine
    var wg sync.WaitGroup
    
    // 运行中的goroutine
    for i := 0; i < 50; i++ {
        wg.Add(1)
        go func(id int) {
            defer wg.Done()
            for {
                time.Sleep(time.Millisecond)
                _ = id
            }
        }(i)
    }
    
    // 等待中的goroutine
    var mutex sync.Mutex
    for i := 0; i < 50; i++ {
        wg.Add(1)
        go func(id int) {
            defer wg.Done()
            mutex.Lock()
            time.Sleep(100 * time.Millisecond)
            mutex.Unlock()
            _ = id
        }(i)
    }
    
    // I/O等待的goroutine
    for i := 0; i < 50; i++ {
        wg.Add(1)
        go func(id int) {
            defer wg.Done()
            time.Sleep(time.Second) // 模拟I/O等待
            _ = id
        }(i)
    }
    
    time.Sleep(100 * time.Millisecond)
    fmt.Printf("  Total goroutines: %d\n", runtime.NumGoroutine())
    
    // 2. 协程栈分析
    fmt.Println("\n2. 协程栈分析:")
    
    fmt.Println("  Use 'GOTRACEBACK=all' for full stack traces")
    fmt.Println("  Use 'GOTRACEBACK=system' for system goroutines")
    fmt.Println("  Use 'GOTRACEBACK=single' for single goroutine")
    
    // 显示当前goroutine信息
    fmt.Printf("  NumCPU: %d\n", runtime.NumCPU())
    fmt.Printf("  GOMAXPROCS: %d\n", runtime.GOMAXPROCS(0))
    fmt.Printf("  NumGoroutine: %d\n", runtime.NumGoroutine())
    
    wg.Wait()
}

// 协程分析工具使用
func demonstrateGoroutineAnalysisTools() {
    fmt.Println("\n=== 协程分析工具使用 ===")
    
    // 1. pprof goroutine分析
    fmt.Println("1. pprof goroutine分析:")
    
    fmt.Println("  Available endpoints:")
    fmt.Println("    http://localhost:6060/debug/pprof/goroutine - 当前goroutine")
    fmt.Println("    http://localhost:6060/debug/pprof/goroutine?debug=1 - 文本格式")
    fmt.Println("    http://localhost:6060/debug/pprof/goroutine?debug=2 - 详细格式")
    
    // 2. 命令行分析
    fmt.Println("\n2. 命令行分析:")
    
    fmt.Println("  go tool pprof http://localhost:6060/debug/pprof/goroutine")
    fmt.Println("  Common commands:")
    fmt.Println("    top - 显示最活跃的goroutine")
    fmt.Println("    list <function> - 显示函数调用")
    fmt.Println("    web - 生成调用图")
    fmt.Println("    traces - 显示goroutine堆栈")
    fmt.Println("    peek <function> - 查看函数调用")
    
    // 3. 实时监控
    fmt.Println("\n3. 实时监控:")
    
    // 启动监控goroutine
    go func() {
        ticker := time.NewTicker(5 * time.Second)
        defer ticker.Stop()
        
        for range ticker.C {
            fmt.Printf("  Goroutine Stats - Count: %d, NumCPU: %d, GOMAXPROCS: %d\n",
                runtime.NumGoroutine(), runtime.NumCPU(), runtime.GOMAXPROCS(0))
        }
    }()
    
    // 启动一些goroutine供分析
    for i := 0; i < 200; i++ {
        go func(id int) {
            for {
                time.Sleep(time.Second)
                _ = id
            }
        }(i)
    }
    
    fmt.Println("  Started 200 goroutines for analysis")
}

// 协程性能监控
func demonstrateGoroutineMonitoring() {
    fmt.Println("\n=== 协程性能监控 ===")
    
    // 1. 自定义监控指标
    fmt.Println("1. 自定义监控指标:")
    
    type GoroutineMetrics struct {
        TotalCreated int64
        PeakCount    int
        ActiveCount  int
        mutex        sync.RWMutex
    }
    
    metrics := &GoroutineMetrics{}
    
    // 监控goroutine创建
    func monitoredGoroutine(fn func()) {
        metrics.mutex.Lock()
        metrics.TotalCreated++
        current := runtime.NumGoroutine()
        if current > metrics.PeakCount {
            metrics.PeakCount = current
        }
        metrics.ActiveCount = current
        metrics.mutex.Unlock()
        
        go fn()
    }
    
    // 使用监控
    for i := 0; i < 1000; i++ {
        monitoredGoroutine(func() {
            time.Sleep(100 * time.Millisecond)
        })
    }
    
    time.Sleep(200 * time.Millisecond)
    
    metrics.mutex.RLock()
    fmt.Printf("  Total created: %d\n", metrics.TotalCreated)
    fmt.Printf("  Peak count: %d\n", metrics.PeakCount)
    fmt.Printf("  Current active: %d\n", metrics.ActiveCount)
    metrics.mutex.RUnlock()
    
    // 2. 性能告警
    fmt.Println("\n2. 性能告警:")
    
    // 启动告警监控
    go func() {
        ticker := time.NewTicker(10 * time.Second)
        defer ticker.Stop()
        
        for range ticker.C {
            count := runtime.NumGoroutine()
            if count > 10000 {
                fmt.Printf("  WARNING: High goroutine count: %d\n", count)
            }
            
            var m runtime.MemStats
            runtime.ReadMemStats(&m)
            if m.NumGC > 1000 {
                fmt.Printf("  WARNING: High GC count: %d\n", m.NumGC)
            }
        }
    }()
    
    fmt.Println("  Started performance monitoring")
}

// 协程最佳实践
func goroutineBestPractices() {
    fmt.Println("\n=== 协程最佳实践 ===")
    
    fmt.Println("1. 协程管理:")
    fmt.Println("   - 合理控制goroutine数量")
    fmt.Println("   - 使用context管理生命周期")
    fmt.Println("   - 及时清理资源")
    fmt.Println("   - 避免goroutine泄漏")
    
    fmt.Println("\n2. 并发模式:")
    fmt.Println("   - 工作池模式")
    fmt.Println("   - 扇出扇入模式")
    fmt.Println("   - 生产者消费者模式")
    fmt.Println("   - 信号量模式")
    
    fmt.Println("\n3. 性能优化:")
    fmt.Println("   - 减少锁竞争")
    fmt.Println("   - 合理使用channel")
    fmt.Println("   - 批量处理")
    fmt.Println("   - 避免频繁创建goroutine")
    
    fmt.Println("\n4. 监控和调试:")
    fmt.Println("   - 实时监控goroutine数量")
    fmt.Println("   - 使用pprof分析")
    fmt.Println("   - 启用调度器跟踪")
    fmt.Println("   - 设置性能告警")
    
    fmt.Println("\n5. 工具使用:")
    fmt.Println("   - go tool pprof")
    fmt.Println("   - net/http/pprof")
    fmt.Println("   - runtime包")
    fmt.Println("   - 第三方工具如goleak")
    
    fmt.Println("\n6. 常见陷阱:")
    fmt.Println("   - goroutine泄漏")
    fmt.Println("   - 死锁")
    fmt.Println("   - 资源竞争")
    fmt.Println("   - 过度并发")
    
    fmt.Println("\n7. 生产环境考虑:")
    fmt.Println("   - 资源限制")
    fmt.Println("   - 故障恢复")
    fmt.Println("   - 性能基准")
    fmt.Println("   - 自动化监控")
    
    fmt.Println("\n8. 调试技巧:")
    fmt.Println("   - 使用GOTRACEBACK")
    fmt.Println("   - 分析堆栈跟踪")
    fmt.Println("   - 监控资源使用")
    fmt.Println("   - 性能回归测试")
}

func main() {
    demonstrateGoroutineBasicAnalysis()
    demonstrateGoroutineLeakAnalysis()
    demonstrateGoroutinePerformanceAnalysis()
    demonstrateGoroutineUsagePatterns()
    demonstrateGoroutineStateAnalysis()
    demonstrateGoroutineAnalysisTools()
    demonstrateGoroutineMonitoring()
    goroutineBestPractices()
    
    // 保持程序运行以便访问pprof
    fmt.Println("\nServer running... Press Ctrl+C to exit")
    select {}
}
```

### 性能调优实践

```go
package main

import (
    "fmt"
    "log"
    "net/http"
    "_net/http/pprof"
    "runtime"
    "runtime/pprof"
    "sync"
    "sync/atomic"
    "time"
)

// 性能调优基础
func demonstratePerformanceTuningBasics() {
    fmt.Println("=== 性能调优实践 ===")
    
    // 1. 建立性能基线
    fmt.Println("1. 建立性能基线:")
    
    // 基准测试函数
    func benchmarkFunction(name string, fn func()) time.Duration {
        start := time.Now()
        fn()
        duration := time.Since(start)
        fmt.Printf("  %s: %v\n", name, duration)
        return duration
    }
    
    // 建立基线
    baseline := benchmarkFunction("Baseline", func() {
        // 模拟业务逻辑
        for i := 0; i < 1000000; i++ {
            _ = i * i
        }
    })
    
    // 优化后测试
    optimized := benchmarkFunction("Optimized", func() {
        // 优化后的业务逻辑
        result := 0
        for i := 0; i < 1000000; i++ {
            result += i * i
        }
        _ = result
    })
    
    fmt.Printf("  Improvement: %.2fx\n", float64(baseline)/float64(optimized))
    
    // 2. 性能分析流程
    fmt.Println("\n2. 性能分析流程:")
    fmt.Println("  Step 1: Identify performance bottlenecks")
    fmt.Println("  Step 2: Collect profiling data")
    fmt.Println("  Step 3: Analyze hotspots")
    fmt.Println("  Step 4: Implement optimizations")
    fmt.Println("  Step 5: Verify improvements")
    fmt.Println("  Step 6: Monitor in production")
}

// 系统级调优
func demonstrateSystemLevelTuning() {
    fmt.Println("\n=== 系统级调优 ===")
    
    // 1. GOMAXPROCS调优
    fmt.Println("1. GOMAXPROCS调优:")
    
    originalProcs := runtime.GOMAXPROCS(0)
    fmt.Printf("  Original GOMAXPROCS: %d\n", originalProcs)
    fmt.Printf("  NumCPU: %d\n", runtime.NumCPU())
    
    // 测试不同GOMAXPROCS设置
    testGOMAXPROCS := []int{1, 2, runtime.NumCPU(), runtime.NumCPU() * 2}
    
    for _, procs := range testGOMAXPROCS {
        runtime.GOMAXPROCS(procs)
        
        start := time.Now()
        var wg sync.WaitGroup
        for i := 0; i < procs; i++ {
            wg.Add(1)
            go func() {
                defer wg.Done()
                cpuIntensiveTask()
            }()
        }
        wg.Wait()
        duration := time.Since(start)
        
        fmt.Printf("  GOMAXPROCS=%d: %v\n", procs, duration)
    }
    
    // 恢复原始设置
    runtime.GOMAXPROCS(originalProcs)
    
    // 2. GC调优
    fmt.Println("\n2. GC调优:")
    
    // 获取当前GC设置
    originalGCPercent := debug.SetGCPercent(-1) // -1表示只读取
    fmt.Printf("  Original GOGC: %d\n", originalGCPercent)
    
    // 测试不同GC百分比
    testGCPercent := []int{20, 50, 100, 200}
    
    for _, percent := range testGCPercent {
        debug.SetGCPercent(percent)
        
        var m1, m2 runtime.MemStats
        runtime.ReadMemStats(&m1)
        
        // 执行内存密集型任务
        memoryIntensiveTask()
        
        runtime.ReadMemStats(&m2)
        gcCount := m2.NumGC - m1.NumGC
        gcPause := time.Duration(m2.PauseTotalNs - m1.PauseTotalNs)
        
        fmt.Printf("  GOGC=%d: GC count=%d, Pause=%v\n", percent, gcCount, gcPause)
    }
    
    // 恢复原始设置
    debug.SetGCPercent(originalGCPercent)
}

func cpuIntensiveTask() {
    result := 0
    for i := 0; i < 1000000; i++ {
        result += i * i
    }
    _ = result
}

func memoryIntensiveTask() {
    data := make([][]int, 10000)
    for i := range data {
        data[i] = make([]int, 1000)
    }
    _ = len(data)
}

// 应用级调优
func demonstrateApplicationLevelTuning() {
    fmt.Println("\n=== 应用级调优 ===")
    
    // 1. 缓存优化
    fmt.Println("1. 缓存优化:")
    
    // 无缓存版本
    func noCacheVersion(n int) int {
        // 模拟耗时计算
        time.Sleep(time.Microsecond)
        return n * n
    }
    
    // 有缓存版本
    var cache = make(map[int]int)
    var cacheMutex sync.RWMutex
    
    func cachedVersion(n int) int {
        cacheMutex.RLock()
        if result, exists := cache[n]; exists {
            cacheMutex.RUnlock()
            return result
        }
        cacheMutex.RUnlock()
        
        // 计算结果
        time.Sleep(time.Microsecond)
        result := n * n
        
        // 缓存结果
        cacheMutex.Lock()
        cache[n] = result
        cacheMutex.Unlock()
        
        return result
    }
    
    // 性能测试
    start := time.Now()
    for i := 0; i < 1000; i++ {
        _ = noCacheVersion(i % 100)
    }
    noCacheTime := time.Since(start)
    
    start = time.Now()
    for i := 0; i < 1000; i++ {
        _ = cachedVersion(i % 100)
    }
    cacheTime := time.Since(start)
    
    fmt.Printf("  No cache time: %v\n", noCacheTime)
    fmt.Printf("  Cache time: %v\n", cacheTime)
    fmt.Printf("  Cache improvement: %.2fx\n", float64(noCacheTime)/float64(cacheTime))
    
    // 2. 批量处理优化
    fmt.Println("\n2. 批量处理优化:")
    
    // 单个处理
    func singleProcess(items []int) []int {
        results := make([]int, len(items))
        for i, item := range items {
            results[i] = item * 2
        }
        return results
    }
    
    // 批量处理
    func batchProcess(items []int, batchSize int) []int {
        results := make([]int, len(items))
        
        for i := 0; i < len(items); i += batchSize {
            end := i + batchSize
            if end > len(items) {
                end = len(items)
            }
            
            // 批量处理
            for j := i; j < end; j++ {
                results[j] = items[j] * 2
            }
        }
        
        return results
    }
    
    // 测试数据
    testItems := make([]int, 100000)
    for i := range testItems {
        testItems[i] = i
    }
    
    start = time.Now()
    singleResults := singleProcess(testItems)
    singleTime := time.Since(start)
    
    start = time.Now()
    batchResults := batchProcess(testItems, 1000)
    batchTime := time.Since(start)
    
    fmt.Printf("  Single processing: %v (results: %d)\n", singleTime, len(singleResults))
    fmt.Printf("  Batch processing: %v (results: %d)\n", batchTime, len(batchResults))
    fmt.Printf("  Batch improvement: %.2fx\n", float64(singleTime)/float64(batchTime))
}

// 并发调优
func demonstrateConcurrencyTuning() {
    fmt.Println("\n=== 并发调优 ===")
    
    // 1. 工作池调优
    fmt.Println("1. 工作池调优:")
    
    type Job struct {
        ID   int
        Data int
    }
    
    type Result struct {
        JobID int
        Value int
    }
    
    // 不同工作池大小的测试
    workerCounts := []int{1, 5, 10, 20, 50}
    
    for _, workerCount := range workerCounts {
        start := time.Now()
        
        jobQueue := make(chan Job, 1000)
        resultQueue := make(chan Result, 1000)
        
        // 启动工作goroutine
        var wg sync.WaitGroup
        for i := 0; i < workerCount; i++ {
            wg.Add(1)
            go func() {
                defer wg.Done()
                for job := range jobQueue {
                    result := Result{
                        JobID: job.ID,
                        Value: job.Data * 2,
                    }
                    resultQueue <- result
                }
            }()
        }
        
        // 启动结果收集
        var resultWg sync.WaitGroup
        resultWg.Add(1)
        go func() {
            defer resultWg.Done()
            count := 0
            for result := range resultQueue {
                _ = result.Value
                count++
                if count >= 10000 {
                    break
                }
            }
        }()
        
        // 发送工作
        go func() {
            for i := 0; i < 10000; i++ {
                jobQueue <- Job{ID: i, Data: i}
            }
            close(jobQueue)
        }()
        
        wg.Wait()
        close(resultQueue)
        resultWg.Wait()
        
        duration := time.Since(start)
        fmt.Printf("  Worker count %d: %v\n", workerCount, duration)
    }
    
    // 2. 锁优化
    fmt.Println("\n2. 锁优化:")
    
    // 普通互斥锁
    var mutex sync.Mutex
    var counter1 int64
    
    start := time.Now()
    var lockWg sync.WaitGroup
    for i := 0; i < 1000; i++ {
        lockWg.Add(1)
        go func() {
            defer lockWg.Done()
            for j := 0; j < 1000; j++ {
                mutex.Lock()
                counter1++
                mutex.Unlock()
            }
        }()
    }
    lockWg.Wait()
    mutexTime := time.Since(start)
    
    // 原子操作
    var counter2 int64
    
    start = time.Now()
    var atomicWg sync.WaitGroup
    for i := 0; i < 1000; i++ {
        atomicWg.Add(1)
        go func() {
            defer atomicWg.Done()
            for j := 0; j < 1000; j++ {
                atomic.AddInt64(&counter2, 1)
            }
        }()
    }
    atomicWg.Wait()
    atomicTime := time.Since(start)
    
    fmt.Printf("  Mutex time: %v (counter: %d)\n", mutexTime, counter1)
    fmt.Printf("  Atomic time: %v (counter: %d)\n", atomicTime, counter2)
    fmt.Printf("  Atomic improvement: %.2fx\n", float64(mutexTime)/float64(atomicTime))
}

// 性能监控和告警
func demonstratePerformanceMonitoring() {
    fmt.Println("\n=== 性能监控和告警 ===")
    
    // 1. 实时性能监控
    fmt.Println("1. 实时性能监控:")
    
    type PerformanceMetrics struct {
        RequestsPerSecond int64
        AverageLatency    time.Duration
        ErrorRate         float64
        MemoryUsage       uint64
        GoroutineCount    int
        mutex             sync.RWMutex
    }
    
    metrics := &PerformanceMetrics{}
    
    // 启动监控goroutine
    go func() {
        ticker := time.NewTicker(10 * time.Second)
        defer ticker.Stop()
        
        for range ticker.C {
            metrics.mutex.RLock()
            fmt.Printf("  Performance Metrics - RPS: %d, Latency: %v, ErrorRate: %.2f%%, Memory: %dMB, Goroutines: %d\n",
                metrics.RequestsPerSecond,
                metrics.AverageLatency,
                metrics.ErrorRate*100,
                metrics.MemoryUsage/1024/1024,
                metrics.GoroutineCount)
            metrics.mutex.RUnlock()
        }
    }()
    
    // 模拟业务处理
    go func() {
        ticker := time.NewTicker(time.Second)
        defer ticker.Stop()
        
        var requestCount int64
        var totalLatency time.Duration
        var errorCount int64
        
        for range ticker.C {
            // 模拟处理请求
            start := time.Now()
            for i := 0; i < 100; i++ {
                if i%1000 == 0 { // 0.1%错误率
                    errorCount++
                }
                time.Sleep(time.Millisecond) // 模拟处理时间
            }
            latency := time.Since(start)
            
            requestCount += 100
            totalLatency += latency
            
            // 更新指标
            metrics.mutex.Lock()
            metrics.RequestsPerSecond = 100
            metrics.AverageLatency = latency / 100
            metrics.ErrorRate = float64(errorCount) / float64(requestCount)
            
            var m runtime.MemStats
            runtime.ReadMemStats(&m)
            metrics.MemoryUsage = m.Alloc
            metrics.GoroutineCount = runtime.NumGoroutine()
            metrics.mutex.Unlock()
        }
    }()
    
    fmt.Println("  Started performance monitoring")
    
    // 2. 性能告警
    fmt.Println("\n2. 性能告警:")
    
    // 启动告警监控
    go func() {
        ticker := time.NewTicker(30 * time.Second)
        defer ticker.Stop()
        
        for range ticker.C {
            metrics.mutex.RLock()
            
            // 告警条件
            if metrics.AverageLatency > 100*time.Millisecond {
                fmt.Printf("  ALERT: High latency - %v\n", metrics.AverageLatency)
            }
            
            if metrics.ErrorRate > 0.05 { // 5%错误率
                fmt.Printf("  ALERT: High error rate - %.2f%%\n", metrics.ErrorRate*100)
            }
            
            if metrics.MemoryUsage > 500*1024*1024 { // 500MB
                fmt.Printf("  ALERT: High memory usage - %dMB\n", metrics.MemoryUsage/1024/1024)
            }
            
            if metrics.GoroutineCount > 10000 {
                fmt.Printf("  ALERT: High goroutine count - %d\n", metrics.GoroutineCount)
            }
            
            metrics.mutex.RUnlock()
        }
    }()
    
    fmt.Println("  Started alert monitoring")
}

// 性能调优最佳实践
func performanceTuningBestPractices() {
    fmt.Println("\n=== 性能调优最佳实践 ===")
    
    fmt.Println("1. 调优流程:")
    fmt.Println("   - 建立性能基线")
    fmt.Println("   - 识别性能瓶颈")
    fmt.Println("   - 制定优化方案")
    fmt.Println("   - 实施优化措施")
    fmt.Println("   - 验证优化效果")
    fmt.Println("   - 持续监控改进")
    
    fmt.Println("\n2. 系统级优化:")
    fmt.Println("   - 合理设置GOMAXPROCS")
    fmt.Println("   - 调优GC参数")
    fmt.Println("   - 优化内存分配")
    fmt.Println("   - 减少系统调用")
    fmt.Println("   - 使用SSD存储")
    
    fmt.Println("\n3. 应用级优化:")
    fmt.Println("   - 算法和数据结构优化")
    fmt.Println("   - 缓存策略实施")
    fmt.Println("   - 批量处理")
    fmt.Println("   - 异步处理")
    fmt.Println("   - 资源池化")
    
    fmt.Println("\n4. 并发优化:")
    fmt.Println("   - 合理的goroutine数量")
    fmt.Println("   - 减少锁竞争")
    fmt.Println("   - 使用无锁数据结构")
    fmt.Println("   - 工作池模式")
    fmt.Println("   - 扇出扇入模式")
    
    fmt.Println("\n5. 监控和告警:")
    fmt.Println("   - 实时性能监控")
    fmt.Println("   - 关键指标告警")
    fmt.Println("   - 性能趋势分析")
    fmt.Println("   - 异常检测")
    fmt.Println("   - 自动化运维")
    
    fmt.Println("\n6. 工具使用:")
    fmt.Println("   - go tool pprof")
    fmt.Println("   - runtime/pprof")
    fmt.Println("   - net/http/pprof")
    fmt.Println("   - 基准测试")
    fmt.Println("   - 火焰图分析")
    
    fmt.Println("\n7. 生产环境考虑:")
    fmt.Println("   - 灰度发布")
    fmt.Println("   - A/B测试")
    fmt.Println("   - 容量规划")
    fmt.Println("   - 故障恢复")
    fmt.Println("   - 性能回归")
    
    fmt.Println("\n8. 常见陷阱:")
    fmt.Println("   - 过早优化")
    fmt.Println("   - 忽视算法复杂度")
    fmt.Println("   - 不合理的并发使用")
    fmt.Println("   - 缺乏性能测试")
    fmt.Println("   - 忽视监控告警")
}

func main() {
    demonstratePerformanceTuningBasics()
    demonstrateSystemLevelTuning()
    demonstrateApplicationLevelTuning()
    demonstrateConcurrencyTuning()
    demonstratePerformanceMonitoring()
    performanceTuningBestPractices()
}
```

### 基准测试编写

```go
package main

import (
    "fmt"
    "math/rand"
    "runtime"
    "sort"
    "sync"
    "testing"
    "time"
)

// 基准测试基础
func demonstrateBasicBenchmarking() {
    fmt.Println("=== 基准测试编写 ===")
    
    // 1. 基本基准测试结构
    fmt.Println("1. 基本基准测试结构:")
    
    fmt.Println("func BenchmarkExample(b *testing.B) {")
    fmt.Println("    for i := 0; i < b.N; i++ {")
    fmt.Println("        // 要测试的代码")
    fmt.Println("    }")
    fmt.Println("}")
    
    // 2. 基准测试运行
    fmt.Println("\n2. 基准测试运行:")
    fmt.Println("  go test -bench=.")
    fmt.Println("  go test -bench=BenchmarkExample")
    fmt.Println("  go test -bench=. -benchmem")
    fmt.Println("  go test -bench=. -count=5")
    fmt.Println("  go test -bench=. -cpuprofile=cpu.prof")
    fmt.Println("  go test -bench=. -memprofile=mem.prof")
}

// 不同类型的基准测试
func demonstrateBenchmarkTypes() {
    fmt.Println("\n=== 不同类型的基准测试 ===")
    
    // 1. CPU密集型基准测试
    fmt.Println("1. CPU密集型基准测试:")
    
    // 示例：排序算法比较
    func BenchmarkQuickSort(b *testing.B) {
        data := make([]int, 10000)
        for i := range data {
            data[i] = rand.Intn(1000000)
        }
        
        b.ResetTimer()
        for i := 0; i < b.N; i++ {
            // 每次测试都使用相同的数据
            testData := make([]int, len(data))
            copy(testData, data)
            
            quickSort(testData, 0, len(testData)-1)
        }
    }
    
    func BenchmarkStandardSort(b *testing.B) {
        data := make([]int, 10000)
        for i := range data {
            data[i] = rand.Intn(1000000)
        }
        
        b.ResetTimer()
        for i := 0; i < b.N; i++ {
            testData := make([]int, len(data))
            copy(testData, data)
            
            sort.Ints(testData)
        }
    }
    
    fmt.Println("  Implemented QuickSort vs StandardSort benchmarks")
    
    // 2. 内存密集型基准测试
    fmt.Println("\n2. 内存密集型基准测试:")
    
    func BenchmarkSliceAllocation(b *testing.B) {
        b.ReportAllocs()
        for i := 0; i < b.N; i++ {
            slice := make([]int, 10000)
            _ = len(slice)
        }
    }
    
    func BenchmarkPreallocatedSlice(b *testing.B) {
        b.ReportAllocs()
        slice := make([]int, 0, 10000)
        for i := 0; i < b.N; i++ {
            slice = slice[:0] // 重置但保留容量
            for j := 0; j < 10000; j++ {
                slice = append(slice, j)
            }
        }
    }
    
    fmt.Println("  Implemented slice allocation benchmarks")
    
    // 3. I/O密集型基准测试
    fmt.Println("\n3. I/O密集型基准测试:")
    
    func BenchmarkFileSyncWrite(b *testing.B) {
        b.ReportAllocs()
        for i := 0; i < b.N; i++ {
            // 模拟同步写入
            time.Sleep(time.Microsecond)
        }
    }
    
    func BenchmarkAsyncWrite(b *testing.B) {
        b.ReportAllocs()
        var wg sync.WaitGroup
        for i := 0; i < b.N; i++ {
            wg.Add(1)
            go func() {
                defer wg.Done()
                time.Sleep(time.Microsecond)
            }()
        }
        wg.Wait()
    }
    
    fmt.Println("  Implemented I/O operation benchmarks")
}

// 快速排序实现
func quickSort(arr []int, low, high int) {
    if low < high {
        pi := partition(arr, low, high)
        quickSort(arr, low, pi-1)
        quickSort(arr, pi+1, high)
    }
}

func partition(arr []int, low, high int) int {
    pivot := arr[high]
    i := low - 1
    for j := low; j < high; j++ {
        if arr[j] < pivot {
            i++
            arr[i], arr[j] = arr[j], arr[i]
        }
    }
    arr[i+1], arr[high] = arr[high], arr[i+1]
    return i + 1
}

// 高级基准测试技巧
func demonstrateAdvancedBenchmarking() {
    fmt.Println("\n=== 高级基准测试技巧 ===")
    
    // 1. 子基准测试
    fmt.Println("1. 子基准测试:")
    
    func BenchmarkAlgorithmSuite(b *testing.B) {
        algorithms := []struct {
            name string
            fn   func([]int)
        }{
            {"BubbleSort", bubbleSort},
            {"QuickSort", func(arr []int) { quickSort(arr, 0, len(arr)-1) }},
            {"MergeSort", mergeSort},
        }
        
        data := make([]int, 1000)
        for i := range data {
            data[i] = rand.Intn(10000)
        }
        
        for _, alg := range algorithms {
            b.Run(alg.name, func(b *testing.B) {
                for i := 0; i < b.N; i++ {
                    testData := make([]int, len(data))
                    copy(testData, data)
                    alg.fn(testData)
                }
            })
        }
    }
    
    fmt.Println("  Implemented benchmark suite with sub-benchmarks")
    
    // 2. 并行基准测试
    fmt.Println("\n2. 并行基准测试:")
    
    func BenchmarkParallelWork(b *testing.B) {
        b.RunParallel(func(pb *testing.PB) {
            for pb.Next() {
                // 并行执行的工作
                result := 0
                for i := 0; i < 1000; i++ {
                    result += i * i
                }
                _ = result
            }
        })
    }
    
    fmt.Println("  Implemented parallel benchmark")
    
    // 3. 基准测试参数化
    fmt.Println("\n3. 基准测试参数化:")
    
    func BenchmarkWithSizes(b *testing.B) {
        sizes := []int{100, 1000, 10000, 100000}
        
        for _, size := range sizes {
            b.Run(fmt.Sprintf("Size%d", size), func(b *testing.B) {
                data := make([]int, size)
                for i := range data {
                    data[i] = rand.Intn(size)
                }
                
                b.ResetTimer()
                for i := 0; i < b.N; i++ {
                    testData := make([]int, len(data))
                    copy(testData, data)
                    sort.Ints(testData)
                }
            })
        }
    }
    
    fmt.Println("  Implemented parameterized benchmark")
}

// 冒泡排序实现
func bubbleSort(arr []int) {
    n := len(arr)
    for i := 0; i < n-1; i++ {
        for j := 0; j < n-i-1; j++ {
            if arr[j] > arr[j+1] {
                arr[j], arr[j+1] = arr[j+1], arr[j]
            }
        }
    }
}

// 归并排序实现
func mergeSort(arr []int) {
    if len(arr) <= 1 {
        return
    }
    
    mid := len(arr) / 2
    left := make([]int, mid)
    right := make([]int, len(arr)-mid)
    
    copy(left, arr[:mid])
    copy(right, arr[mid:])
    
    mergeSort(left)
    mergeSort(right)
    merge(arr, left, right)
}

func merge(arr, left, right []int) {
    i, j, k := 0, 0, 0
    
    for i < len(left) && j < len(right) {
        if left[i] <= right[j] {
            arr[k] = left[i]
            i++
        } else {
            arr[k] = right[j]
            j++
        }
        k++
    }
    
    for i < len(left) {
        arr[k] = left[i]
        i++
        k++
    }
    
    for j < len(right) {
        arr[k] = right[j]
        j++
        k++
    }
}

// 基准测试结果分析
func demonstrateBenchmarkAnalysis() {
    fmt.Println("\n=== 基准测试结果分析 ===")
    
    // 1. 结果解读
    fmt.Println("1. 结果解读:")
    fmt.Println("  BenchmarkExample-8    1000000    1234 ns/op    2048 B/op    5 allocs/op")
    fmt.Println("  |                     |          |             |            |")
    fmt.Println("  |                     |          |             |            └─ 每次操作分配次数")
    fmt.Println("  |                     |          |             └─ 每次操作分配字节数")
    fmt.Println("  |                     |          └─ 每次操作纳秒数")
    fmt.Println("  |                     └─ 操作次数")
    fmt.Println("  └─ 基准测试名称-并发数")
    
    // 2. 性能比较
    fmt.Println("\n2. 性能比较:")
    
    // 模拟基准测试结果
    type BenchmarkResult struct {
        Name       string
        Operations int
        TimePerOp  time.Duration
        BytesPerOp int
        AllocsPerOp int
    }
    
    results := []BenchmarkResult{
        {"QuickSort", 100000, 1234 * time.Nanosecond, 2048, 5},
        {"StandardSort", 150000, 890 * time.Nanosecond, 1024, 2},
        {"MergeSort", 80000, 1567 * time.Nanosecond, 4096, 10},
    }
    
    fmt.Println("  Performance comparison:")
    for _, result := range results {
        fmt.Printf("    %s: %v/op, %d B/op, %d allocs/op\n", 
            result.Name, result.TimePerOp, result.BytesPerOp, result.AllocsPerOp)
    }
    
    // 3. 统计分析
    fmt.Println("\n3. 统计分析:")
    fmt.Println("  Use 'go test -bench=. -count=10' for multiple runs")
    fmt.Println("  Use 'go test -bench=. -benchtime=10s' for longer runs")
    fmt.Println("  Use 'go test -bench=. -timeout=30s' to set timeout")
    
    // 4. 基准测试稳定性
    fmt.Println("\n4. 基准测试稳定性:")
    
    func checkBenchmarkStability(b *testing.B, fn func()) {
        results := make([]time.Duration, 5)
        
        for i := 0; i < 5; i++ {
            b.Run(fmt.Sprintf("Run%d", i), func(b *testing.B) {
                start := time.Now()
                fn()
                results[i] = time.Since(start)
            })
        }
        
        // 计算平均值和标准差
        var sum time.Duration
        for _, result := range results {
            sum += result
        }
        avg := sum / time.Duration(len(results))
        
        fmt.Printf("  Average time: %v\n", avg)
        fmt.Printf("  Individual times: %v\n", results)
    }
    
    fmt.Println("  Implemented stability checking")
}

// 基准测试最佳实践
func demonstrateBenchmarkBestPractices() {
    fmt.Println("\n=== 基准测试最佳实践 ===")
    
    // 1. 测试设计
    fmt.Println("1. 测试设计:")
    fmt.Println("   - 测试真实的使用场景")
    fmt.Println("   - 避免测试过于简单或复杂")
    fmt.Println("   - 确保测试的可重复性")
    fmt.Println("   - 考虑边界条件")
    fmt.Println("   - 测试不同规模的数据")
    
    // 2. 性能考虑
    fmt.Println("\n2. 性能考虑:")
    fmt.Println("   - 预热避免冷启动影响")
    fmt.Println("   - 使用b.ResetTimer()重置计时器")
    fmt.Println("   - 使用b.StopTimer()/b.StartTimer()控制计时")
    fmt.Println("   - 避免在循环内进行不必要的操作")
    fmt.Println("   - 合理设置b.N的值")
    
    // 3. 内存分析
    fmt.Println("\n3. 内存分析:")
    fmt.Println("   - 使用b.ReportAllocs()报告内存分配")
    fmt.Println("   - 关注每次操作的内存分配")
    fmt.Println("   - 优化内存使用模式")
    fmt.Println("   - 避免内存泄漏")
    fmt.Println("   - 使用对象池减少分配")
    
    // 4. 并发测试
    fmt.Println("\n4. 并发测试:")
    fmt.Println("   - 使用b.RunParallel()进行并行测试")
    fmt.Println("   - 考虑不同并发级别的性能")
    fmt.Println("   - 避免竞态条件")
    fmt.Println("   - 测试锁竞争")
    fmt.Println("   - 验证线程安全性")
    
    // 5. 结果解释
    fmt.Println("\n5. 结果解释:")
    fmt.Println("   - 关注ns/op指标")
    fmt.Println("   - 分析内存分配模式")
    fmt.Println("   - 比较不同实现的性能")
    fmt.Println("   - 考虑统计显著性")
    fmt.Println("   - 识别性能回归")
    
    // 6. 工具使用
    fmt.Println("\n6. 工具使用:")
    fmt.Println("   - go test -bench=.")
    fmt.Println("   - go test -bench=. -benchmem")
    fmt.Println("   - go test -bench=. -cpuprofile")
    fmt.Println("   - go test -bench=. -memprofile")
    fmt.Println("   - go tool pprof分析profile")
    fmt.Println("   - benchstat比较不同版本")
    
    // 7. 持续集成
    fmt.Println("\n7. 持续集成:")
    fmt.Println("   - 将基准测试集成到CI/CD")
    fmt.Println("   - 设置性能回归阈值")
    fmt.Println("   - 自动化性能监控")
    fmt.Println("   - 生成性能报告")
    fmt.Println("   - 与历史数据对比")
    
    // 8. 常见陷阱
    fmt.Println("\n8. 常见陷阱:")
    fmt.Println("   - 忽视编译器优化")
    fmt.Println("   - 测试数据不具代表性")
    fmt.Println("   - 忽视系统负载影响")
    fmt.Println("   - 不正确的基准测试设计")
    fmt.Println("   - 缺乏统计分析")
}

// 实际基准测试示例
func demonstrateRealWorldBenchmarks() {
    fmt.Println("\n=== 实际基准测试示例 ===")
    
    // 1. Web服务基准测试
    fmt.Println("1. Web服务基准测试:")
    
    fmt.Println("  // 使用net/http/httptest进行HTTP基准测试")
    fmt.Println("  func BenchmarkHTTPHandler(b *testing.B) {")
    fmt.Println("      handler := MyHandler{}")
    fmt.Println("      server := httptest.NewServer(handler)")
    fmt.Println("      defer server.Close()")
    fmt.Println("      ")
    fmt.Println("      b.ResetTimer()")
    fmt.Println("      for i := 0; i < b.N; i++ {")
    fmt.Println("          http.Get(server.URL)")
    fmt.Println("      }")
    fmt.Println("  }")
    
    // 2. 数据库操作基准测试
    fmt.Println("\n2. 数据库操作基准测试:")
    
    fmt.Println("  // 使用database/sql进行数据库基准测试")
    fmt.Println("  func BenchmarkDatabaseQuery(b *testing.B) {")
    fmt.Println("      db, _ := sql.Open(\"sqlite3\", \":memory:\")")
    fmt.Println("      defer db.Close()")
    fmt.Println("      ")
    fmt.Println("      // 准备测试数据")
    fmt.Println("      b.ResetTimer()")
    fmt.Println("      for i := 0; i < b.N; i++ {")
    fmt.Println("          var result int")
    fmt.Println("          db.QueryRow(\"SELECT 1\").Scan(&result)")
    fmt.Println("      }")
    fmt.Println("  }")
    
    // 3. 缓存基准测试
    fmt.Println("\n3. 缓存基准测试:")
    
    fmt.Println("  // 测试不同缓存实现的性能")
    fmt.Println("  func BenchmarkCacheImplementations(b *testing.B) {")
    fmt.Println("      implementations := map[string]Cache{")
    fmt.Println("          \"sync.Map\": NewSyncMapCache(),")
    fmt.Println("          \"RWMutex\":  NewRWMutexCache(),")
    fmt.Println("          \"Sharded\":  NewShardedCache(16),")
    fmt.Println("      }")
    fmt.Println("      ")
    fmt.Println("      for name, cache := range implementations {")
    fmt.Println("          b.Run(name, func(b *testing.B) {")
    fmt.Println("              b.ResetTimer()")
    fmt.Println("              for i := 0; i < b.N; i++ {")
    fmt.Println("                  cache.Set(fmt.Sprintf(\"key%d\", i), i)")
    fmt.Println("                  cache.Get(fmt.Sprintf(\"key%d\", i))")
    fmt.Println("              }")
    fmt.Println("          })")
    fmt.Println("      }")
    fmt.Println("  }")
    
    // 4. 序列化基准测试
    fmt.Println("\n4. 序列化基准测试:")
    
    fmt.Println("  // 比较不同序列化方式的性能")
    fmt.Println("  func BenchmarkSerialization(b *testing.B) {")
    fmt.Println("      data := TestData{Field1: \"test\", Field2: 42}")
    fmt.Println("      ")
    fmt.Println("      b.Run(\"JSON\", func(b *testing.B) {")
    fmt.Println("          for i := 0; i < b.N; i++ {")
    fmt.Println("              json.Marshal(data)")
    fmt.Println("          }")
    fmt.Println("      })")
    fmt.Println("      ")
    fmt.Println("      b.Run(\"Gob\", func(b *testing.B) {")
    fmt.Println("          for i := 0; i < b.N; i++ {")
    fmt.Println("              var buf bytes.Buffer")
    fmt.Println("              gob.NewEncoder(&buf).Encode(data)")
    fmt.Println("          }")
    fmt.Println("      })")
    fmt.Println("  }")
}

func main() {
    demonstrateBasicBenchmarking()
    demonstrateBenchmarkTypes()
    demonstrateAdvancedBenchmarking()
    demonstrateBenchmarkAnalysis()
    demonstrateBenchmarkBestPractices()
    demonstrateRealWorldBenchmarks()
    
    fmt.Println("\n=== 运行基准测试 ===")
    fmt.Println("使用以下命令运行基准测试:")
    fmt.Println("  go test -bench=.")
    fmt.Println("  go test -bench=. -benchmem")
    fmt.Println("  go test -bench=. -cpuprofile=cpu.prof")
    fmt.Println("  go test -bench=. -memprofile=mem.prof")
}
```

### 性能监控

```go
package main

import (
    "context"
    "fmt"
    "log"
    "net/http"
    "_net/http/pprof"
    "runtime"
    "sync"
    "sync/atomic"
    "time"
)

// 性能监控基础
func demonstratePerformanceMonitoringBasics() {
    fmt.Println("=== 性能监控 ===")
    
    // 1. 监控指标收集
    fmt.Println("1. 监控指标收集:")
    
    type Metrics struct {
        RequestsTotal     int64
        RequestsSuccess   int64
        RequestsError     int64
        TotalLatency      int64 // 纳秒
        MemoryAllocated   uint64
        Goroutines        int
        GCCount           uint32
        mutex             sync.RWMutex
    }
    
    var globalMetrics Metrics
    
    // 收集请求指标
    func collectRequestMetrics(success bool, latency time.Duration) {
        atomic.AddInt64(&globalMetrics.RequestsTotal, 1)
        if success {
            atomic.AddInt64(&globalMetrics.RequestsSuccess, 1)
        } else {
            atomic.AddInt64(&globalMetrics.RequestsError, 1)
        }
        atomic.AddInt64(&globalMetrics.TotalLatency, int64(latency))
    }
    
    // 收集系统指标
    func collectSystemMetrics() {
        var m runtime.MemStats
        runtime.ReadMemStats(&m)
        
        globalMetrics.mutex.Lock()
        globalMetrics.MemoryAllocated = m.Alloc
        globalMetrics.Goroutines = runtime.NumGoroutine()
        globalMetrics.GCCount = m.NumGC
        globalMetrics.mutex.Unlock()
    }
    
    fmt.Println("  Implemented metrics collection")
    
    // 2. 监控数据展示
    fmt.Println("\n2. 监控数据展示:")
    
    // 启动监控goroutine
    go func() {
        ticker := time.NewTicker(10 * time.Second)
        defer ticker.Stop()
        
        for range ticker.C {
            collectSystemMetrics()
            
            globalMetrics.mutex.RLock()
            requestsTotal := atomic.LoadInt64(&globalMetrics.RequestsTotal)
            requestsSuccess := atomic.LoadInt64(&globalMetrics.RequestsSuccess)
            requestsError := atomic.LoadInt64(&globalMetrics.RequestsError)
            totalLatency := atomic.LoadInt64(&globalMetrics.TotalLatency)
            
            avgLatency := time.Duration(0)
            if requestsTotal > 0 {
                avgLatency = time.Duration(totalLatency / requestsTotal)
            }
            
            errorRate := float64(0)
            if requestsTotal > 0 {
                errorRate = float64(requestsError) / float64(requestsTotal) * 100
            }
            
            fmt.Printf("  Metrics - Total: %d, Success: %d, Error: %d (%.2f%%), AvgLatency: %v, Memory: %dMB, Goroutines: %d, GC: %d\n",
                requestsTotal, requestsSuccess, requestsError, errorRate, avgLatency,
                globalMetrics.MemoryAllocated/1024/1024, globalMetrics.Goroutines, globalMetrics.GCCount)
            globalMetrics.mutex.RUnlock()
        }
    }()
    
    fmt.Println("  Started metrics monitoring")
}

// 实时性能监控
func demonstrateRealTimeMonitoring() {
    fmt.Println("\n=== 实时性能监控 ===")
    
    // 1. HTTP监控接口
    fmt.Println("1. HTTP监控接口:")
    
    // 启动监控服务器
    go func() {
        http.HandleFunc("/metrics", func(w http.ResponseWriter, r *http.Request) {
            var m runtime.MemStats
            runtime.ReadMemStats(&m)
            
            fmt.Fprintf(w, "goroutines %d\n", runtime.NumGoroutine())
            fmt.Fprintf(w, "memory_alloc_bytes %d\n", m.Alloc)
            fmt.Fprintf(w, "memory_sys_bytes %d\n", m.Sys)
            fmt.Fprintf(w, "gc_count %d\n", m.NumGC)
            fmt.Fprintf(w, "gc_pause_total_ns %d\n", m.PauseTotalNs)
        })
        
        http.HandleFunc("/health", func(w http.ResponseWriter, r *http.Request) {
            fmt.Fprintf(w, "OK")
        })
        
        http.HandleFunc("/debug/pprof/", pprof.Index)
        http.HandleFunc("/debug/pprof/cmdline", pprof.Cmdline)
        http.HandleFunc("/debug/pprof/profile", pprof.Profile)
        http.HandleFunc("/debug/pprof/symbol", pprof.Symbol)
        http.HandleFunc("/debug/pprof/trace", pprof.Trace)
        
        log.Println("Monitoring server starting on :8080")
        log.Fatal(http.ListenAndServe(":8080", nil))
    }()
    
    fmt.Println("  Started HTTP monitoring server on :8080")
    fmt.Println("  Endpoints: /metrics, /health, /debug/pprof/")
    
    // 2. 实时指标计算
    fmt.Println("\n2. 实时指标计算:")
    
    type RealTimeMetrics struct {
        RequestRate       float64
        ErrorRate         float64
        AverageLatency    time.Duration
        P95Latency        time.Duration
        P99Latency        time.Duration
        mutex             sync.RWMutex
    }
    
    var realTimeMetrics RealTimeMetrics
    
    // 滑动窗口计算
    type SlidingWindow struct {
        requests []time.Duration
        maxSize  int
        mutex    sync.RWMutex
    }
    
    func NewSlidingWindow(size int) *SlidingWindow {
        return &SlidingWindow{
            requests: make([]time.Duration, 0, size),
            maxSize:  size,
        }
    }
    
    func (sw *SlidingWindow) Add(latency time.Duration) {
        sw.mutex.Lock()
        defer sw.mutex.Unlock()
        
        if len(sw.requests) >= sw.maxSize {
            // 移除最旧的记录
            sw.requests = sw.requests[1:]
        }
        sw.requests = append(sw.requests, latency)
    }
    
    func (sw *SlidingWindow) Percentile(p float64) time.Duration {
        sw.mutex.RLock()
        defer sw.mutex.RUnlock()
        
        if len(sw.requests) == 0 {
            return 0
        }
        
        // 复制并排序
        sorted := make([]time.Duration, len(sw.requests))
        copy(sorted, sw.requests)
        
        // 简单排序（实际应用中使用更高效的算法）
        for i := 0; i < len(sorted)-1; i++ {
            for j := i + 1; j < len(sorted); j++ {
                if sorted[i] > sorted[j] {
                    sorted[i], sorted[j] = sorted[j], sorted[i]
                }
            }
        }
        
        index := int(float64(len(sorted)-1) * p)
        return sorted[index]
    }
    
    latencyWindow := NewSlidingWindow(1000)
    
    fmt.Println("  Implemented sliding window for latency calculation")
}

// 性能告警系统
func demonstrateAlertingSystem() {
    fmt.Println("\n=== 性能告警系统 ===")
    
    // 1. 告警规则定义
    fmt.Println("1. 告警规则定义:")
    
    type AlertRule struct {
        Name        string
        Metric      string
        Threshold   float64
        Duration    time.Duration
        Severity    string
        Enabled     bool
    }
    
    alertRules := []AlertRule{
        {
            Name:      "High Error Rate",
            Metric:    "error_rate",
            Threshold: 5.0, // 5%
            Duration:  5 * time.Minute,
            Severity:  "critical",
            Enabled:   true,
        },
        {
            Name:      "High Latency",
            Metric:    "latency_p95",
            Threshold: 1000, // 1000ms
            Duration:  5 * time.Minute,
            Severity:  "warning",
            Enabled:   true,
        },
        {
            Name:      "High Memory Usage",
            Metric:    "memory_usage",
            Threshold: 80.0, // 80%
            Duration:  10 * time.Minute,
            Severity:  "warning",
            Enabled:   true,
        },
        {
            Name:      "High Goroutine Count",
            Metric:    "goroutine_count",
            Threshold: 10000,
            Duration:  5 * time.Minute,
            Severity:  "critical",
            Enabled:   true,
        },
    }
    
    fmt.Printf("  Defined %d alert rules\n", len(alertRules))
    
    // 2. 告警评估
    fmt.Println("\n2. 告警评估:")
    
    type AlertState struct {
        Rule      AlertRule
        Triggered bool
        LastCheck time.Time
        Violations int
        mutex     sync.RWMutex
    }
    
    var alertStates []AlertState
    
    // 初始化告警状态
    for _, rule := range alertRules {
        alertStates = append(alertStates, AlertState{
            Rule:      rule,
            Triggered: false,
            LastCheck: time.Now(),
            Violations: 0,
        })
    }
    
    // 告警评估函数
    func evaluateAlerts() {
        for i := range alertStates {
            state := &alertStates[i]
            state.mutex.Lock()
            
            if !state.Rule.Enabled {
                state.mutex.Unlock()
                continue
            }
            
            // 检查指标是否超过阈值
            violation := false
            currentValue := 0.0
            
            switch state.Rule.Metric {
            case "error_rate":
                // 模拟错误率计算
                currentValue = 2.5 // 实际应用中从metrics获取
                violation = currentValue > state.Rule.Threshold
            case "latency_p95":
                // 模拟P95延迟
                currentValue = 500.0
                violation = currentValue > state.Rule.Threshold
            case "memory_usage":
                // 模拟内存使用率
                var m runtime.MemStats
                runtime.ReadMemStats(&m)
                memoryUsage := float64(m.Alloc) / float64(m.Sys) * 100
                currentValue = memoryUsage
                violation = currentValue > state.Rule.Threshold
            case "goroutine_count":
                // 模拟goroutine数量
                currentValue = float64(runtime.NumGoroutine())
                violation = currentValue > state.Rule.Threshold
            }
            
            if violation {
                state.Violations++
                if !state.Triggered {
                    state.Triggered = true
                    fmt.Printf("  ALERT TRIGGERED: %s - Current: %.2f, Threshold: %.2f\n", 
                        state.Rule.Name, currentValue, state.Rule.Threshold)
                    // 这里可以发送告警通知
                }
            } else {
                if state.Triggered {
                    state.Triggered = false
                    fmt.Printf("  ALERT RESOLVED: %s\n", state.Rule.Name)
                }
                state.Violations = 0
            }
            
            state.LastCheck = time.Now()
            state.mutex.Unlock()
        }
    }
    
    // 启动告警评估
    go func() {
        ticker := time.NewTicker(30 * time.Second)
        defer ticker.Stop()
        
        for range ticker.C {
            evaluateAlerts()
        }
    }()
    
    fmt.Println("  Started alert evaluation system")
}

// 分布式监控
func demonstrateDistributedMonitoring() {
    fmt.Println("\n=== 分布式监控 ===")
    
    // 1. 服务发现和监控
    fmt.Println("1. 服务发现和监控:")
    
    type ServiceInstance struct {
        ID       string
        Name     string
        Address  string
        Port     int
        Status   string
        LastSeen time.Time
        Metrics  map[string]float64
    }
    
    type ServiceRegistry struct {
        services map[string]*ServiceInstance
        mutex    sync.RWMutex
    }
    
    func NewServiceRegistry() *ServiceRegistry {
        return &ServiceRegistry{
            services: make(map[string]*ServiceInstance),
        }
    }
    
    func (sr *ServiceRegistry) Register(instance *ServiceInstance) {
        sr.mutex.Lock()
        defer sr.mutex.Unlock()
        
        instance.LastSeen = time.Now()
        sr.services[instance.ID] = instance
    }
    
    func (sr *ServiceRegistry) Deregister(id string) {
        sr.mutex.Lock()
        defer sr.mutex.Unlock()
        
        delete(sr.services, id)
    }
    
    func (sr *ServiceRegistry) GetServices() []*ServiceInstance {
        sr.mutex.RLock()
        defer sr.mutex.RUnlock()
        
        services := make([]*ServiceInstance, 0, len(sr.services))
        for _, service := range sr.services {
            services = append(services, service)
        }
        return services
    }
    
    func (sr *ServiceRegistry) Cleanup(timeout time.Duration) {
        sr.mutex.Lock()
        defer sr.mutex.Unlock()
        
        now := time.Now()
        for id, service := range sr.services {
            if now.Sub(service.LastSeen) > timeout {
                delete(sr.services, id)
                fmt.Printf("  Service %s cleaned up due to timeout\n", id)
            }
        }
    }
    
    registry := NewServiceRegistry()
    
    fmt.Println("  Implemented service registry")
    
    // 2. 跨服务指标聚合
    fmt.Println("\n2. 跨服务指标聚合:")
    
    type AggregatedMetrics struct {
        TotalRequests     int64
        TotalErrors       int64
        AverageLatency    time.Duration
        ServicesUp        int
        ServicesDown      int
        mutex             sync.RWMutex
    }
    
    var aggregatedMetrics AggregatedMetrics
    
    // 聚合函数
    func aggregateMetrics() {
        services := registry.GetServices()
        
        var totalRequests, totalErrors int64
        var totalLatency time.Duration
        var servicesUp, servicesDown int
        
        for _, service := range services {
            if service.Status == "up" {
                servicesUp++
                if requests, ok := service.Metrics["requests_total"]; ok {
                    totalRequests += int64(requests)
                }
                if errors, ok := service.Metrics["errors_total"]; ok {
                    totalErrors += int64(errors)
                }
                if latency, ok := service.Metrics["latency_avg"]; ok {
                    totalLatency += time.Duration(latency * float64(time.Millisecond))
                }
            } else {
                servicesDown++
            }
        }
        
        aggregatedMetrics.mutex.Lock()
        aggregatedMetrics.TotalRequests = totalRequests
        aggregatedMetrics.TotalErrors = totalErrors
        aggregatedMetrics.ServicesUp = servicesUp
        aggregatedMetrics.ServicesDown = servicesDown
        if len(services) > 0 {
            aggregatedMetrics.AverageLatency = totalLatency / time.Duration(len(services))
        }
        aggregatedMetrics.mutex.Unlock()
    }
    
    // 启动聚合
    go func() {
        ticker := time.NewTicker(1 * time.Minute)
        defer ticker.Stop()
        
        for range ticker.C {
            aggregateMetrics()
            
            aggregatedMetrics.mutex.RLock()
            fmt.Printf("  Aggregated Metrics - Requests: %d, Errors: %d, AvgLatency: %v, Services: %d up, %d down\n",
                aggregatedMetrics.TotalRequests,
                aggregatedMetrics.TotalErrors,
                aggregatedMetrics.AverageLatency,
                aggregatedMetrics.ServicesUp,
                aggregatedMetrics.ServicesDown)
            aggregatedMetrics.mutex.RUnlock()
        }
    }()
    
    fmt.Println("  Started metrics aggregation")
    
    // 注册示例服务
    service1 := &ServiceInstance{
        ID:      "service1-123",
        Name:    "UserService",
        Address: "192.168.1.10",
        Port:    8080,
        Status:  "up",
        Metrics: map[string]float64{
            "requests_total": 1000,
            "errors_total":   5,
            "latency_avg":    50.5,
        },
    }
    
    service2 := &ServiceInstance{
        ID:      "service2-456",
        Name:    "OrderService",
        Address: "192.168.1.11",
        Port:    8081,
        Status:  "up",
        Metrics: map[string]float64{
            "requests_total": 2000,
            "errors_total":   10,
            "latency_avg":    75.2,
        },
    }
    
    registry.Register(service1)
    registry.Register(service2)
}

// 性能监控最佳实践
func performanceMonitoringBestPractices() {
    fmt.Println("\n=== 性能监控最佳实践 ===")
    
    fmt.Println("1. 监控指标设计:")
    fmt.Println("   - 选择关键业务指标")
    fmt.Println("   - 平衡监控粒度和性能")
    fmt.Println("   - 设置合理的指标采集频率")
    fmt.Println("   - 考虑指标的可解释性")
    fmt.Println("   - 建立指标基线")
    
    fmt.Println("\n2. 告警策略:")
    fmt.Println("   - 设置合理的告警阈值")
    fmt.Println("   - 避免告警风暴")
    fmt.Println("   - 实现告警抑制和分组")
    fmt.Println("   - 提供告警上下文信息")
    fmt.Println("   - 建立告警处理流程")
    
    fmt.Println("\n3. 数据存储和查询:")
    fmt.Println("   - 选择合适的时序数据库")
    fmt.Println("   - 设计高效的数据模型")
    fmt.Println("   - 实现数据压缩和归档")
    fmt.Println("   - 优化查询性能")
    fmt.Println("   - 考虑数据一致性")
    
    fmt.Println("\n4. 可视化展示:")
    fmt.Println("   - 设计直观的仪表板")
    fmt.Println("   - 提供多维度分析")
    fmt.Println("   - 实现实时和历史数据对比")
    fmt.Println("   - 支持自定义视图")
    fmt.Println("   - 优化页面加载性能")
    
    fmt.Println("\n5. 分布式监控:")
    fmt.Println("   - 实现服务发现")
    fmt.Println("   - 统一监控数据格式")
    fmt.Println("   - 跨服务指标关联")
    fmt.Println("   - 分布式追踪集成")
    fmt.Println("   - 多集群监控")
    
    fmt.Println("\n6. 性能优化:")
    fmt.Println("   - 减少监控开销")
    fmt.Println("   - 优化指标采集")
    fmt.Println("   - 实现指标采样")
    fmt.Println("   - 缓存监控数据")
    fmt.Println("   - 异步处理监控事件")
    
    fmt.Println("\n7. 安全考虑:")
    fmt.Println("   - 保护监控接口")
    fmt.Println("   - 实现访问控制")
    fmt.Println("   - 加密敏感数据")
    fmt.Println("   - 审计监控操作")
    fmt.Println("   - 防止监控数据泄露")
    
    fmt.Println("\n8. 运维实践:")
    fmt.Println("   - 建立监控运维流程")
    fmt.Println("   - 定期审查监控配置")
    fmt.Println("   - 实施监控数据备份")
    fmt.Println("   - 建立故障恢复机制")
    fmt.Println("   - 持续改进监控体系")
}

// 监控系统集成示例
func demonstrateMonitoringIntegration() {
    fmt.Println("\n=== 监控系统集成示例 ===")
    
    // 1. Prometheus集成
    fmt.Println("1. Prometheus集成:")
    
    fmt.Println("  // 使用prometheus/client_golang库")
    fmt.Println("  import \"github.com/prometheus/client_golang/prometheus\"")
    fmt.Println("  import \"github.com/prometheus/client_golang/prometheus/promhttp\"")
    fmt.Println("  ")
    fmt.Println("  var (")
    fmt.Println("      requestCounter = prometheus.NewCounterVec(")
    fmt.Println("          prometheus.CounterOpts{")
    fmt.Println("              Name: \"http_requests_total\",")
    fmt.Println("              Help: \"Total number of HTTP requests\",")
    fmt.Println("          },")
    fmt.Println("          []string{\"method\", \"endpoint\", \"status\"},")
    fmt.Println("      )")
    fmt.Println("  )")
    fmt.Println("  ")
    fmt.Println("  func init() {")
    fmt.Println("      prometheus.MustRegister(requestCounter)")
    fmt.Println("  }")
    fmt.Println("  ")
    fmt.Println("  func metricsHandler() http.Handler {")
    fmt.Println("      return promhttp.Handler()")
    fmt.Println("  }")
    
    // 2. OpenTelemetry集成
    fmt.Println("\n2. OpenTelemetry集成:")
    
    fmt.Println("  // 使用go.opentelemetry.io/otel库")
    fmt.Println("  import \"go.opentelemetry.io/otel\"")
    fmt.Println("  import \"go.opentelemetry.io/otel/trace\"")
    fmt.Println("  ")
    fmt.Println("  func tracedHandler(w http.ResponseWriter, r *http.Request) {")
    fmt.Println("      ctx, span := tracer.Start(r.Context(), \"http.handler\")")
    fmt.Println("      defer span.End()")
    fmt.Println("      ")
    fmt.Println("      // 处理请求")
    fmt.Println("      span.SetAttributes(")
    fmt.Println("          attribute.String(\"http.method\", r.Method),")
    fmt.Println("          attribute.String(\"http.url\", r.URL.String()),")
    fmt.Println("      )")
    fmt.Println("  }")
    
    // 3. 自定义监控客户端
    fmt.Println("\n3. 自定义监控客户端:")
    
    type MonitoringClient struct {
        endpoint string
        apiKey   string
        client   *http.Client
    }
    
    func NewMonitoringClient(endpoint, apiKey string) *MonitoringClient {
        return &MonitoringClient{
            endpoint: endpoint,
            apiKey:   apiKey,
            client:   &http.Client{Timeout: 30 * time.Second},
        }
    }
    
    func (mc *MonitoringClient) SendMetric(name string, value float64, tags map[string]string) error {
        // 实现发送指标到监控系统的逻辑
        fmt.Printf("  Sending metric %s=%f with tags %v\n", name, value, tags)
        return nil
    }
    
    func (mc *MonitoringClient) SendAlert(title, message string, severity string) error {
        // 实现发送告警的逻辑
        fmt.Printf("  Sending alert: %s - %s (severity: %s)\n", title, message, severity)
        return nil
    }
    
    fmt.Println("  Implemented custom monitoring client")
    
    // 4. 健康检查
    fmt.Println("\n4. 健康检查:")
    
    type HealthCheck struct {
        Name     string
        Check    func() error
        Interval time.Duration
    }
    
    type HealthChecker struct {
        checks  []HealthCheck
        results map[string]bool
        mutex   sync.RWMutex
    }
    
    func NewHealthChecker() *HealthChecker {
        return &HealthChecker{
            checks:  make([]HealthCheck, 0),
            results: make(map[string]bool),
        }
    }
    
    func (hc *HealthChecker) AddCheck(check HealthCheck) {
        hc.checks = append(hc.checks, check)
    }
    
    func (hc *HealthChecker) Start() {
        go func() {
            for {
                hc.performChecks()
                time.Sleep(30 * time.Second)
            }
        }()
    }
    
    func (hc *HealthChecker) performChecks() {
        hc.mutex.Lock()
        defer hc.mutex.Unlock()
        
        for _, check := range hc.checks {
            err := check.Check()
            hc.results[check.Name] = (err == nil)
            
            if err != nil {
                fmt.Printf("  Health check %s failed: %v\n", check.Name, err)
            } else {
                fmt.Printf("  Health check %s passed\n", check.Name)
            }
        }
    }
    
    func (hc *HealthChecker) GetStatus() map[string]bool {
        hc.mutex.RLock()
        defer hc.mutex.RUnlock()
        
        status := make(map[string]bool)
        for name, result := range hc.results {
            status[name] = result
        }
        return status
    }
    
    // 创建健康检查器
    healthChecker := NewHealthChecker()
    
    // 添加健康检查
    healthChecker.AddCheck(HealthCheck{
        Name:     "database",
        Check:    func() error { return nil }, // 实际应用中检查数据库连接
        Interval: 30 * time.Second,
    })
    
    healthChecker.AddCheck(HealthCheck{
        Name:     "cache",
        Check:    func() error { return nil }, // 实际应用中检查缓存连接
        Interval: 30 * time.Second,
    })
    
    healthChecker.Start()
    
    fmt.Println("  Implemented health checker")
}

func main() {
    demonstratePerformanceMonitoringBasics()
    demonstrateRealTimeMonitoring()
    demonstrateAlertingSystem()
    demonstrateDistributedMonitoring()
    performanceMonitoringBestPractices()
    demonstrateMonitoringIntegration()
    
    fmt.Println("\n=== 监控系统运行 ===")
    fmt.Println("监控系统已启动:")
    fmt.Println("  - 实时指标收集")
    fmt.Println("  - HTTP监控接口 :8080")
    fmt.Println("  - 告警评估系统")
    fmt.Println("  - 分布式监控")
    fmt.Println("  - 健康检查")
    
    // 保持程序运行
    fmt.Println("\n系统运行中... 按 Ctrl+C 退出")
    
    // 模拟一些业务活动来产生监控数据
    go func() {
        ticker := time.NewTicker(1 * time.Second)
        defer ticker.Stop()
        
        for range ticker.C {
            // 模拟请求处理
            start := time.Now()
            time.Sleep(time.Millisecond * time.Duration(rand.Intn(100)))
            latency := time.Since(start)
            
            // 收集指标
            collectRequestMetrics(true, latency)
        }
    }()
    
    // 清理过期服务
    go func() {
        ticker := time.NewTicker(1 * time.Minute)
        defer ticker.Stop()
        
        registry := NewServiceRegistry() // 实际应用中使用全局registry
        for range ticker.C {
            registry.Cleanup(5 * time.Minute)
        }
    }()
    
    select {}
}
```