## 5.4 并发模式

### 生产者消费者模式

```go
import (
    "fmt"
    "sync"
    "time"
)

type Task struct {
    ID   int
    Data string
}

type TaskQueue struct {
    queue chan Task
    wg    sync.WaitGroup
}

func NewTaskQueue(bufferSize int) *TaskQueue {
    return &TaskQueue{
        queue: make(chan Task, bufferSize),
    }
}

func (tq *TaskQueue) AddProducer(producer func() Task) {
    tq.wg.Add(1)
    go func() {
        defer tq.wg.Done()
        for i := 0; i < 10; i++ {
            task := producer()
            task.ID = i
            task.Data = fmt.Sprintf("data-%d", i)
            tq.queue <- task
            time.Sleep(100 * time.Millisecond)
        }
        close(tq.queue)
    }()
}

func (tq *TaskQueue) AddConsumer(consumer func(Task)) {
    tq.wg.Add(1)
    go func() {
        defer tq.wg.Done()
        for task := range tq.queue {
            consumer(task)
        }
    }()
}

func (tq *TaskQueue) Wait() {
    tq.wg.Wait()
}

func demonstrateProducerConsumer() {
    taskQueue := NewTaskQueue(5)
    
    // 添加生产者
    taskQueue.AddProducer(func() Task {
        return Task{}
    })
    
    // 添加多个消费者
    for i := 0; i < 3; i++ {
        consumerID := i
        taskQueue.AddConsumer(func(task Task) {
            fmt.Printf("Consumer %d processing task %d: %s\n", consumerID, task.ID, task.Data)
            time.Sleep(200 * time.Millisecond) // 模拟处理时间
        })
    }
    
    taskQueue.Wait()
    fmt.Println("All tasks processed")
}
```

### 工作池模式

```go
import (
    "fmt"
    "sync"
    "time"
)

type Job struct {
    ID   int
    Data interface{}
    Process func(interface{}) interface{}
}

type Worker struct {
    ID         int
    JobQueue   <-chan Job
    ResultChan chan<- JobResult
    QuitChan   <-chan bool
}

type JobResult struct {
    JobID  int
    Result interface{}
    Error  error
}

func (w Worker) Start(wg *sync.WaitGroup) {
    wg.Add(1)
    go func() {
        defer wg.Done()
        for {
            select {
            case job := <-w.JobQueue:
                result := job.Process(job.Data)
                w.ResultChan <- JobResult{
                    JobID:  job.ID,
                    Result: result,
                    Error:  nil,
                }
            case <-w.QuitChan:
                fmt.Printf("Worker %d stopping\n", w.ID)
                return
            }
        }
    }()
}

type WorkerPool struct {
    JobQueue   chan Job
    ResultChan chan JobResult
    QuitChan   chan bool
    Workers    []Worker
}

func NewWorkerPool(numWorkers int) *WorkerPool {
    jobQueue := make(chan Job, 100)
    resultChan := make(chan JobResult, 100)
    quitChan := make(chan bool)
    
    pool := &WorkerPool{
        JobQueue:   jobQueue,
        ResultChan: resultChan,
        QuitChan:   quitChan,
        Workers:    make([]Worker, numWorkers),
    }
    
    // 创建并启动workers
    for i := 0; i < numWorkers; i++ {
        worker := Worker{
            ID:         i,
            JobQueue:   jobQueue,
            ResultChan: resultChan,
            QuitChan:   quitChan,
        }
        pool.Workers[i] = worker
    }
    
    return pool
}

func (wp *WorkerPool) Start() {
    var wg sync.WaitGroup
    for _, worker := range wp.Workers {
        worker.Start(&wg)
    }
    go func() {
        wg.Wait()
        close(wp.ResultChan)
    }()
}

func (wp *WorkerPool) Stop() {
    close(wp.QuitChan)
}

func (wp *WorkerPool) Submit(job Job) {
    wp.JobQueue <- job
}

func demonstrateWorkerPool() {
    pool := NewWorkerPool(3)
    pool.Start()
    
    // 提交任务
    go func() {
        for i := 1; i <= 10; i++ {
            job := Job{
                ID:   i,
                Data: i,
                Process: func(data interface{}) interface{} {
                    num := data.(int)
                    time.Sleep(100 * time.Millisecond) // 模拟处理时间
                    return num * num
                },
            }
            pool.Submit(job)
        }
        close(pool.JobQueue)
    }()
    
    // 收集结果
    for result := range pool.ResultChan {
        fmt.Printf("Job %d result: %v\n", result.JobID, result.Result)
    }
    
    pool.Stop()
    fmt.Println("Worker pool completed")
}
```

### 扇入扇出模式

```go
import (
    "fmt"
    "sync"
    "time"
)

// 扇出：将输入分发给多个处理者
func distributor(input <-chan int, numWorkers int) []<-chan string {
    outputs := make([]<-chan string, numWorkers)
    
    for i := 0; i < numWorkers; i++ {
        output := make(chan string, 10)
        outputs[i] = output
        
        workerID := i
        go func(out chan<- string) {
            defer close(out)
            for num := range input {
                // 模拟不同的处理时间
                time.Sleep(time.Duration(workerID*100) * time.Millisecond)
                result := fmt.Sprintf("Worker-%d processed %d -> %d", workerID, num, num*num)
                out <- result
            }
        }(output)
    }
    
    return outputs
}

// 扇入：将多个输入合并为一个输出
func collector(inputs ...<-chan string) <-chan string {
    output := make(chan string, 100)
    
    var wg sync.WaitGroup
    wg.Add(len(inputs))
    
    for _, input := range inputs {
        go func(in <-chan string) {
            defer wg.Done()
            for msg := range in {
                output <- msg
            }
        }(input)
    }
    
    go func() {
        wg.Wait()
        close(output)
    }()
    
    return output
}

func demonstrateFanInOut() {
    // 创建输入数据流
    input := make(chan int, 100)
    go func() {
        for i := 1; i <= 20; i++ {
            input <- i
        }
        close(input)
    }()
    
    // 扇出处理
    outputs := distributor(input, 4)
    
    // 扇入合并
    merged := collector(outputs...)
    
    // 处理合并后的结果
    results := make([]string, 0)
    for result := range merged {
        results = append(results, result)
        fmt.Println(result)
    }
    
    fmt.Printf("Total results: %d\n", len(results))
}
```

### 生成器模式

```go
import (
    "fmt"
    "time"
)

// 简单的生成器
func numberGenerator(start, end int) <-chan int {
    ch := make(chan int)
    go func() {
        defer close(ch)
        for i := start; i <= end; i++ {
            ch <- i
        }
    }()
    return ch
}

// 斐波那契生成器
func fibonacciGenerator() <-chan int {
    ch := make(chan int)
    go func() {
        defer close(ch)
        a, b := 0, 1
        for {
            ch <- a
            a, b = b, a+b
        }
    }()
    return ch
}

// 带取消功能的生成器
func cancellableGenerator(ctx context.Context, numbers []int) <-chan int {
    ch := make(chan int)
    go func() {
        defer close(ch)
        for _, num := range numbers {
            select {
            case <-ctx.Done():
                return
            case ch <- num:
                time.Sleep(100 * time.Millisecond)
            }
        }
    }()
    return ch
}

func demonstrateGenerators() {
    // 使用数字生成器
    fmt.Println("Number generator (1-10):")
    for num := range numberGenerator(1, 10) {
        fmt.Print(num, " ")
    }
    fmt.Println()
    
    // 使用斐波那契生成器
    fmt.Println("Fibonacci numbers:")
    fib := fibonacciGenerator()
    for i := 0; i < 10; i++ {
        fmt.Print(<-fib, " ")
    }
    fmt.Println()
    
    // 使用可取消的生成器
    ctx, cancel := context.WithTimeout(context.Background(), 500*time.Millisecond)
    defer cancel()
    
    numbers := []int{1, 2, 3, 4, 5, 6, 7, 8, 9, 10}
    fmt.Println("Cancellable generator:")
    for num := range cancellableGenerator(ctx, numbers) {
        fmt.Print(num, " ")
    }
    fmt.Println("\nGenerator cancelled or completed")
}
```

### 并发安全的数据结构

```go
import (
    "fmt"
    "sync"
    "sync/atomic"
)

// 并发安全的队列
type ConcurrentQueue struct {
    items []interface{}
    mu    sync.Mutex
}

func (cq *ConcurrentQueue) Enqueue(item interface{}) {
    cq.mu.Lock()
    defer cq.mu.Unlock()
    cq.items = append(cq.items, item)
}

func (cq *ConcurrentQueue) Dequeue() (interface{}, bool) {
    cq.mu.Lock()
    defer cq.mu.Unlock()
    
    if len(cq.items) == 0 {
        return nil, false
    }
    
    item := cq.items[0]
    cq.items = cq.items[1:]
    return item, true
}

func (cq *ConcurrentQueue) Size() int {
    cq.mu.Lock()
    defer cq.mu.Unlock()
    return len(cq.items)
}

// 并发安全的栈
type ConcurrentStack struct {
    items []interface{}
    mu    sync.RWMutex
}

func (cs *ConcurrentStack) Push(item interface{}) {
    cs.mu.Lock()
    defer cs.mu.Unlock()
    cs.items = append(cs.items, item)
}

func (cs *ConcurrentStack) Pop() (interface{}, bool) {
    cs.mu.Lock()
    defer cs.mu.Unlock()
    
    if len(cs.items) == 0 {
        return nil, false
    }
    
    index := len(cs.items) - 1
    item := cs.items[index]
    cs.items = cs.items[:index]
    return item, true
}

func (cs *ConcurrentStack) Peek() (interface{}, bool) {
    cs.mu.RLock()
    defer cs.mu.RUnlock()
    
    if len(cs.items) == 0 {
        return nil, false
    }
    
    return cs.items[len(cs.items)-1], true
}

// 使用原子操作的计数器集合
type AtomicCounterMap struct {
    counters map[string]*int64
    mu       sync.RWMutex
}

func NewAtomicCounterMap() *AtomicCounterMap {
    return &AtomicCounterMap{
        counters: make(map[string]*int64),
    }
}

func (acm *AtomicCounterMap) Increment(key string) {
    acm.mu.RLock()
    counter, exists := acm.counters[key]
    acm.mu.RUnlock()
    
    if !exists {
        acm.mu.Lock()
        if counter, exists = acm.counters[key]; !exists {
            counter = new(int64)
            acm.counters[key] = counter
        }
        acm.mu.Unlock()
    }
    
    atomic.AddInt64(counter, 1)
}

func (acm *AtomicCounterMap) Get(key string) int64 {
    acm.mu.RLock()
    defer acm.mu.RUnlock()
    
    if counter, exists := acm.counters[key]; exists {
        return atomic.LoadInt64(counter)
    }
    return 0
}

func demonstrateConcurrentDataStructures() {
    // 测试并发队列
    queue := &ConcurrentQueue{}
    var wg sync.WaitGroup
    
    // 并发入队
    for i := 0; i < 100; i++ {
        wg.Add(1)
        go func(id int) {
            defer wg.Done()
            queue.Enqueue(id)
        }(i)
    }
    
    wg.Wait()
    fmt.Printf("Queue size after enqueuing: %d\n", queue.Size())
    
    // 并发出队
    results := make([]int, 0, 100)
    var mu sync.Mutex
    
    for i := 0; i < 50; i++ {
        wg.Add(1)
        go func() {
            defer wg.Done()
            if item, ok := queue.Dequeue(); ok {
                mu.Lock()
                results = append(results, item.(int))
                mu.Unlock()
            }
        }()
    }
    
    wg.Wait()
    fmt.Printf("Remaining queue size: %d\n", queue.Size())
    fmt.Printf("Dequeued %d items\n", len(results))
    
    // 测试并发栈
    stack := &ConcurrentStack{}
    
    // 并发压栈
    for i := 0; i < 10; i++ {
        stack.Push(i)
    }
    
    // 并发查看和弹栈
    if top, ok := stack.Peek(); ok {
        fmt.Printf("Top of stack: %v\n", top)
    }
    
    if item, ok := stack.Pop(); ok {
        fmt.Printf("Popped: %v\n", item)
    }
    
    // 测试原子计数器映射
    counterMap := NewAtomicCounterMap()
    
    // 并发增加计数器
    var wg2 sync.WaitGroup
    for i := 0; i < 1000; i++ {
        wg2.Add(1)
        go func() {
            defer wg2.Done()
            counterMap.Increment("page_views")
            if i%2 == 0 {
                counterMap.Increment("user_actions")
            }
        }()
    }
    
    wg2.Wait()
    fmt.Printf("Page views: %d\n", counterMap.Get("page_views"))
    fmt.Printf("User actions: %d\n", counterMap.Get("user_actions"))
}
```

### 信号量模式

```go
import (
    "fmt"
    "sync"
    "time"
)

// 信号量实现
type Semaphore struct {
    ch chan struct{}
}

func NewSemaphore(maxConcurrency int) *Semaphore {
    return &Semaphore{
        ch: make(chan struct{}, maxConcurrency),
    }
}

func (s *Semaphore) Acquire() {
    s.ch <- struct{}{}
}

func (s *Semaphore) Release() {
    <-s.ch
}

// 带超时的信号量
type TimeoutSemaphore struct {
    ch chan struct{}
}

func NewTimeoutSemaphore(maxConcurrency int) *TimeoutSemaphore {
    return &TimeoutSemaphore{
        ch: make(chan struct{}, maxConcurrency),
    }
}

func (ts *TimeoutSemaphore) Acquire(timeout time.Duration) bool {
    select {
    case ts.ch <- struct{}{}:
        return true
    case <-time.After(timeout):
        return false
    }
}

func (ts *TimeoutSemaphore) Release() {
    <-ts.ch
}

func demonstrateSemaphore() {
    // 限制并发数为3的信号量
    sem := NewSemaphore(3)
    var wg sync.WaitGroup
    
    // 模拟10个任务，但最多同时执行3个
    for i := 1; i <= 10; i++ {
        wg.Add(1)
        go func(id int) {
            defer wg.Done()
            
            sem.Acquire()
            defer sem.Release()
            
            fmt.Printf("Task %d started\n", id)
            time.Sleep(1 * time.Second) // 模拟工作
            fmt.Printf("Task %d completed\n", id)
        }(i)
    }
    
    wg.Wait()
    fmt.Println("All tasks completed")
    
    // 带超时的信号量示例
    timeoutSem := NewTimeoutSemaphore(2)
    
    for i := 1; i <= 5; i++ {
        go func(id int) {
            if timeoutSem.Acquire(500 * time.Millisecond) {
                defer timeoutSem.Release()
                fmt.Printf("Timeout task %d acquired semaphore\n", id)
                time.Sleep(1 * time.Second)
                fmt.Printf("Timeout task %d released semaphore\n", id)
            } else {
                fmt.Printf("Timeout task %d failed to acquire semaphore\n", id)
            }
        }(i)
    }
    
    time.Sleep(3 * time.Second)
}
```

### 令牌桶模式

```go
import (
    "fmt"
    "sync"
    "time"
)

// 令牌桶实现
type TokenBucket struct {
    capacity  int64
    tokens    int64
    rate      int64 // 每秒生成的令牌数
    lastRefill time.Time
    mu         sync.Mutex
}

func NewTokenBucket(capacity, rate int64) *TokenBucket {
    return &TokenBucket{
        capacity:   capacity,
        tokens:     capacity,
        rate:       rate,
        lastRefill: time.Now(),
    }
}

func (tb *TokenBucket) refill() {
    now := time.Now()
    duration := now.Sub(tb.lastRefill)
    tokensToAdd := int64(duration.Seconds()) * tb.rate
    
    if tokensToAdd > 0 {
        tb.tokens = min(tb.capacity, tb.tokens+tokensToAdd)
        tb.lastRefill = now
    }
}

func (tb *TokenBucket) Allow() bool {
    tb.mu.Lock()
    defer tb.mu.Unlock()
    
    tb.refill()
    
    if tb.tokens > 0 {
        tb.tokens--
        return true
    }
    return false
}

func (tb *TokenBucket) AllowN(count int64) bool {
    tb.mu.Lock()
    defer tb.mu.Unlock()
    
    tb.refill()
    
    if tb.tokens >= count {
        tb.tokens -= count
        return true
    }
    return false
}

func min(a, b int64) int64 {
    if a < b {
        return a
    }
    return b
}

// 持续生成令牌的令牌桶
type ContinuousTokenBucket struct {
    tokens chan struct{}
}

func NewContinuousTokenBucket(rate int, burst int) *ContinuousTokenBucket {
    tb := &ContinuousTokenBucket{
        tokens: make(chan struct{}, burst),
    }
    
    // 启动令牌生成器
    go func() {
        ticker := time.NewTicker(time.Second / time.Duration(rate))
        defer ticker.Stop()
        
        for range ticker.C {
            select {
            case tb.tokens <- struct{}{}:
            default:
                // 令牌桶已满，丢弃多余的令牌
            }
        }
    }()
    
    // 预填充令牌桶
    for i := 0; i < burst; i++ {
        select {
        case tb.tokens <- struct{}{}:
        default:
        }
    }
    
    return tb
}

func (ctb *ContinuousTokenBucket) Allow() bool {
    select {
    case <-ctb.tokens:
        return true
    default:
        return false
    }
}

func demonstrateTokenBucket() {
    // 基本令牌桶示例
    bucket := NewTokenBucket(10, 5) // 容量10，每秒生成5个令牌
    
    var wg sync.WaitGroup
    
    // 模拟请求
    for i := 1; i <= 20; i++ {
        wg.Add(1)
        go func(id int) {
            defer wg.Done()
            if bucket.Allow() {
                fmt.Printf("Request %d: Allowed\n", id)
            } else {
                fmt.Printf("Request %d: Rate limited\n", id)
            }
        }(i)
    }
    
    wg.Wait()
    
    // 等待一段时间让令牌桶重新填充
    time.Sleep(2 * time.Second)
    
    // 连续令牌桶示例
    fmt.Println("\nContinuous token bucket:")
    continuousBucket := NewContinuousTokenBucket(3, 5) // 每秒3个请求，突发5个
    
    for i := 1; i <= 10; i++ {
        if continuousBucket.Allow() {
            fmt.Printf("Continuous request %d: Allowed\n", i)
        } else {
            fmt.Printf("Continuous request %d: Rate limited\n", i)
        }
        time.Sleep(200 * time.Millisecond)
    }
}
```

### 并发控制最佳实践

```go
import (
    "context"
    "fmt"
    "sync"
    "time"
)

// 最佳实践1：使用context进行超时和取消控制
func processWithContext(ctx context.Context, id int) error {
    // 模拟长时间运行的任务
    for i := 0; i < 10; i++ {
        select {
        case <-ctx.Done():
            return ctx.Err()
        case <-time.After(100 * time.Millisecond):
            fmt.Printf("Process %d step %d completed\n", id, i)
        }
    }
    return nil
}

// 最佳实践2：使用WaitGroup等待所有Goroutine完成
func batchProcess(tasks []int, timeout time.Duration) {
    ctx, cancel := context.WithTimeout(context.Background(), timeout)
    defer cancel()
    
    var wg sync.WaitGroup
    errChan := make(chan error, len(tasks))
    
    for _, task := range tasks {
        wg.Add(1)
        go func(id int) {
            defer wg.Done()
            if err := processWithContext(ctx, id); err != nil {
                errChan <- fmt.Errorf("task %d failed: %w", id, err)
            }
        }(task)
    }
    
    // 等待所有任务完成或超时
    done := make(chan struct{})
    go func() {
        wg.Wait()
        close(done)
    }()
    
    select {
    case <-done:
        fmt.Println("All tasks completed successfully")
    case <-ctx.Done():
        fmt.Printf("Batch processing timeout/cancelled: %v\n", ctx.Err())
    }
    
    // 检查错误
    close(errChan)
    for err := range errChan {
        fmt.Println("Error:", err)
    }
}

// 最佳实践3：优雅关闭服务
type Service struct {
    name     string
    running  int32
    shutdown chan struct{}
    wg       sync.WaitGroup
}

func NewService(name string) *Service {
    return &Service{
        name:     name,
        shutdown: make(chan struct{}),
    }
}

func (s *Service) Start() {
    if !atomic.CompareAndSwapInt32(&s.running, 0, 1) {
        return // 已经在运行
    }
    
    s.wg.Add(1)
    go s.run()
}

func (s *Service) run() {
    defer s.wg.Done()
    ticker := time.NewTicker(1 * time.Second)
    defer ticker.Stop()
    
    fmt.Printf("Service %s started\n", s.name)
    
    for {
        select {
        case <-ticker.C:
            fmt.Printf("Service %s is running\n", s.name)
        case <-s.shutdown:
            fmt.Printf("Service %s shutting down\n", s.name)
            return
        }
    }
}

func (s *Service) Stop() {
    if !atomic.CompareAndSwapInt32(&s.running, 1, 0) {
        return // 已经停止
    }
    
    close(s.shutdown)
    s.wg.Wait()
    fmt.Printf("Service %s stopped\n", s.name)
}

// 最佳实践4：资源池管理
type ResourcePool struct {
    resources chan *Resource
    factory   func() *Resource
    mu        sync.Mutex
    closed    bool
}

type Resource struct {
    id  int
    use int
}

func NewResourcePool(size int, factory func() *Resource) *ResourcePool {
    pool := &ResourcePool{
        resources: make(chan *Resource, size),
        factory:   factory,
    }
    
    // 预创建资源
    for i := 0; i < size; i++ {
        pool.resources <- factory()
    }
    
    return pool
}

func (rp *ResourcePool) Get() (*Resource, error) {
    rp.mu.Lock()
    if rp.closed {
        rp.mu.Unlock()
        return nil, fmt.Errorf("pool closed")
    }
    rp.mu.Unlock()
    
    select {
    case resource := <-rp.resources:
        resource.use++
        return resource, nil
    default:
        // 池中无资源，创建新资源
        return rp.factory(), nil
    }
}

func (rp *ResourcePool) Put(resource *Resource) {
    rp.mu.Lock()
    if rp.closed {
        rp.mu.Unlock()
        return
    }
    rp.mu.Unlock()
    
    select {
    case rp.resources <- resource:
    default:
        // 池已满，丢弃资源
    }
}

func (rp *ResourcePool) Close() {
    rp.mu.Lock()
    defer rp.mu.Unlock()
    
    if rp.closed {
        return
    }
    
    rp.closed = true
    close(rp.resources)
}

func demonstrateBestPractices() {
    fmt.Println("=== Batch Processing with Context ===")
    tasks := []int{1, 2, 3, 4, 5}
    batchProcess(tasks, 2*time.Second)
    
    fmt.Println("\n=== Service Lifecycle Management ===")
    service := NewService("MyService")
    service.Start()
    
    time.Sleep(3 * time.Second)
    service.Stop()
    
    fmt.Println("\n=== Resource Pool Management ===")
    factory := func() *Resource {
        staticID := 0
        return &Resource{id: staticID}
    }
    
    pool := NewResourcePool(3, factory)
    
    var wg sync.WaitGroup
    for i := 0; i < 10; i++ {
        wg.Add(1)
        go func(id int) {
            defer wg.Done()
            resource, err := pool.Get()
            if err != nil {
                fmt.Printf("Failed to get resource %d: %v\n", id, err)
                return
            }
            
            fmt.Printf("Got resource %d (use count: %d)\n", resource.id, resource.use)
            time.Sleep(100 * time.Millisecond)
            
            pool.Put(resource)
        }(i)
    }
    
    wg.Wait()
    pool.Close()
    
    fmt.Println("All best practices demonstrated")
}

func main() {
    demonstrateBestPractices()
}
```